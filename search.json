[{"title":"Raycast 超詳細介紹！快速提升生產力的超好用工具！","url":"/Raycast-超詳細介紹！快速提升生產力的超好用工具！/","content":"\n# 前言\n\n不知道大家會不會覺得在使用電腦時，常常會有鍵盤滑鼠切換的動作，導致工作效率低下？例如在需要開啟一個檔案的時候，可能就會需要先打開 Finder，再用滑鼠點擊開啟檔案；又或是臨時需要翻譯時，就需要先切換到瀏覽器打開 Google Translate 再進行翻譯；想確認接下來的會議連結時，又需要點擊到日曆的 APP 再開啟會議連結。這些切換在無形之中就浪費了不少時間，而 Raycast 就是一個可以幫助你解決這些問題的工具。\n\n![Raycast](/assets/Raycast-超詳細介紹！快速提升生產力的超好用工具！/intro.png)\n\n<!-- More -->\n\n# 簡介\n\n從[官網](https://www.raycast.com/)上，我們可以看到 Raycast 是一個啟動器，他提供給你一個輸入指令的視窗，你可以輸入指令來執行你想要的動作，例如開啟檔案、翻譯、計算機、單位轉換等等。並且 Raycast 的社群非常強大，眾多開發者製作的各式各樣的 extensions，使得 Raycast 擁有非常多的功能。\n\n如果有使用過 Spotlight 的讀者，可以直接把 Raycast 當作 Spotlight 的升級版使用，官方也提供了[文件](https://manual.raycast.com/hotkey)教你如何將 Spotlight 取代成 Raycast。\n\n今天筆者將會介紹 Raycast 中，筆者認為最實用、最能夠提升生產力的指令，只要能夠熟悉這些指令的使用，一定能夠大幅提升你的工作效率！\n\n讓我們按下 **<code style=\"color: red\">⌘</code> <code style=\"color: red\">Space</code>**，打開 Raycast，開始探索 Raycast 的強大功能吧！\n\n# 常用功能介紹\n\n{% note success %}\n👉 在使用 Raycast 時，不一定要輸入完整的指令，Raycast 有模糊搜尋功能，也會根據你使用指令的頻率來排序指令，像是筆者輸入 **<code style=\"color: red\">tr</code>** 後，Raycast 會自動推薦 **<code style=\"color: red\">Translate</code>**，所以也不用擔心打字時輸入錯字或是要打很多字啦～\n{% endnote %}\n\n{% note success %}\n👉 常用的指令可以加到 Favorites（對指令按下 **<code style=\"color: red\">⌘</code> **<code style=\"color: red\">⇧</code>** <code style=\"color: red\">F</code>**），這樣就可以把常用的指令固定在 Raycast 的最上面囉。\n{% endnote %}\n\n## 一般使用者\n\n### 開啟／切換 APP\n\n最基本的功能之一，但習慣之後就可以省下很多時間，不用再移動你的滑鼠去點 APP 的 icon 啦。只要打開 Raycast 後輸入 APP 的名稱就可以快速開啟或是切換到該 APP。\n\n### 檔案搜尋\n\n- **<code style=\"color: red\">File Search</code>**\n\nRaycast 也可以快速的瀏覽最近使用的檔案或是搜尋檔案，輸入 **<code style=\"color: red\">File Search</code>** 就可以看到最近使用的檔案或是再輸入關鍵字搜尋檔案，按下 enter **<code style=\"color: red\">↩</code>** 就可以直接開啟檔案。\n\n![Raycast 檔案搜尋](/assets/Raycast-超詳細介紹！快速提升生產力的超好用工具！/file-search.png)\n\n### 各種系統設定\n\n- **<code style=\"color: red\">Lock Screen</code>**\n- **<code style=\"color: red\">Log Out</code>**\n\nRaycast 還提供了各種系統設定的指令，像是鎖定螢幕、登出系統等等，讀者們可以輸入 **<code style=\"color: red\">Raycast Settings Extension</code>** 在 Raycast 設定中，找到 System 以及 System Settings，就可以看到更多的系統設定指令。\n\n### 剪貼簿歷史\n\n- **<code style=\"color: red\">Clipboard History</code>**\n\n筆者最喜歡的功能之一，不用再煩惱一次只能複製貼上一個東西啦～Raycast 幫你通通記住，而且如果複製的是一個連結或是一個圖片，還可以有一個快速的 preview，讓你可以直接看到你複製的內容喔！\n\n甚至還可以把常用的內容直接 Pin 在剪貼簿的最上面，這樣每次打開 clipboard history 就可以直接貼上你常用的內容了！像是筆者在寫這篇文章的時候就會把一些常用的文字 pin 住，非常實用！\n\n![Raycast Clipboard History](/assets/Raycast-超詳細介紹！快速提升生產力的超好用工具！/clipboard-history.png)\n\n{% note success %}\n👉 選定要貼上的內容後按下 enter **<code style=\"color: red\">↩</code>**，就可以直接貼上內容到目前的輸入框中！\n{% endnote %}\n\n### 計算機\n\nRaycast 有比 Spotlight 更強大的計算機功能，可以直接在輸入框中輸入數學運算式，甚至是單位轉換、貨幣轉換等等，非常實用！更多使用技巧可以參考[官方文件](https://raycast.com/extensions/calculator)。\n\n![Raycast 可以做到貨幣轉換](/assets/Raycast-超詳細介紹！快速提升生產力的超好用工具！/currency-conversion.png)\n![Raycast 也可以做到運算後單位轉換](/assets/Raycast-超詳細介紹！快速提升生產力的超好用工具！/calculator-conversion.png)\n\n{% note success %}\n👉 按下 enter **<code style=\"color: red\">↩</code>** 可以把運算結果複製到剪貼簿！\n{% endnote %}\n\n### 視窗管理\n\n- **<code style=\"color: red\">Maximize</code>**\n- **<code style=\"color: red\">Left Half</code>**\n- **<code style=\"color: red\">Right Half</code>**\n- **<code style=\"color: red\">Toggle Fullscreen</code>**\n\n很多時候我們會想要把剛開啟的視窗最大化、或是在多工處理的時候把視窗分成兩半，Raycast 提供了 56 個管理視窗的指令，只有你想不到沒有它做不到！\n\n![Raycast 有超多 Window Management 指令！](/assets/Raycast-超詳細介紹！快速提升生產力的超好用工具！/window-management.png)\n\n筆者最常用的就是 **<code style=\"color: red\">Maximize</code>**，可以把視窗最大化，再也不用按著 <code style=\"color: red\">⌥</code> 去點視窗的上面小小的綠色按鈕了！**<code style=\"color: red\">Left Half</code>** 和 **<code style=\"color: red\">Right Half</code>** 分別會把視窗放置在左半部或是右半部，這樣就可以在同時處理多個視窗的時候，快速的調整好分割的視窗大小啦！\n\n![Raycast Maximize Window](/assets/Raycast-超詳細介紹！快速提升生產力的超好用工具！/maximize.gif)\n\n{% note success %}\n👉 你可以把不會使用到的功能在 Raycast 的設定中關閉，打開 Raycast 輸入 **<code style=\"color: red\">Raycast Settings Extensions</code>** 就可以看到設定頁面囉！\n{% endnote %}\n\n### 日曆\n\n- **<code style=\"color: red\">My Schedule</code>**\n\n輸入 **<code style=\"color: red\">My Schedule</code>** 就可以快速瀏覽接下來的行程，如果會議上有綁定會議連結，則按下 enter **<code style=\"color: red\">↩</code>** 就可以直接打開會議，不用再打開日曆的 APP 啦～Raycast 還有整合 menu bar 的功能，可以把日曆的 icon 放在 menu bar 上，讓你可以快速瀏覽接下來的行程。\n\n![Raycast 瀏覽行程](/assets/Raycast-超詳細介紹！快速提升生產力的超好用工具！/calendar.png)\n\n![Raycast 日曆與 Menu Bar 的整合](/assets/Raycast-超詳細介紹！快速提升生產力的超好用工具！/calendar-menu-bar.png)\n\n{% note success %}\n👉 記得安裝 Raycast 後要先[設定日曆](https://www.raycast.com/extensions/calendar)的權限，讓 Raycast 可以讀取 MacOS 的日曆資料才能使用喔！Menu Bar 的 icon 要在會議開始前的什麼時候顯示也可以設定喔！\n{% endnote %}\n\n### Google 翻譯\n\n- **<code style=\"color: red\">Translate</code>**\n\n推薦會打開 Google 翻譯的各位使用，可以直接在 Raycast 輸入 **<code style=\"color: red\">Translate</code>**，然後輸入要翻譯的文字，就可以直接看到翻譯結果囉！\n\n![Raycast Google Translate](/assets/Raycast-超詳細介紹！快速提升生產力的超好用工具！/translate.png)\n\n{% note success %}\n👉 Raycast 的 Google Translate 就是非官方製作的 extension，在 Raycast 中輸入 **<code style=\"color: red\">Store</code>** 再搜尋 Google Translate 就可以安裝囉！或是可以到[這裡](https://www.raycast.com/gebeto/translate)下載！\n{% endnote %}\n\n### 其他\n\nRaycast 還有超多 extensions 等著你去探索安裝，像是：\n- 喜歡聽音樂的朋友可以安裝 [Spotify](https://www.raycast.com/mattisssa/spotify-player) 插件，就可以透過 Raycast 看到目前正在播放的歌曲，也可以直接控制播放、暫停、下一首、上一首和搜尋歌曲！\n- 常常需要搜尋天氣預報嗎？現在你可以安裝 [Weather](https://www.raycast.com/tonka3000/weather) 插件，不但可以透過 **<code style=\"color: red\">Weather</code>** 指令搜尋地點的天氣，還可以直接在 menu bar 上顯示天氣預報，就可以快速瀏覽天氣囉！\n- 有在用 Notion 或是 Obsidian 這類的筆記軟體嗎？可以安裝 [Notion](https://www.raycast.com/HenriChabrand/notion) 或是 [Obsidian](https://www.raycast.com/marcjulian/obsidian) 的插件，快速的搜尋和瀏覽你的筆記！\n- 想要快速的開啟瀏覽器書籤嗎？不如試試 [Browser Bookmarks](https://www.raycast.com/raycast/browser-bookmarks) 這個插件。或是如果你是 Arc Browser 的用戶的話，可以改裝 [Arc](https://www.raycast.com/the-browser-company/arc) 的插件，不但可以從 Raycast 開啟書籤，還能在 Raycast 中搜尋瀏覽紀錄和切換分頁喔！\n\n## 開發者\n\n接下來筆者想要介紹一些身為軟體開發者一定會喜歡的工具，用 Raycast 來提升自己的開發生產力吧！\n\n### What's my IP\n\n- **<code style=\"color: red\">My IP</code>**\n- **<code style=\"color: red\">Query IP</code>**\n\n還在上瀏覽器搜尋自己的 IP 嗎？安裝 [IP Geolocation](https://www.raycast.com/koinzhang/ip-geolocation) 這個插件，就可以透過 **<code style=\"color: red\">My IP</code>** 指令快速的查看自己的 IP 囉！也可以透過 **<code style=\"color: red\">Query IP</code>** 指令查詢 domain 的 IP！\n\n![Raycast 查詢當前 IP 資訊](/assets/Raycast-超詳細介紹！快速提升生產力的超好用工具！/myip.png)\n\n### Speedtest\n\n- **<code style=\"color: red\">Speedtest</code>**\n\n每次都要上 speedtest.net 或是 fast.com 測網路速度？安裝 [Speedtest](https://www.raycast.com/tonka3000/speedtest) 這個插件，就可以透過 **<code style=\"color: red\">Speedtest</code>** 指令快速的做 speedtest 囉！\n\n![Raycast 做 speedtest](/assets/Raycast-超詳細介紹！快速提升生產力的超好用工具！/speedtest.png)\n\n### Random Data Generator\n\n- **<code style=\"color: red\">Generate Random Data</code>**\n\n需要生成假資料或是隨機的密碼嗎？安裝 [Random Data Generator](https://www.raycast.com/tonka3000/random-data-generator) 這個插件，就可以透過 Raycast 直接使用由 [faker.js](https://fakerjs.dev/api/) 產生的隨機資料囉！不管你是想要隨機的 UUID、姓名、地址、電話號碼還是其他的資料，都可以透過這個插件來產生囉！\n\n![Raycast 產生隨機 UUID](/assets/Raycast-超詳細介紹！快速提升生產力的超好用工具！/random-uuid.png)\n\n### VSCode Project Manager\n\n- **<code style=\"color: red\">Search Project Manager</code>**\n\n有在使用 VSCode 的開發者一定要來試試看 [Project Manager](https://marketplace.visualstudio.com/items?itemName=alefragnani.project-manager) 這個插件與 [Raycast 插件](https://www.raycast.com/MarkusLanger/vscode-project-manager)的組合！\n\n把常用的 project 都加到 VSCode 的 project manager 中，就可以透過 Raycast 快速的開啟你的 project 囉！再也不用先打開終端機 `cd` 到專案目錄，再用 `code .` 來開啟 VSCode 了。\n\n{% note\tsuccess %}\n👉 你甚至可以到 Raycast 中將這個插件設置 alias 為 **<code style=\"color: red\">code</code>**，這樣你就可以在 Raycast 中直接輸入 **<code style=\"color: red\">code</code>** **<code style=\"color: red\">Space</code>** **<code style=\"color: red\">{Project Name}</code>** 來快速的開啟你的 project 囉！\n{% endnote %}\n\n![Raycast 開啟 VSCode 專案](/assets/Raycast-超詳細介紹！快速提升生產力的超好用工具！/vscode.gif)\n\n### Toolbox\n\n- **<code style=\"color: red\">Toolbox</code>**\n\n[Toolbox](https://www.raycast.com/Kang/toolbox) 這個插件包含了一些常用的工具，例如：\n\n- Base64 Encode/Decode\n- JSON Format\n- Date to Unix Timestamp\n- JWT Decode\n\n雖然覺得功能還可以再齊全一點，但已經可以滿足很多需求了，再也不用上網找網站來轉換囉！\n\n### Github\n\nGithub 應該是每個開發者都使用過的工具吧～何不用用看 [Github](https://www.raycast.com/raycast/github) 的插件呢？可以快速的搜尋 Repository、查看 Pull Request、創建或是查看 Issue、查看 Github Actions 的狀態，還支援把 notification 設置在 menu bar 上的功能喔！唯一的缺點大概只有如果想要查看 Organization 裡面的 private 資訊，必須要先經過 Organization 的 owner 授權，這就要看公司願不願意授權了🫠。\n\n![Raycast Search Github Repository](/assets/Raycast-超詳細介紹！快速提升生產力的超好用工具！/github-search.png)\n\n# 彩蛋\n\nRaycast 還隱藏了一些小彩蛋：\n\n- **<code style=\"color: red\">Confetti</code>** 可以播放慶祝的動畫！\n\n\t![Raycast Confetti](/assets/Raycast-超詳細介紹！快速提升生產力的超好用工具！/confetti.gif)\n- **<code style=\"color: red\">Toggle Bounce Animation</code>** 可以讓 Raycast 視窗在螢幕上來回彈跳！\n\n\t![Raycast Toggle Bounce Animation](/assets/Raycast-超詳細介紹！快速提升生產力的超好用工具！/bounce.gif)\n\n# 結尾\n\n一開始安裝 Raycast 可能常常會忘記要使用它，但是一旦習慣了，你會發現它可以幫你省下很多時間，讓你的工作更有效率。Raycast 還有很多插件等著你去探索，去 Raycast 的[商店](https://www.raycast.com/store)看看自己有沒有什麼好用的插件吧！如果你推薦有什麼好用的插件或是功能，也歡迎在下面留言分享給我喔～\n\n> 最後，如果你喜歡這篇文章，或是文章對你有幫助的話，可以幫我按個喜歡、或是留言！你的支持就是我寫作的最大動力。有任何想問的問題也可以在底下留言喔～\n","tags":["MacOS","Productivity"],"categories":["Others"]},{"title":"PostgreSQL 如何預估 Function Return Rows 以及對 Query 的效能影響","url":"/PostgreSQL-如何預估-Function-Return-Rows-以及對-Query-的效能影響/","content":"\n今天要來跟大家分享 PostgreSQL 是如何預估 function 的 return rows 的？以及 function 的 return rows 會對 query 的效能有什麼影響？\n\n透過真實案例可以看到當 function 的 return rows 與實際不同時，會造成的效能影響，再透過簡單的分析和 PostgreSQL 原始碼分析做找出原因，最後再用簡單的幾個方式讓 PostgreSQL 可以更準確的預測 function 的 return rows。\n\n環境：PostgreSQL 11.17\n\n<!-- More -->\n\n# 先備知識\n\nPostgreSQL 會利用 cost estimation 來創建 query plan，而其中在每個步驟後會有一個 return rows，代表 PostgreSQL 預估這個步驟會回傳多少 rows。\n\n舉個簡單的例子來說：\n\n```sql\nCREATE TABLE IF NOT EXISTS test (\n\tid INT PRIMARY KEY,\n\tvalue INT NOT NULL\n);\n\nINSERT INTO test(id, value) SELECT generate_series(1, 100000), generate_series(1, 100000);\nVACUUM ANALYZE test;\n```\n\n我們先創建一個 table，並且插入 id 為 1 ~ 100000，value 為 1 ~ 100000 的資料，並且執行 VACUUM ANALYZE 來更新 table 的統計資訊。\n\n```sql\nEXPLAIN SELECT * FROM test WHERE id > 100;\n                        QUERY PLAN\n-----------------------------------------------------------\nSeq Scan on test  (cost=0.00..1693.00 rows=99900 width=8)\n\tFilter: (id > 100)\n```\n\n```sql\nEXPLAIN SELECT * FROM test WHERE id > 99000;\n                                QUERY PLAN\n--------------------------------------------------------------------------\nIndex Scan using test_pkey on test  (cost=0.29..38.77 rows=1056 width=8)\n\tIndex Cond: (id > 99000)\n```\n\n再來我們分別搜尋 id > 100 和 id > 99000 的資料，可以看到第一個 query 的 return rows 為 99900，而第二個 query 的 return rows 為 1056。PostgreSQL 很好的預估了 return rows 並且可以根據 return rows 來決定接下來的 query plan。\n\n# 真實案例\n\n我們有一段類似這樣的 query：\n\n```sql\nSELECT\n\tseries.date,\n\tCOALESCE(stats.count, 0) AS count\nFROM\n\t(\n\t\tSELECT GENERATE_SERIES((NOW() - INTERVAL '6 DAYS')::TIMESTAMP, NOW()::TIMESTAMP, '1 DAY')::DATE\n\t) AS series(date)\n\tLEFT JOIN stats ON stats.member_id = 123 AND stats.date = series.date;\n```\n\n這段 query 想要做的事情很簡單，就是取得 `member_id = 123` 的最近 7 天的資料（count），並且如果有些日期沒有資料，就回傳 0。\n\n而 `stats` 表中有 `(member_id, date)` 的 index `stats_pkey`，並且我們知道 generate_series 只會產生 7 個 rows，因此期望上如果 PostgreSQL 使用 [*Indexed Nested Loop Join*](https://www.interdb.jp/pg/pgsql03.html#_3.5.1.1.)，就可以在 7 次 index scan 完成這個 query。\n\n\n但事實上使用 `EXPLAIN` 後卻發現 PostgreSQL 先對 `stats` 使用 `member_id` 做了一次 index scan 過濾後，才使用 merge join 將兩表合併。\n\n```sql\nMerge Left Join  (cost=21048.31..21120.93 rows=4508 width=12)\n  Merge Cond: ((((generate_series(((now() - '6 days'::interval))::timestamp without time zone, (now())::timestamp without time zone, '1 day'::interval)))::date) = stats.date)\n  ->  Sort  (cost=92.36..94.86 rows=1000 width=4)\n\t\tSort Key: (((generate_series(((now() - '6 days'::interval))::timestamp without time zone, (now())::timestamp without time zone, '1 day'::interval)))::date)\n\t\t->  Result  (cost=0.00..32.53 rows=1000 width=4)\n\t\t\t->  ProjectSet  (cost=0.00..5.03 rows=1000 width=8)\n\t\t\t\t->  Result  (cost=0.00..0.01 rows=1 width=0)\n  ->  Sort  (cost=20955.95..20962.00 rows=2421 width=16)\n\t\tSort Key: stats.date\n\t\t->  Bitmap Heap Scan on stats  (cost=239.32..20819.87 rows=2421 width=16)\n\t\t\tRecheck Cond: (member_id = 123)\n\t\t\t->  Bitmap Index Scan on stats_pkey  (cost=0.00..238.72 rows=2421 width=0)\n\t\t\t\tIndex Cond: (member_id = 123)\n```\n\n可以看到下面的 sort 是對 stats 表使用 `member_id = 123` 的 index 進行過濾，並且根據 `member_id` 選擇的不同，PostgreSQL 會因為 `member_id` 在表中出現的頻率甚至可能選擇 `(Parallel) Seq Scan`（高頻率時）或是 `Index Scan`（低頻率時）來做第一次的過濾。\n\n而上面的 sort 是對 `generate_series` 產生的 rows 進行過濾，雖然我們知道 `generate_series` 只會產生 7 個 rows，但 PostgreSQL 的 query planner 並沒辦法知道這件事情，而預估出來的 rows 竟然是 1000！\n\n# 分析\n\n有了 `EXPLAIN` 的結果，接下來就可以分析以下兩個問題：\n\n## 為什麼 PostgreSQL 對 function 產生的 rows 會預估成 1000？\n\nPostgreSQL 儲存 function 的相關資訊是在 `pg_proc` 這張表中，而當中有一個欄位 [prorows](https://www.postgresql.org/docs/11/catalog-pg-proc.html#:~:text=prorows,not%20proretset)，這個欄位就是用來預估 function 產生的 rows 數量的。\n\n要設定 `prorows` 可以在 `CREATE FUNCTION` 時指定，而根據[文件](https://www.postgresql.org/docs/11/sql-createfunction.html#:~:text=often%20than%20necessary.-,ROWS%20result_rows,-A%20positive%20number)的說明：\n\n{% note info %}\n\nRows: A positive number giving the estimated number of rows that the planner should expect the function to return. This is only allowed when the function is declared to return a set. The default assumption is 1000 rows.\n\n{% endnote %}\n\n我們可以知道 `prorows` 的預設值是 1000，並且我們可以查看 `generate_series` 的 `prorows` 是多少：\n\n```sql\nSELECT proname, prosrc, prorows FROM pg_proc WHERE proname = 'generate_series';\n\n     proname     |            prosrc            | prorows\n-----------------+------------------------------+---------\n generate_series | generate_series_timestamp    |    1000\n generate_series | generate_series_step_int4    |    1000\n generate_series | generate_series_int4         |    1000\n generate_series | generate_series_step_int8    |    1000\n generate_series | generate_series_int8         |    1000\n generate_series | generate_series_step_numeric |    1000\n generate_series | generate_series_numeric      |    1000\n generate_series | generate_series_timestamptz  |    1000\n```\n\n可以看到確實是 1000，這也是為什麼 PostgreSQL 在 planning 時，預估 `generate_series` 會產生 1000 個 rows。\n\n## 為什麼 PostgreSQL 會選擇先過濾一次 `member_id` 再做 Join？\n\n在上面 `EXPLAIN` 的結果可以看到，PostgreSQL 選擇了先對內表（`stats`）進行一次過濾才做 Join，而不是我們預期的直接使用 *Indexed Nested Loop Join*（或嚴格來說是 [*index scan with parameterized path*](https://github.com/postgres/postgres/blob/REL_11_STABLE/src/backend/optimizer/README#L705)）。\n\n{% note info %}\n**Pseudo Plan of Index Nested Loop Join**\n```\nNest Loop\n\t-> Seq Scan on series\n\t-> Index Scan using stats_pkey on stats\n\t\tIndex Condition: (stats.member_id = 123) AND (stats.date = series.date)\n```\n{% endnote %}\n\n由上面可以看出，對於 indexed nested loop join 來說，外表（`series`）越小越好，因為 nested loop join 就是對每個外表的 row 進行一次內表的過濾，但內表的大小並不是太重要。\n\n因此當外表太大時，planner 可能就會改用 merge join 或是 hash join 的方式來合併兩表。而採用 merge join 或是 hash join 時，planner 就可以先使用 `member_id = 123` 的條件來過濾 `series`，可以直接讓內表的數量大幅減少（以我們的例子來說大約是一千萬個 rows -> 數千個 rows），來加速 merge join 或是 hash join 的過程。\n\n## 當 Function Return Rows 錯誤時的 Nested Loop Join Cost\n\n我們可以透過把其他 join method 關閉的方式來強制 PostgreSQL 使用 nested loop join，來看看 nested loop join 的 cost 是多少：\n\n```sql\nSET enable_hashjoin = FALSE;\nSET enable_mergejoin = FALSE;\nSET enable_material = FALSE;\nEXPLAIN \nSELECT\n\tseries.date,\n\tCOALESCE(stats.count, 0) AS count\nFROM\n\t(\n\t\tSELECT GENERATE_SERIES((NOW() - INTERVAL '6 DAYS')::TIMESTAMP, NOW()::TIMESTAMP, '1 DAY')::DATE\n\t) AS series(date)\n\tLEFT JOIN stats ON stats.member_id = 123 AND stats.date = series.date;\n\nNested Loop Left Join  (cost=0.56..59249.13 rows=4524 width=12)\n  ->  Result  (cost=0.00..32.53 rows=1000 width=4)\n\t\t->  ProjectSet  (cost=0.00..5.03 rows=1000 width=8)\n\t\t\t->  Result  (cost=0.00..0.01 rows=1 width=0)\n  ->  Index Scan using stats_pkey on stats  (cost=0.56..59.16 rows=5 width=16)\n\t\tIndex Cond: ((member_id = 123) AND (date = (((generate_series(((now() - '6 days'::interval))::timestamp without time zone, (now())::timestamp without time zone, '1 day'::interval)))::date)))\n```\n\n可以看到 index scan 所需的 cost 為 59.16，而因為外表（`stats`）預估有 1000 個 rows，因此 cost 理所當然的會是 $59.16 \\times 1000 + C \\approx 59249.13$。確實比[上面](#真實案例)使用 merge left join 得到的 cost 21120.13 還要高。\n\n{% note info %}\n詳細的 indexed nested loop join cost 計算方式可以參考 [The Internals of PostgreSQL](https://www.interdb.jp/pg/pgsql03.html#_3.5.1.3.) 的介紹。\n{% endnote %}\n\n{% note info %}\n實際上 index scan 的 cost 會受到設定中的 `random_page_cost` 以及資料分布（index selectivity、most common values、．．．）的影響：\n\n- `random_page_cost` 越低，index scan 的 cost 越低。筆者使用的是預設值 10，當改為實際上在 production 上的值 1.1 時，index scan 的 cost 只剩 7.09，total cost 為 7187.16。（但同時 merge left join 的 total cost 也降到 2961.17，所以 PostgreSQL 還是會選擇 merge left join）。\n- 如果 `member_id = 123` 在表中出現的次數過多，index scan 的 cost 也會增加（因為過濾的效率變差了，導致更多的 rows 返回）。PostgreSQL 也有可能改採用 bitmap scan 或是 (parallel) seq scan 的方式來過濾。\n{% endnote %}\n\n# 原始碼分析\n\n## PostgreSQL Set Returning Function(SRF) Rows Estimation\n\n我們來分析 PostgreSQL 底層是如何預估 SRF 產生的 rows 數量的。\n\n根據上面部分的 `EXPLAIN` 結果，我們可以看到首先是由 `ProjectSet` 這個節點產生 1000 個 rows 這個結論的：\n\n```sql\nResult  (cost=0.00..37.53 rows=1000 width=8)\n\t->  ProjectSet  (cost=0.00..5.03 rows=1000 width=8)\n\t\t->  Result  (cost=0.00..0.01 rows=1 width=0)\n```\n\n而 `ProjectSet` 節點是由函數 [`create_set_projection_path`](https://github.com/postgres/postgres/blob/REL_11_STABLE/src/backend/optimizer/util/pathnode.c#L2634) 產生。Call path 如下：\n\n- {% codeblock pathnode.c/create_set_projection_path lang:c https://github.com/postgres/postgres/blob/REL_11_STABLE/src/backend/optimizer/util/pathnode.c#L2634 first_line:2668 %}\n\titemrows = expression_returns_set_rows(node);\n\t{% endcodeblock %}\n\n- {% codeblock clauses.c/expression_returns_set_rows lang:c https://github.com/postgres/postgres/blob/REL_11_STABLE/src/backend/optimizer/util/clauses.c#L804 first_line:812 %}\n\tif (expr->funcretset)\n\t\treturn clamp_row_est(get_func_rows(expr->funcid));\n\t{% endcodeblock %}\n\n- {% codeblock lsyscache.c/get_func_rows lang:c https://github.com/postgres/postgres/blob/REL_11_STABLE/src/backend/utils/cache/lsyscache.c#L1664 first_line:1673 %}\n\tresult = ((Form_pg_proc) GETSTRUCT(tp))->prorows;\n\tReleaseSysCache(tp);\n\treturn result;\n\t{% endcodeblock %}\n\n可以看到 `ProjectSet` 確實是由 function 的 `prorows` 來預測 return rows 的數量的。\n\n# 解決方案\n\n## 更改 `prorows` 的值\n\n我們可以先做以下的實驗，創建一個 `my_generate_series` function，並將 `prorows` 設為 7：\n\n```sql\nCREATE FUNCTION my_generate_series(TIMESTAMP WITH TIME ZONE, TIMESTAMP WITH TIME ZONE, INTERVAL)\n\tRETURNS TABLE (t TIMESTAMP WITH TIME ZONE) AS\n\t$$ SELECT * FROM generate_series($1, $2, $3) $$\n\tLANGUAGE SQL ROWS 7;\n\n      proname       |                   prosrc                    | prorows\n--------------------+---------------------------------------------+---------\n my_generate_series |  SELECT * FROM generate_series($1, $2, $3)  |      10\n```\n\n將 query 改為使用 `my_generate_series`：\n\n```sql\nEXPLAIN \nSELECT\n\tseries.date,\n\tCOALESCE(stats.count, 0) AS count\nFROM\n\t(\n\t\tSELECT my_generate_series((NOW() - INTERVAL '6 DAYS')::TIMESTAMP, NOW()::TIMESTAMP, '1 DAY')::DATE\n\t) AS series(date)\n\tLEFT JOIN stats ON stats.member_id = 123 AND stats.date = series.date;\n\nNested Loop Left Join  (cost=0.56..426.14 rows=32 width=12)\n  ->  Result  (cost=0.00..2.28 rows=7 width=4)\n\t\t->  ProjectSet  (cost=0.00..0.32 rows=7 width=8)\n\t\t\t->  Result  (cost=0.00..0.01 rows=1 width=0)\n  ->  Index Scan using stats_pkey on stats  (cost=0.56..60.49 rows=5 width=16)\n\t\tIndex Cond: ((member_id = 123) AND (date = (((my_generate_series((((now() - '6 days'::interval))::timestamp without time zone)::timestamp with time zone, ((now())::timestamp without time zone)::timestamp with time zone, '1 day'::interval)))::date)))\n```\n\n可以看到 `ProjectSet` 節點的 rows 數量已經從 1000 變成 7，並且正確的使用了我們預期的 nested loop join。\n\n而 total cost 也從從原本的 59249.13 降到 $60.49 \\times 7 + C \\approx 426.14$。\n\n{% note info %}\n如果讀者使用的 PostgreSQL 版本 >= 12，也可以試試直接更改 `generate_series` 的 `prorows`：\n```sql\nALTER FUNCTION generate_series(TIMESTAMP WITH TIME ZONE, TIMESTAMP WITH TIME ZONE, INTERVAL) ROWS 7;\n```\n{% endnote %}\n\n但在實際環境中，我們要特別創建一個 `generate_series` 函數感覺有點多此一舉，所以我們可以使用另一個方法。\n\n## 加上 LIMIT\n\n我們可以在 `generate_series` 的 subquery 後加上 `LIMIT`：\n\n```sql\nEXPLAIN\nSELECT\n\tseries.date,\n\tCOALESCE(stats.count, 0) AS count\nFROM\n\t(\n\t\tSELECT\n\t\t\tgenerate_series((NOW() - INTERVAL '6 DAYS')::TIMESTAMP, NOW()::TIMESTAMP, '1 DAY')::DATE\n\t\tLIMIT 7\n\t) AS series(date)\n\tLEFT JOIN stats ON stats.member_id = 123 AND stats.date = series.date;\n\nNested Loop Left Join  (cost=0.56..424.09 rows=32 width=12)\n  ->  Limit  (cost=0.00..0.23 rows=7 width=4)\n\t\t->  Result  (cost=0.00..32.53 rows=1000 width=4)\n\t\t\t->  ProjectSet  (cost=0.00..5.03 rows=1000 width=8)\n\t\t\t\t->  Result  (cost=0.00..0.01 rows=1 width=0)\n  ->  Index Scan using stats_pkey on stats  (cost=0.56..60.49 rows=5 width=16)\n\t\tIndex Cond: ((member_id = 123) AND (date = (((generate_series(((now() - '6 days'::interval))::timestamp without time zone, (now())::timestamp without time zone, '1 day'::interval)))::date)))\n```\n\n可以看到因為多了一個 `Limit` 節點回傳了 7 個 rows 給上層，我們一樣能得到預期的結果。\n\n# 補充\n\n## PostgreSQL 12 Planner Support Function\n\n現在我們可以透過 `prorows` 的設定或是 `LIMIT` 來讓 planner 更好的預測 return rows 的數量。但當 function 的 return rows 真的是 dynamic 的時候怎麼辦呢？\n\n而 PostgreSQL 針對 function 沒辦法很好的預估 return rows 在 PostgreSQL 12 時提出了解決辦法，稱作 [planner support function](https://www.postgresql.org/docs/12/xfunc-optimization.html)，基本上就是允許在 function 上面綁定一個 support function 用來幫助 planner 根據參數的不同估計 return rows 的數量。\n\n我們可以很快的體驗一下有沒有 support function 的差異：\n\n```sql\n-- PG 11\nEXPLAIN SELECT GENERATE_SERIES(1, 10);\n\n                   QUERY PLAN\n------------------------------------------------\nProjectSet  (cost=0.00..5.02 rows=1000 width=4)\n  ->  Result  (cost=0.00..0.01 rows=1 width=0)\n\n-- PG 12\nEXPLAIN SELECT GENERATE_SERIES(1, 10);\n\n                   QUERY PLAN\n------------------------------------------------\n ProjectSet  (cost=0.00..0.52 rows=10 width=4)\n   ->  Result  (cost=0.00..0.01 rows=1 width=0)\n```\n\n這是因為在 PostgreSQL 12 整數的 `generate_series` 已經有了預設的 support function，我們可以看新增的 `prosupport` 欄位。\n\n```sql\nSELECT proname, prosrc, prorows, prosupport FROM pg_proc WHERE proname = 'generate_series';\n     proname     |            prosrc            | prorows |          prosupport\n-----------------+------------------------------+---------+------------------------------\n generate_series | generate_series_timestamp    |    1000 | -\n generate_series | generate_series_step_int4    |    1000 | generate_series_int4_support\n generate_series | generate_series_int4         |    1000 | generate_series_int4_support\n generate_series | generate_series_step_int8    |    1000 | generate_series_int8_support\n generate_series | generate_series_int8         |    1000 | generate_series_int8_support\n generate_series | generate_series_step_numeric |    1000 | -\n generate_series | generate_series_numeric      |    1000 | -\n generate_series | generate_series_timestamptz  |    1000 | -\n```\n\n很可惜直到目前（PostgreSQL 15）為止，`generate_series` 都還是只有支援整數的 support function，所以對於使用 timestamp 來說，還是要使用上面提到的方法。\n\n# 總結\n\nPostgreSQL 目前對於 function 的 return rows 雖然有了新的 `prosupport` 欄位來支援一些簡單函數的 return rows 預估，但大多數的 functions 都還是使用預設值 1000 的。因此在未來如果有在 query 內使用到 function，不仿用 `EXPLAIN` 注意 PostgreSQL 的 estimated function return rows 是否會影響到 query plan。如果發現與預想中的 plan 不同，可以透過上面提到的幾個方法改寫 query 來達到預期的效果！\n\n> 最後，如果你喜歡這篇文章，或是文章對你有幫助的話，可以幫我按個喜歡、或是留言！你的支持就是我寫作的最大動力。有任何想問的問題也可以在底下留言喔～\n","tags":["PostgreSQL"],"categories":["PostgreSQL"]},{"title":"LeetCode 629 - K Inverse Pairs Array","url":"/LeetCode-K-Inverse-Pairs-Array/","content":"\n# 題目\n題目連結：[https://leetcode.com/problems/k-inverse-pairs-array/](https://leetcode.com/problems/k-inverse-pairs-array/)\n\n給定 $N$ 以及 $K$，求出包含 $1\\sim N$ 的序列中，有多少種恰好有 $K$ 個逆序數對。\n\n答案要對 $10^9 + 7$ 取餘。\n\n# 範例說明\n\n## Example 1:\n\n```\nInput: n = 3, k = 0\nOutput: 1\nExplanation: Only the array [1,2,3] which consists of numbers from 1 to 3 has exactly 0 inverse pairs.\n```\n\n## Example 2:\n\n```\nInput: n = 3, k = 1\nOutput: 2\nExplanation: The array [1,3,2] and [2,1,3] have exactly 1 inverse pair.\n```\n\n<!-- More -->\n\n# 想法\n\n假設我們要產生 $1\\sim N$ 的任意序列，我們可以從第一個位置開始擺起，假設 $N=3$ 且 $K=2$，則：\n\n1. 若第一個數字是 1，則我們可以知道不管剩下的數字怎麼擺，1 與剩下數字皆不會產生逆序數對。因此若剩下的兩個數字中能產生 $k-0=2-0=2$ 組逆序數對，就滿足我們 $N=3$ 且 $K=2$ 的要求。\n2. 若第一個數字是 2，則我們可以知道不管剩下的數字怎麼擺，2 與剩下的數字一定會產生一組逆序數對 $(2,1)$，因此若剩下的兩個數字中能產生 $k-1=2-1=1$ 組逆序數對，就能滿足我們 $N=3$ 且 $K=2$ 的需求。\n3. 若第一個數字是 3，則我們可以知道不管剩下的數字怎麼擺，3 與剩下的數字一定會產生兩組逆序數對 $(3,1)$ 與 $(3,2)$，因此若剩下的兩個數字中能產生 $k-2=2-2=0$ 組逆序數對，就能滿足我們 $N=3$ 且 $K=2$ 的需求。\n\n因此我們可以定義 $dp(i,j)$ 為長度為 $i$ 的序列中恰好有 $j$ 個逆序數對的序列數量。則我們知道長度為 $i$ 的序列中，第一個數字有 $i$ 種選擇：\n\n- 若第一個數字選擇第 1 小的數字，第一個數字不會與後面的任何數字產生逆序數對，因此 $dp(i,j)=dp(i-1,j)$。\n- 若第一個數字選擇第 2 小的數字，第一個數字恰好與後面的所有數字產生 1 組逆序數對，因此 $dp(i,j)=dp(i-1,j-1)$。\n- ...\n- 若第一個數字選擇第 $i$ 小的數字（也就是最大的），第一個數字恰好與後面的 $i-1$ 個數字都產生逆序數對，因此 $dp(i,j)=dp(i-1,j-i+1)$。\n\n因此總結來說轉移即為：\n\n$$\\red{dp(i,j)=\\sum_{k=1}^{i}dp(i-1,j-k+1)}$$\n\n舉例來說：\n\n- $dp(3,0)=dp(2,0)+dp(2,-1)+dp(2,-2)$\n- $dp(3,1)=dp(2,1)+dp(2,0)+dp(2,-1)$\n- $dp(3,2)=dp(2,2)+dp(2,1)+dp(2,0)$\n- $dp(3,3)=dp(2,3)+dp(2,2)+dp(2,1)$\n- $dp(3,4)=dp(2,4)+dp(2,3)+dp(2,2)$\n- ...\n\n因此我們即可開始實作。\n\n# 實作細節\n\n## 時間複雜度優化\n\n根據上面的轉移式，我們可以很簡單的做出 $O(N\\cdot K^2)$ 的 DP，pseudo code 如下（這裡先不考慮邊界問題）：\n\n```cpp\nfor (int i = 1; i <= N; ++i) {\n  for (int j = 1; j <= K; ++j) {\n    for (int k = 1; k <= i; ++k) {\n      dp[i][j] += dp[i - 1][j - k + 1];\n    }\n  }\n}\n```\n\n但很顯然觀察上面列出的轉移，我們可以觀察到每次計算 $dp(i,j)$ 時，並不需要都獨立的用一個 $k=1\\sim i$ 的迴圈計算，而可以從 $dp(i,j-1)$ 來轉移：\n\n例如計算 $dp(3,3)=dp(2,3)+dp(2,2)+dp(2,1)$ 時，我們可以透過 $dp(3,2)=dp(2,2)+dp(2,1)+dp(2,0)$，得到 $dp(3,3)=dp(3,2)+dp(2,3)-dp(2,0)$。\n\n也就是說我們可以將轉移式簡化為：\n\n$$\\red{dp(i,j)=dp(i,j-1)+dp(i-1,j)-dp(i-1,j-i)}$$\n\n因此中間的 $k$ 迴圈即可被省去，時間複雜度可以降到 $O(N \\cdot K)$。\n\n實作時，要注意：\n\n- 邊界 $j-i$ 可能會小於 0，由於我們知道不可能會有負數個逆序數對的情況，因此對於所有 $j \\lt 0$，$dp(i,j)=0$。\n- 所有的 $dp(i,0)=1$（長度為 $i$ 且沒有逆序數對的序列只有一種）。\n\n最後的答案即為 $dp(N,K)$。\n\n## 空間複雜度優化\n\n我們可以開一個 $(N + 1)\\times (K+1)$ 大小的陣列來儲存所有的 DP 狀態，但是透過上述的轉移式可以發現，在計算 $dp(i,j)$ 時，只會用到 $dp(i-1,j)$、$dp(i,j-1)$ 以及 $dp(i-1,j-i)$ 這三個值，因此我們只需要保留兩個 rows 的 DP 狀態就足夠了。\n\n因此筆者在實作時使用 `pre` 陣列代表 $dp(i-1)$；`cur` 陣列代表 $dp(i)$，每次 $i$ 迴圈後交換兩個陣列的指標即可。\n\n如此一來可以把空間複雜度從 $O(N \\cdot K)$ 降到 $O(K)$。\n\n# 程式碼\n\n```cpp\n/**\n * Author: justin0u0<mail@justin0u0.com>\n * Problem: https://leetcode.com/problems/k-inverse-pairs-array/\n * Runtime: 33ms\n * Time Complexity: O(NK)\n * Space Complexity: O(K)\n */\n\nclass Solution {\nprivate:\n  const int mod = 1e9 + 7;\npublic:\n  int kInversePairs(int n, int k) {\n    vector<int>* pre = new vector<int>(k + 1, 0);\n    vector<int>* cur = new vector<int>(k + 1, 0);\n    (*pre)[0] = 1;\n    (*cur)[0] = 1;\n\n    for (int i = 1; i <= n; ++i) {\n      swap(pre, cur); // cur->dp[i], pre->dp[i-1]\n      for (int j = 1; j <= k; ++j) {\n        if (j < i) {\n          // j - i < 0, so dp(i-1,j-i) = 0\n          (*cur)[j] = ((*cur)[j - 1] + (*pre)[j]) % mod;\n        } else {\n          (*cur)[j] = (((*cur)[j - 1] + (*pre)[j]) % mod - (*pre)[j - i] + mod) % mod;\n        }\n      }\n    }\n\n    int answer = (*cur)[k];\n    delete pre;\n    delete cur;\n\n    return answer;\n  }\n};\n```\n","tags":["LeetCode","動態規劃（Dynamic Programming, DP）"],"categories":["LeetCode"]},{"title":"Designing Data-Intensive Application 第五章筆記","url":"/Designing-Data-Intensive-Application-第五章筆記/","content":"\n資料副本（Replication）的意思是透過網路，將資料複製到多個節點（機器）上面儲存。Replication 有以下三個好處：\n\n1. 讓資料在地理位置上靠近使用者以降低 network latency。\n2. 當部分節點不可用時系統依然可以保持運作，提高可用性（Availability）。\n3. 分散 read queries，提高 read throughput。\n\nReplication 的難處在於資料是會更新的，因此如何透過網路同步這些資料的更新是最大的難點。本章節主要探討三種常見的 replication model，分別是 **single-leader replication**、**multi-leader replication** 以及 **leaderless replication**。\n\n<!-- More -->\n\n# Leader and Followers\n\n首先，只要每個 writes 都能被每個 replica 按照一樣的順序執行，那麼最後每個 replica 都會擁有相同的資料。\n\n因此最常見的 replica 方式即將某個節點視為 leader，所有的 client writes 都只能送給 leader，在 leader 確認資料寫入其本地的儲存後，由 leader 透過 replication log 或是 stream 向其他的 replicas（稱作 followers）送出資料變更的請求。每個 followers 只要在收到更新的 log 後按照與 leader 一樣的順序更新其本地的儲存即可。\n\n而 client 雖然只能寫入到 leader，但是可以透過 leader 或是 followers 來讀取。\n\n![Single-leader replication.](/assets/Designing-Data-Intensive-Application-第五章筆記/leader_follower.png)\n\nLeader-follower 模式可以透過讀寫分離來大幅降低資料庫的 loading，並且一般多數的 web application 都是 read-heavy 的，因此在 PostgreSQL、MySQL、MongoDB 等常見的 databases、或是 Kafka、RabbitMQ 等 message queue systems 中，leader-based replication 都是內建的 features。\n\n## Synchronous Versus Asynchonous Replication\n\n在 replication 的過程中，可以發現從 leader 寫入到 followers 寫入中間會有一段 delay。\n\n在 relational database 中，可以選擇使用 synchronous 或是 asynchronous 的方式來做 replication。\n\n- Synchronous Replication：Leader 等到 followers 回覆資料寫入後才讓寫入可見並且回傳成功。\n- Asynchronous Replication：Leader 確認寫入到本地儲存空間後立刻回傳成功。\n\nSynchronous 的好處能夠確保資料的一致性（Consistency），壞處是當 followers failure 時資料就無法寫入，降低系統的可用性（Availability）。\n\n因此所有的 followers 都使用 synchronous replication 是不可行的，否則一個 follower 的 outage 就會導致所有寫入無法執行。常見的配置包括：\n\n- 只有一個 follower 採用 synchronous，其他 followers 採用 asynchronous。有時稱作 *semi-synchronous* 的設定。\n- 全部的 followers 都是 asynchronous，可能會造成資料的遺失（寫入到 leader 後 leader failure，則這筆 commit 無法被提交到其他的 followers 而消失）。\n\n## Setting Up New Followers\n\n要在 zero-downtime 的情況下增加新的 follower，首先取得 leader 在某個時間點的 snapshot 並複製到 follower node 中，follower 開始向 leader 請求 snapshot 後的 replication log，例如 log 的索引值在 PostgreSQL 中稱作 LSN，最後同步完成。\n\n## Handling Node Outages\n\n### Follower failure: Catch-up recovery\n\n在 follower 的本地儲存中有紀錄哪些 commit 已經完成的 log，因此當 follower 重啟時可以從最後一個完成的 transaction 開始向 leader 請求所有的變更。\n\n### Leader failure: Failover\n\nLeader failure 後某個 follower 需要晉升成 leader，這個過程稱作 *failover*。\n\nFailover 的過程包含以下幾個步驟：\n\n1. 偵測 leader 是否還正常運作：通常透過 heartbeat 與 timeout 達成。\n2. 選擇一個新的 leader：通常稱作 *leader election*，新的 leader 最好的選擇是擁有最新資料的 follower。要讓所有 followers 取得新 leader 的共識是一個 *consensus problem*，會在後面的章節介紹到。\n3. 重新設置系統：要讓 client 端、舊的 leader、其餘 followers 都能夠知道有新的 leader 以及新的 leader 是哪個節點。\n\n其中有一些重要的問題要注意：\n\n- 採用 asynchronous replication 可能導致資料的遺失，違反 durability 的原則。\n- 就算 durability 的問題可以被允許，也要小心丟棄 writes 可能造成的問題。\n\n\t例如使用 autoincrementing ID 後，若新的 leader 使用到一些舊 leader 使用過的 ID，可能導致儲存在 Redis 快取中 ID 對應到的資料與 DB 中的資料不符而導致讀取到錯誤的資料（可能造成資料外洩）。\n- 要小心 *split brain* 的發生，也就是有兩個 nodes 任為自己是 leader 並同時接收 client 的寫入。\n- Heartbeat timeout 的時間如果過短，會造成不必要的 failover（leader 可能只是 response time 增加）；過長會造成系統花更久的時間 recovery。\n\n## Implementation of Replication Logs\n\n關於 replication logs 的實作有以下幾種：\n\n### Statement-based replication\n\n將修改相關的 statement 複製到 follower nodes，例如 SQL 中就是 `INSERT`、`UPDATE` 與 `DELETE`。這種方法會有一些問題：\n\n- Nondeterministic functions 會得到不一樣的結果：例如 `NOW()` 或是 `RAND()`。\n- 一些 statements 的順序將不能改變，例如 `INSERT` autoincrementing column，或是基於一些欄位的 `UPDATE`。這會限制原本可以並行的 transactions 使他們一定要串行的執行。\n\n所以 leader 需要先將 nondeterministic statement 都先變成 deterministic log 才能送給 follower nodes。因此這個方法只有在少數情境下使用，例如 MySQL v5.1 之前。\n\n### Write-ahead log (WAL) shipping\n\nFollowers 透過讀取 leader 的 WAL 來同步資料。被 PostgreSQL 以及 Oracle 使用。\n\n如此一來完全可以解決 statement-based replication 的問題，但是壞處是 WAL 是非常底層的格式，通常是紀錄 disk 的哪個 block 的數值變化。因此基本上跨版本之間的 WAL 是很有可能不相容的。\n\n如果 WAL 可以跨版本相容，那可以被用在 zero-downtime 升級。先將 followers 都升級後，再讓 leader failover 即可。\n\n### Logical log replication\n\n透過額外的 log 提供給 follower 使用，例如 MySQL 的 binlog。\n\n因為 logical log 與 storage engine 使用的格式完全不同，因此適合提供給外部的服務使用，例如寫到 warehouse 或是同步到其他 database 等等。這種技術被稱作 *capture data change*。\n\n### Trigger-based replication\n\n使用 database 的 trigger 註冊一個 application layer 的函數，讓資料更新時自動的呼叫。\n\n適合用在更彈性、更複雜的 replication 上，但是 overhead 較大。\n\n例如 Databus for Oracle、Bucardo for Postgres。\n\n# Problems with Replication Log\n\nReplicaiton 提供 fault-tolerance、提升 scalability 以及降低 network latency（地理位置上）。\n\n採用 leader-based replication 可以透過增加 followers 的數量提升 read scability，並且大多數網路應用程式都是 read-heavy 的。就如同前面提到的，使用 leader-based replication 必須採用 asynchronous 的模式，否則單一節點故障會使得整個系統無法運作。\n\n而後面介紹到的 multi-leader replication 或是 leaderless 也都採用 asynchronous 來保證 availability。\n\n採用 asynchronous 模式可能會讀到尚未更新的資料，造成資料庫間暫時的不一致（data inconsistency）。如果對資料庫的寫入停止，那 followers 終究會更新並且達到一致，這就是所謂的 *最終一致性 eventual consistency*。\n\n以下探討 *eventual consistency* 造成的幾個問題：\n\n## Reading Your Own Writes\n\n使用者送了一筆更新，但是下次讀取時沒有讀到。\n\n若想要達到 *read-your-writes consistency* or *read-after-writes consistency* 來避免這個問題，可以：\n\n- 當使用者讀取自己可以修改到的資料時，從 leader 讀取。例如個人資料只有使用者本人可以修改，因此只要是本人讀取時皆從 leader 讀取。但若資料可以被大多使用者修改則不適合這種方式（會變成每個 requests 都要從 leader 讀取）。\n- 由 client 提供上次 write 的時間，則 server 只回傳再這個時間之後的結果。若當前的 follower 還沒有更新到這個時間點，可以轉交 requests 給其他 followers 或是多等待。但如果使用者從多個裝置上操作，這個方法將難以達到。\n\n## Monotonic Reads\n\n若同一個使用者前後兩次 requests 讀到不同的 followers，可能造成第一次的 request 讀到比第二次 request 還要新的資料。\n\n若想要達到 *monotonic reads consistency* 來避免這個問題，可以讓同一個使用者永遠都只讀到同一個 replica，例如透過 hash user ID 來決定讀取的 replica，但這樣就必須考慮 replica failed 的時候這些 requests 要如何 re-route 到其他 replica 的問題。\n\n## Consistent Prefix Reads\n\n有因果關係的兩個更新，讀取時要保留相同的順序。\n\n這個情況在 single-leader replication 並不會發生，只有在資料庫有 partitioned 並且兩個更新被寫入到不同資料庫時才會發生。因此我們需要一些方式來追蹤有因果關係的寫入，方法會在本章節的後面提到。\n\n## Solutions for Replication Lag\n\n因此在使用 *eventual consistency* 的資料庫時，開發者必須思考這些 replication lag 會不會帶來問題。若有問題的話，則應該要考慮提供更強的 consistency。\n\n> 最後，如果你喜歡這篇文章，或是文章對你有幫助的話，可以幫我按個喜歡、或是留言！你的支持就是我寫作的最大動力。有任何想問的問題也可以在底下留言喔～\n\n# Multi-Leader Replication\n\nSingle-leader replication 的主要缺點是所有的 write operations 都要透過 leader。\n\n一個簡單的想法就是使用多個 leaders，每個 leader 並且每個 leaders 都要把收到的 writes forward 給其他節點。\n\n## Use Cases for Multi-Leader \n\n多個 datacenter 的操作即是一個很適合 multi-leader replication 的應用場景。\n\n![Multi-leader replication.](/assets/Designing-Data-Intensive-Application-第五章筆記/multi_leader.png)\n\n可以考慮每個 datacenter 中只有一個 leader，在一個 data center 內使用 single-leader replication。而 datacenters 之間由 leader 複製 writes 給其他的 leaders。\n\nMulti-leader replication 比 single-leader replication 好的地方在於：\n\n- Performance：若 datacenters 是跨國的，則可以選擇最近的 datacenter 進行讀寫大幅降低 network latency。\n- Tolerance of datacenter outages：可以容忍整個 datacenter 的 failover。\n- Tolerance of network problems：當 server 與 leader 之間有 network problems 時可以直接寫入到其他 leaders。\n\n使用 Multi-leader replication 最大的缺點在必須處理 concurrent writes，包含 conflict detection、conflict avoidance 以及 conflict resolution。這部分會在[接下來的篇幅中](#handling-write-conflicts)提到。\n\n一些 database 是可以透過外部工具支援 multi-leader replication，例如 BDR for PostgreSQL。\n\n## Handling Write Conflicts\n\n假設兩個使用者同時對一個值做修改，而一個修改被成功寫到 leader 1，另一個修改被成功寫道 leader 2，這時就會產生衝突。要處理 write conflicts 有以下幾種方式：\n\n1. Detect conflicts：可以透過 lock write operations 來偵測 conflicts，但是在 multi-leader replication 下使用 global lock 會喪失 multi-leader replication 的主要優點。\n\n2. Avoid conflicts：\n\t1. 確保資料不會在兩個 datacenter 同時寫入（要考慮在兩地的 user 有多大機率寫入同一筆資料，若機率很小則適合）。\n\t2. 利用 routing 使得同樣的資料被寫入到同一個 leader。壞處是對於同一筆資料來說其實就是 single-leader replication。\n\n3. Resolve conflicts：\n\t以下是幾種可能發生的 conflicts 與常用的解決方案：\n\n\t1. 寫入同一筆資料：\n\t\t1. *Last write wins (LWW)*：注意分散式系統下時間是不可靠的，可能會需要使用 logical clock。並且 *last write wins* 代表有 data loss 的可能性。\n\t\t2. Perserve all (*MVCC*)：保留全部的資訊並且交由 application layer 來解決衝突。\n\n\t\t*LWW* 與 *MVCC* 會在 [Leaderless Replication](#leaderless-replication) 中大量被使用並介紹。\n\t\n\t2. Autoincrementing ID：改使用 distributed sequence ID，例如 UUIDV1，Twitter's Snowflake ID 等等。\n\n\t3. DDL Change：在某一 leader 修改 schema，例如 `ALTER TABLE ADD COLUMN` 或是 `ALTER TABLE ALTER COLUMN`。若指令本身需要 lock whole table 才能運作，那就會需要 global leaders lock。否則只將 DDL Change 複製到其他 leaders 就好。\n\n\t4. Trigger on slave：在 multi-leader replication 下使用 trigger，可能會造成重複的問題。例如 database 中有一 trigger 會在表 A 修改欄位後寫入一筆紀錄到表 B。假設 leader 1 修改表 A 後 trigger 而新增一筆紀錄到表 B，表 A 的修改與表 B 的修改都會被 replica 到 leader 2，而 leader 2 的 trigger 又會因為表 A 的修改而新增一筆紀錄到表 B，造成重複。因此在 multi-leader replication 中不能使用 trigger。\n\n### Automatic Conflict Resolution\n\n因為 resolve conflicts 的方式很多，而自己實作有時容易有 error 發生，而在某些情況下衝突是可以自動被解決的，以下有幾種方案：\n\n1. Conflict-free replicatec datatypes (CRDTs)：可以自動 resolve conflicts 的 data structure。Riak、Redis 中都有實作 CRDTs 來自動 resolve conflicts。\n2. Mergable persistent data structures：透過紀錄 version history，提供 three-way merge 的能力。\n\tThree-way merge 是指除了兩個版本之外，再多加上一個 LSA（Base）的版本一起做比較（因此 CRDTs 是 two-way merge）。例如 Git 就是使用 three-way merge。\n3. Operational transformation：常被用於共同編輯的算法。\n\n## Multi-Leader Replication Topologies\n\n![Multi-leader replication topologies.](/assets/Designing-Data-Intensive-Application-第五章筆記/multi_leader_topologies.png)\n\n使用環狀、星狀拓樸，寫入可能會經過同一個 node 多次，因此每個節點需要在自己處理過的資料上面加上自己的 node ID 的 tag。並且若一個節點 fail 可能會導致整個 cluster 無法運作。\n\n所以 multi-leader replication 比較喜歡採用 all-to-all 的拓樸形式，但是這種模式可能導致因果關係的順序有誤（環狀、星狀都一定不會有）。如下圖：\n\n![All-to-all topology cause consistent prefix reads problem.](/assets/Designing-Data-Intensive-Application-第五章筆記/multi_leader_all_to_all_topology_wrong_order.png)\n\n可以透過 version clock 來解決 [consistent prefix reads](#consistent-prefix-reads) 的問題。\n\n# Leaderless Replication\n\n每個 replication 都允許讀寫。最著名的 leaderless replication 應用是 [Dynamo](https://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf)。根據這篇 paper 的想法，有了 Riak、Cassandra、Voldermort 等 opensource 的 leaderless replication database。\n\n## Writing to the Database When a Node Is Down\n\n### Read repair and anti-entropy\n\n在 leaderless replication 中，寫入操作會一次寫到 N 個節點（N 不需要等於節點數量）。先不考慮 concurrent writes 的問題，假設有一節點正在重啟，那麼寫入操作會略過此節點的寫入。當此節點重啟完畢後，有以下兩個問題：\n\n1. 若 client 從此節點讀資料，可能會讀到舊的資料。\n\t解決辦法：一次從多個節點讀取，透過 version 就可以知道哪個是最新的資料。\n\n2. 此節點要如何同步沒更新到的資料？\n\n\t1. Read repair：當 client 讀到舊的資料時，做一個寫入到 replica。適合大量 read 的情境。\n\t2. Anti-Entropy：用一個背景程序不斷檢查兩個節點之間的資料。會有 delay，但是很少被讀到的資料也能被同步。\n\n\t\t{% note info %}\n\t\t#### Merkle Tree\n\n\t\t如何快速的比對兩個節點之間的資料呢？可以透過 merkle tree（雜湊樹）這個資料結構。\n\t\t- `IH: internal hash function`\n\t\t- `LH: leaf hash function`\n\t\t- `S1, S2, S3, S4, S5: data`\n\n\t\t每個節點都對資料創建一個 merkle tree，因此若兩節點資料相同，只需要 `O(1)` 的時間就可以確認。若兩節點有一筆資料不同，也只需要 `O(logN)` 的時間就可以找到不同的資料。\n\n\t\t```plaintext\n                          ROOT=IH(H+E)\n                           /        \\\n                          /          \\\n                    H=IH(F+G)         E\n                   /       \\           \\\n                  /         \\           \\\n            F=IH(A+B)       G=IH(C+D)    E\n           /     \\           /     \\      \\\n          /       \\         /       \\      \\\n      A=LH(S1)  B=LH(S2) C=LH(S3)  D=LH(S4) E=LH(S5)\n\t\t```\n\n\t\t{% endnote %}\n\n### Quorums for reading and writing\n\n若每一筆資料有 N 個副本，只要保證每次寫入 $w$ 個副本並且每次讀入 $r$ 個副本且 $w+r \\gt n$，則根據鴿籠原理至少有一個 read 可以讀到最新的資料。\n\n在 dynamo-style 資料庫中，$w,\\ r,\\ n$ 通常都是可以調整的，常見的配置是 $w=r=\\lceil (n+1)/2 \\rceil$。只要節點數量 $n \\ge w\\And n \\ge r$，系統就可以繼續運行。例如 $n=5,\\ w=3,\\ r=3$ 則可以容忍 2 個節點的 failure。\n\n{% note warning %}\n\n#### Quorum\n\n注意，在 Dynamo 的 paper 中提到的 quorum 與 [wiki 上的 quorum](https://en.wikipedia.org/wiki/Quorum_(distributed_computing)) 解釋上面有些不同。\n\nWiki 上面的 quorum 利用 lock 會在 read/write 操作前進行 lock 的動作，因此若設置 $w+r \\gt n$，則讀與寫不可能並行。若再加上 $w+w \\gt n$ 的條件，則寫與寫也不可能並行。如此一來即可保證 [**serializability**](https://en.wikipedia.org/wiki/Serializability)。\n\n但是在 Dynamo 的 paper 中並沒有提到要做讀寫之前需要 lock，$w,\\ r$ 只是用來確認寫入與讀取的節點數量而已，因此在 paper 中也有提及是使用 quorum-like technique 而已。**因此 dynamo-style 的資料庫就算設置 $w+r \\gt n \\And w+w \\gt n$ 也通常不保證 linearizability。**\n\n{% endnote %}\n\n## Limitations of Quorum Consistency\n\n採用 quorum 可能會有以下的問題：\n\n- 透過設置更小的 $w,\\ r$，可以提高系統的可用性以及降低延遲，但就有可能會讀到舊的資料。\n- 兩個寫入操作可能會造成衝突。在 [文章後段](#detecting-concurrent-writes) 會介紹 LWW 與 MVCC 的做法來解決衝突。\n- 如果寫入操作在一些節點成功一些失敗，並且最後只寫入少於 $w$ 個節點並回傳失敗。這些成功的寫入並無法被 rollback 造成資料不一致。\n- 就算採用 $w+r \\gt n$，dynamo-style 的資料庫並不保證 linearizability。\n\t![Reader B read stale value although strict quorum is applied.](/assets/Designing-Data-Intensive-Application-第五章筆記/strict_quorum_not_linearizable.png)\n\n因此雖然正常情況下使用 $w+r \\gt n$ 的 quorum 配置可以確保讀到最新的值，但是實際上並沒有那麼簡單。Dynamo-style 資料庫通常需要應用能夠容忍最終一致性，而 $w,\\ r$ 的配置可以用來調整讀到舊資料的機率。\n\n## Sloppy Quorums and Hinted Handoff\n\n一般情況下，database cluster 會有很多節點，而每個寫入操作只需要 $n$ 個副本，透過 [consistent hashing](https://justin0u0.notion.site/Consistent-Hashing-a9969a175f464d008d1c18e347b210db) 可以決定資料要被寫到哪 $n$ 個節點。\n\n![Consistent hashing shows that data with key K must write to node A, B and C.](/assets/Designing-Data-Intensive-Application-第五章筆記/consistent_hashing.png)\n\n若 client 因為網路問題無法連接到這 $n$ 個節點，我們可以回傳 error 告知失敗。或是允許寫入到這 $n$ 個節點以外的節點，稱作 *sloppy quorum*。\n\n例如上圖，資料要被寫到 A、B、C 節點。當 A 節點不可用時，可以先暫時寫入到節點 D 的獨立儲存空間，並且紀錄原節點是 A 節點。如此一來當 D 節點發現 A 節點恢復時，就會將資料重新寫回 A 節點並將 D 節點內的資料刪除。這種方式就稱作 *hinted handoff*。\n\n## Detecting Concurrent Writes\n\n考慮兩個 clients 想寫入 `set(x, 1)` 與 `set(x, 2)`，因為網路速度的不同，不同節點可能收到不一樣的順序，導致最後兩個節點的資料是不一致的。\n\n因此這裡介紹 LWW 與 MVCC 兩種方式：\n\n### Last write wins\n\n在每個 writes 上面都附加一個 timestamp，當 conflict 發生時，選擇較新的 write。LWW 可以達成最終一致性，但壞處是會造成資料的遺失。\n\n由於在分散式系統下每個節點的時間都是不一樣的，因此甚至可能造成有因果關係的 writes 的時間是對調的。\n\n![A cause B but timestamp of A is after B.](/assets/Designing-Data-Intensive-Application-第五章筆記/lww_time_skew.png)\n\nCassandra 即選擇 LWW 來解決衝突，至於為什麼 cassandra 不選擇接下來要介紹的 *vector clock*，可以參考這篇 [Why Cassandra Doesn't Need Vector Clocks](https://www.datastax.com/blog/why-cassandra-doesnt-need-vector-clocks)。\n\n### MVCC\n\nMVCC 的想法為如果有衝突發生，那麼就偵測衝突並且保留全部的版本，在下一次 client 讀取這筆資料時就將全部版本返回交由 client 來解決衝突。\n\n所以首先要定義對於同一筆資料何謂衝突？**Concurrent write** 這個詞彙看似指的是時間上的同時發生，但若把時間的粒度縮小來看兩個寫入並不會完全同時發生。因此 concurrent write 的定義應該是兩個寫入是沒有因果關係的，因此這兩個寫入誰先誰後都沒有問題，所以才會照成衝突。\n\n使用 **[vector clocks/version vectors](https://justin0u0.notion.site/Vector-Clock-8f7434edf4e34ed5a2649f13c496d31a)** 為每個 key 維護多個版本號碼，當發生衝突時都保留。\n\n這種做法可以保證資料不會遺失，但是 client 必須自己解決衝突。\n\nDynamo 的 paper 中即使用此方法來偵測衝突的發生，Voldermort、Riak 都是採用此做法。\n\n# Summary\n\n總結 replication 帶來的好處有：\n\n- High availability：就算有部分節點停止也能正常運作。\n- Latency：透過縮短地理上的距離來降低延遲。\n- Scalability：可以透過增加機器的數量來提升讀寫能力。\n\n而常見的三種 replication 模式包含：\n\n- Single-leader replication：只有一個 leader 節點並且所有的寫入操作只能透過 leader，由 leader 將資料複製到其他的 follower 節點。配置簡單且不需要考慮 concurrent writes 的問題；但只能提升 read scalability，並且要考慮 leader failure 的問題\n- Multi-leader replication：有多個 leader 節點，適合在 datacenter 使用以降低寫入的 latency，有更高的可用性。但是必須處理 concurrent writes 的問題。\n- Leaderless replication：可以在任何 nodes 進行讀寫，有更高的 availability 以及更低的 consistency，適合能容忍 eventual consistency 的應用使用。\n\n對於 replication lag，使用時要考慮是否能接受 eventual consistency，否則需要考慮提高 consistency level：\n\n- Read-after-write consistency：使用者必須讀到自己寫入的資料。\n- Monotonic reads consistency：讀到的資料不能回朔。\n- Consistency prefix reads consistency：有因果關係的資料要正確。\n\n本文的圖片來源（Image credits）：\n- https://dataintensive.net/\n- https://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf\n\n> 最後，如果你喜歡這篇文章，或是文章對你有幫助的話，可以幫我按個喜歡、或是留言！你的支持就是我寫作的最大動力。有任何想問的問題也可以在底下留言喔～\n","tags":["Notes","DDIA"],"categories":["Notes"]},{"title":"Dcard Backend 實習心得","url":"/Dcard-Backend-實習心得/","content":"\n嗨大家好，我是 Justin，目前就讀清華大學資訊工程學系四年級，在 Dcard 做 backend intern 也半年了，想跟大家分享在 Dcard 實習這半年來的心得～\n\n![Dcard 真的是一間很有活力的公司，Slack 群組常常有各種梗圖xD](/assets/Dcard-Backend-實習心得/slack.png)\n\n在進入 Dcard 之前，因為已經有些後端開發經驗，但是並沒有機會接觸到**高流量**的系統是如何設計與開發的。因此找實習時，主要就是希望能接觸到大型系統開發以及能使用到最新技術。Dcard 在這方面算是非常符合，流量的部分相信不用多做說明，使用的技術部分也是相當的新，包含 Golang、Kubernetes、Microservices、gRPC 以及 OpenTelemetry 這些雲原生生態系最熱門技術 Dcard 都有在使用！\n\n<!-- More -->\n\n# Dcard Backend Team 日常\n\n開發方面，Dcard Backend 目前主要使用 Golang 作為開發語言，但還是有少部分比較早期的 repo 使用 NodeJS。目前都採用 Microservices 架構，對內服務使用 gRPC，對外則是一般的 RESTful API。而 Backend 內部有一套 code generating tool，可以幫助避免 boilerplate code 的撰寫，讓工程師們只需要專注於 business logic 與 architecture design 上。資料庫主要使用 PostgreSQL 以及 Redis。Infra 的部分則是 Kubernetes。\n\n在 Dcard Backend 會用到很多新的技術，例如 Capture Data Change（CDC）就是我在 Dcard 才第一次聽到並且使用到的技術。在 Microservices 中，最難處理的就是跨 services 的資料同步問題。早期 Dcard 內部是使用 event-driven 的方式，也就是透過 application layer 發送訊息到 message queue 中，再由另一端的 service subscribe 並消費這些 events。使用 event-driven 的麻煩之處在於工程師還要自己定義 event 的形式並且撰寫發送與接收的邏輯，另外要確保資料的寫入與 event 是否有同時寫到 message queue 中也是一個難點。現在 Dcard Backend 都大量改用 CDC 來處理這些資料同步化的問題，利用 PostgreSQL 的 logical replication 功能，工程師就只需要專注在訂閱資料的變化即可。\n\n我認為在 Dcard 實習很棒的一點在於，**這邊的工作環境不會讓你感受到因為你是實習生，而就不看重你的意見，或是會讓你感到不敢發言，在這裡各種意見都是歡迎的**，並且大家都會很踴躍的提出看法。舉例來說，因為 Dcard Backend 常常會有一些新技術的使用或是架構上的改進，因此 backend 在每週五都會有一次 sync up 會議進行分享與討論，在這些會議上我也常常能提出很多看法意見～\n\n在 Dcard Backend，**主管也不會因為你是實習生，而派遣一些不重要的工作給你**。像我現在就獨立的待在一個 delivery team 裡面，學習與 PM 溝通開出你認為可以實作的 spec，與 Android/iOS/Web 工程師們溝通適合的 API 並且常常會需要記得為他們考慮向下相容的問題。我目前做過最有趣的專案是抽卡匹配算法的改善，因為自己本身是就是打競賽的，從沒想過真的有一天能將競賽用到的 Dinic 演算法用在實務的 backend 開發上，真的是很有意思。\n\n但如果平時都自己待在 delivery team，要怎麼知道自己的架構設計好不好呢？在**開發大型專案之前，會透過舉辦 Design Review 的形式，大家自由的參加 review 來討論這樣的設計是不是有任何改進的地方**。若在設計上面有任何疑問，公司一些比較資深的前輩或是主管也都非常好相處，有任何不懂的地方就去提問、討論，他們都能提供很棒的建議！\n\n在 Dcard Backend 每兩週會舉辦一次讀書會，像是我剛加入時剛好開始讀一本叫做 *Designing Data-Intensive Application* 的書，最近也剛讀完整本書了。書中講到的各種分散式系統架構下重要的理論，真的是讓我受益良多。我也在讀書會中負責分享了其中的一個章節。對這本書有興趣的也可以去看我的[部落格文章](https://blog.justin0u0.com/tags/DDIA/)，雖然我還剩下很多章節的文章還沒補完😢。\n\n另外，每週五下午會舉辦 developer's session，不同 team 的工程師出來分享一些開發上的知識。例如 backend 分享過 cache-control 的機制讓前端工程師了解為什麼資料不會立即更新；Android 之前分享過如何處理 emoji 字數統計的問題。\n\n# Dcard 公司福利\n\nDcard 公司福利也是很讚的一部分，吃不完的零食，冰箱飲料有午後時光，每週二五公司請客一杯手搖，每週二還會提供午餐，每週五提供下午茶，特殊節日也會送一堆禮物～\n\n{% img /assets/Dcard-Backend-實習心得/food.jpg 600 600 %}\n\n另外公司的上班時間也很彈性，基本上表定時間是上午 10 點到晚上 7 點，但是有事的話都可以提早離開時數自己補。這樣的制度對還在上學的我真的很讚，不用特地為了考兩小時的期中考請假，直接提早兩小時去上班，在公司直接考試完再繼續工作XD！\n\n# 投 Dcard Backend 實習\n\n如果你有興趣投 Dcard Backend 實習但擔心不知如何準備的，可以去看我的另一篇文章[2021-Dcard-Backend-Intern-面試經驗分享](https://blog.justin0u0.com/2021-Dcard-Web-Backend-Intern-%E9%9D%A2%E8%A9%A6%E7%B6%93%E9%A9%97%E5%88%86%E4%BA%AB/)，相信會對你的準備很有幫助的！有任何疑問也歡迎來找我詢問～\n\n> 最後，如果你喜歡這篇文章，或是文章對你有幫助的話，可以幫我按個喜歡、或是留言！你的支持就是我寫作的最大動力。有任何想問的問題也可以在底下留言喔～\n","tags":["Dcard"],"categories":["Others"]},{"title":"神奇的整數壓縮算法——ZigZag","url":"/神奇的整數壓縮算法-ZigZag/","content":"\n在 Thirft 與 Protocol Buffers 中，都使用了一種整數壓縮的演算法叫做 ZigZag。\n\n算法本身很簡單，卻也很實用，因此分享給大家 ZigZag 的實作與想法。\n\n<!-- More -->\n\n# 二進制與二補數\n\n在電腦的世界，所有數字都是以二進位儲存的，我們假設數字是儲存在 8 bits 的變數中，例如：$(1)_{10}=(00000001)_{2}$、$(3)_{10}=(00000010)_{2}$。因此如果所有數字都是正數，則使用 8 個 bits 的最大數字很明顯是 $(255)_{10}=(11111111)_2$。\n\n可惜這個世界是有負數存在的，因此人們在考慮要如何在二進位中表示負數時，有了以下這些想法：\n\n1. 原碼（True form）\n\t這個想法很直觀，使用第一個 bit 做為 signed bit，如果是正數則為 0，負數則為 1。\n\n\t因此正負數除了第一個 bit 之外，剩下的表達方式與數值本身一樣。例如 $(11)_{10}=(00001011)_{2}$，$(-11)_{10}=(10001011)_{2}$。\n\n2. 1's 補數（One's complement）\n\t這個的想法也很直觀，直接將正數的所有 bit 取反當作負數的表達式。例如 $(11)_{10}=(00001011)_{2}$，$(-11)_{10}=(11110100)_{2}$。\n\n3. 2's 補數（Two's complement）\n\t然而以上兩種方式都有兩個問題：\n\t1. 數字 0 有兩種表達方式，原碼中有 $+0=(00000000)_2$ 與 $-0=(10000000)_2$；1's 補數中有 $+0=(00000000)_2)$ 與 $-0=(11111111)_2$。會造成混淆。\n\t2. 加法上的不便：在加法的實作上，兩種方式若直接做二進位的加法，都會出現奇怪的現象（請讀者自己加加看，就不補充例子了）。\n\n\t2's 補數即先取反（做 1's 補數）後，再 $+1$。\n\n\t例如：$(11)_{10}=(00001011)_{2}$，$(-11)_{10}=(11110101)_{2}$\n\n\t```\n\t(11)     ：00001011\n\t(-11) 1's：11110100（取反）\n\t(-11) 2's：11110101（+1）\n\t```\n\n# ZigZag\n\n接著進入正題，在大多數情況下，軟體工程師習慣使用 32 bits 的變數來儲存整數，例如 C/C++ 中的 `int`、Java 中的 `int`。因此在網路傳輸時，往往也會直接使用 32 bits 的數字做為傳輸類型，而 32 bits 的有號整數可以最大可以儲存到 2147483647，也就是 21 億。\n\n但是現實世界中，較小的數字往往比較常出現，例如使用者的 ID、商品的數量、商品的價格等，往往都是幾十幾百幾千到幾萬不等的數字。如果只是要傳輸一個數字 $(1)_{10}=(00000000\\_00000000\\_00000000\\_00000001)_2$，卻需要傳輸這麼多不需要的 0，感覺就很浪費。\n\n因此 ZigZag 的核心想法就是**當數字很小的時候，就只傳送有需要的 bytes 即可**，例如數字 $(1)_{10}$ 只傳送 $(00000001)_2$。\n\n如果只有正數的話就很容易實作，可惜我們需要考慮負數的存在。負數 $(-1)_{10}=(11111111\\_11111111\\_11111111\\_11111111)_2$，前面都是 1，就沒辦法直接丟棄了。\n\n因為 ZigZag 希望比較小的數字都用比較少的 bytes，因此 ZigZag 決定將數字依照絕對值大小排序，順序如下：\n\n```\n順序： 0  1  2  3  4  5  6 ...\n數字： 0 -1 +1 -2 +2 -3 +3 ...\n```\n\n觀察數字與順序在二進位的關係（這裡為了方便，先回到 8bits）：\n\n```\n數字：           順序：          順序、去除 last bit：\n 0 (00000000)   0 (00000000)   0 (0000000)\n-1 (11111111)   1 (00000001)   1 (0000000)\n+1 (00000001)   2 (00000010)   2 (0000001)\n-2 (11111110)   3 (00000011)   3 (0000001)\n+2 (00000010)   4 (00000100)   4 (0000010)\n-3 (11111101)   5 (00000101)   5 (0000010)\n+3 (00000011)   6 (00000110)   6 (0000011)\n```\n\n可以觀察到，若將順序中的最後一個 bit 看成 signed bit，則剩下的 bits 中，正數即原本的數字，而負數即原數字取反。\n\n因此我們只要**將原數字左移一位，負數再做取反後，將 signed bit 補到最後一位即可**。實際操作一次：\n\n```\n+3 = 00000011\n    \n   = 0000011x（左移一位）\n   = 00000110（補上 signed bit）\n   = 6\n```\n\n```\n-3 = 11111101\n\n   = 1111101x（左移一位）\n\t = 0000010x（取反）\n\t = 00000101（補上 signed bit）\n   = 5\n```\n\n最後 ZigZag 厲害的地方就在於，程式上的實作也非常簡單，可以透過位元運算達成：\n\n```go\nfunc int8ToZigZag(n int8) int8 {\n\treturn (n << 1) ^ (n >> 7)\n}\n\nfmt.Println(int8ToZigZag(3))  // 6\nfmt.Println(int8ToZigZag(-3)) // 5\n```\n\n其原理也很簡單，首先要知道，`<<` 是算術左移運算子（arithematic left shift operator），會將所有 bits 向左移動一格後補上 0；而 `>>` 是 算術右移運算子（arithematic right shift operator），會將所有 bits 向右移動後<font color=\"red\">補上 signed bit</font>。\n\n因此所有數在右移 7（`n >> 7`）後，正數因為原 signed bit 是 0，每次左移之後都會在左邊補上 0，所以最後變成 `00000000`；而負數因為原 signed bit 是 1，所以每次右移都會在左邊補上 1，所以最後變成 `11111111`。\n\n再來 `(n << 1)` 即數字左移一位，且最後右邊一位會補上 0。最後 `^` 為 xor 運算子，所以觀察 `(n << 1) ^ (n >> 7)`：\n\n```\n(n >> 7)：\n正數：      負數：\n00000000   11111111\n\n(n << 1)：\n正數：      負數：\nxxxxxxx0   yyyyyyy0\n```\n\n可以發現最右邊的 signed bit 部分，正數的一定是 0，負數的一定是 1。左邊數字部分，我們知道 `0 ^ x = x` 且 `1 ^ y = ~y`，所以正數的數字一定保持不變，而負數會被取反。\n\n而這正是我們想要的結果。\n\n最後回到 32bits 的數字：\n\n```go\nfunc int32ToZigZag(n int32) int32 {\n\treturn (n << 1) ^ (n >> 31)\n}\n```\n\nDecode 時只要將操作反過來即可（注意 golang 在 unsigned int 才會做 logical right shift，所以要先轉 `uint32`）：\n\n```go\nfunc zigZagToInt32(n int32) int32 {\n\tu := uint32(n)\n\treturn int32(u>>1) ^ -(n & 1)\n}\n```\n\n知道了如何對一個數字做 ZigZag encoding 後，我們只要再思考如何決定傳輸時要送幾個 bytes 即可：\n\n一種做法是用額外的一個 byte 代表接下來的整數有幾個 bytes，例如 $(00000001\\_00000010)_2$ 的第一個 byte 代表接下來的整數只有一個 byte，而第二個 byte 開始才是真正要傳輸的數字。但是這樣的做法最少需要兩個 bytes 才能表示一個數字。\n\n而 ZigZag 採用了另一種做法，就是每個 byte 中都**使用第一個 bit 作為「還有沒有下一個 byte」的判斷**，也就是說如果 first bit 是 1，則代表這個數字還沒有結束；如果 first bit 是 0，則代表這個數字已經結束。因此在傳輸時，其實每個 byte 能被使用的 bits 只有 7 個。而這種做法被稱作 [*Base128 Varint*](https://developers.google.com/protocol-buffers/docs/encoding#varints)。\n\n舉例來說，如果我們想要傳輸 1337 這個數字，先做 `int32ToZigZag(1337) = 2674 = 0b10100_1110010`，傳輸時由低位先傳，所以傳出的第一個 byte 為 `11110010`，可以看到因為還沒傳完，所以第一個 bit 為 1，後 7 個 bits 才是真正的資料 `1110010`；傳出的第二個 bit 為 `00010100`，因為已經沒有下一個 byte 了，所以第一個 bit 為 0。\n\n實作上也是很簡單，`^0x7F` 是 $(11111111\\_11111111\\_11111111\\_10000000)_2$，所以 `n & ^0x7F` 的作用在於檢查 `n` 是不是只有最後 7 個 bits 有數字。如果是的話，就寫入 `n`；否則就只寫入 `n` 的最後 7 bits 加上前面的一個 1（代表後面還有數字）。\n\n```go\nfunc writeVarint32(n int32) (int, []byte) {\n\ti32buf := make([]byte, 5)\n\tidx := 0\n\tfor {\n\t\tif (n & ^0x7F) == 0 {\n\t\t\ti32buf[idx] = byte(n)\n\t\t\tidx++\n\t\t\tbreak\n\t\t\t// return;\n\t\t} else {\n\t\t\ti32buf[idx] = byte((n & 0x7F) | 0x80)\n\t\t\tidx++\n\t\t\tu := uint32(n)\n\t\t\tn = int32(u >> 7)\n\t\t}\n\t}\n\treturn idx, i32buf\n}\n```\n\n也因為這種方式一次只能傳輸 7 個 bits 的真實資料，因此一個 32bits 的整數是有可能要花費 5 個 bytes 才傳完的（不過要在數字很大的時候）。\n\n# 總結\n\nZigZag 在處理有號整數的壓縮是非常精妙的，在實作中也僅僅使用不到百行的程式碼就可以完成。\n\n也因此 Thrift、Protobuf 和 Arvo 這三大 binary encoding libraries 都有透過 ZigZag encoding 做有號整數壓縮來減少傳輸的量。\n\n全部的實作在這裡，有興趣的讀者可以自己替換數字跑跑看。\n\n```go\npackage main\n\nimport \"fmt\"\n\nfunc int32ToZigZag(n int32) int32 {\n\treturn (n << 1) ^ (n >> 31)\n}\nfunc zigZagToInt32(n int32) int32 {\n\treturn int32((uint32(n) >> 1)) ^ -(n & 1)\n}\n\nfunc writeVarint32(n int32) (int, []byte) {\n\ti32buf := make([]byte, 5)\n\tidx := 0\n\tfor {\n\t\tif (n & ^0x7F) == 0 {\n\t\t\ti32buf[idx] = byte(n)\n\t\t\tidx++\n\t\t\t// p.writeByteDirect(byte(n));\n\t\t\tbreak\n\t\t\t// return;\n\t\t} else {\n\t\t\ti32buf[idx] = byte((n & 0x7F) | 0x80)\n\t\t\tidx++\n\t\t\t// p.writeByteDirect(byte(((n & 0x7F) | 0x80)));\n\t\t\tu := uint32(n)\n\t\t\tn = int32(u >> 7)\n\t\t}\n\t}\n\treturn idx, i32buf\n}\n\nfunc main() {\n\tfmt.Println(int32ToZigZag(1337)) // 2647\n\n\tfmt.Println(zigZagToInt32(2674)) // 1337\n\n  l, b := writeVarint32(2674)\n  for i := 0; i < l; i++ {\n    fmt.Printf(\"%08b \", b[i]) // 11110010 00010100\n  }\n  fmt.Println(\"\")\n}\n```\n\n# 參考資料\n\n- [Thrift Compact protocol encoding](https://github.com/apache/thrift/blob/master/doc/specs/thrift-compact-protocol.md)\n- [Thrift Compact protocol encoding implementation in Golang](https://github.com/apache/thrift/blob/master/lib/go/thrift/compact_protocol.go)\n- [Protocol Buffers encoding - Signed Integers](https://developers.google.com/protocol-buffers/docs/encoding#signed_integers)\n- https://blog.csdn.net/zgwangbo/article/details/51590186\n\n> 最後，如果你喜歡這篇文章，或是文章對你有幫助的話，可以幫我按個喜歡、或是留言！你的支持就是我寫作的最大動力。有任何想問的問題也可以在底下留言喔～\n","categories":["Others"]},{"title":"Designing Data-Intensive Application 第四章筆記","url":"/Designing-Data-Intensive-Application-第四章筆記/","content":"\n應用程式是不會永恆不變的，隨著新的 features 加入資料的儲存格式可能改變。因此本章節主要探討第一章節中\b所提到的 maintainability 中的 **evolvability**。\n\n在 relational database 中，通常需要更新 schema；而在 schemaless database 中，新舊版本的資料格式可以同時存在。\n\nApplication code 也會因為資料格式的改變而有所變化，但是在大型應用程式中，做到瞬間的版本更新是不可能的：\n\n- Server side applications：通常會執行 **rolling upgrade**，因此新舊版本的程式會通時運作。\n\n\t{% note info %}\n\t#### Rolling Upgrade\n\n\t透過逐漸部署新版本到 server，確認新版本正常運作後，才逐漸移除舊版本的部署，以達到 zero-downtime 的版本升級。\n\t{% endnote %}\n\n- Client side applications：是否更新取決於使用者，因此會同時擁有多種版本在運作。\n\n以上兩點就說明了在軟體開發中，相容性的重要性。相容性包含兩個方向：\n\n- **Backward compatibility（向下相容）**：新的程式碼可以讀舊的資料。\n- **Forward compatibility（向上相容）**：舊的程式碼可以讀新的資料。\n\n本章節會討論在 JSON、XML、Protocol Buffers、Thrift、Arvo 這些資料格式下的相容性問題，以及在 REST、RPC、Message Queue 下如何使用這些資料格式傳輸資料。\n\n![](/assets/Designing-Data-Intensive-Application-第四章筆記/data_formats.jpeg)\n\n<!-- More -->\n\n# Formats for Encoding Data\n\n資料在程式中以 objects、structs、lists、hash tables、trees 等格式儲存在 memory 中，這些資料結構經常透過 pointers 來存取資料。但是透過網路傳輸資料時，這些資料必須轉換成 sequences of bytes（例如 JSON）。\n\n<strong>這種從 in-memory 結構轉換到 byte sequence 的過程叫做 *encoding*、*serialization* 或是 *marshalling*；反過來則叫 *decoding*、*deserialization* 或是 *unmarshalling*。</strong>\n\n## Language-Specific Formats\n\n一些 programming language 有自己的 encoding 方式，例如 Java 中的 `java.io.Serialiable`。使用這些 encoding 很方便，但是可能有以下問題：\n\n- Language-specific encoding 通常只能在一個 langauge 使用，要使用其他 language 讀取是很困難的。\n- 這些 encoding 通常不支援資料的上下相容。\n\t\n\t{% note info %}\n\t#### Golang gob library\n\n\tGolang 內建的 encoding `gob` 可以自動忽略 `struct` 中新增或是刪除的欄位，可以做到一些上下相容。\n\n\t例如 encode 端的結構長這樣：\n\t```go\n\tstruct { A, B int } // encode\n\t```\n\n\t在 decode 端以下情況都是被允許的：\n\t```go\n\tstruct { A, B int, C string } // new field\n\tstruct { A int } // missing field\n\t```\n\n\t{% endnote %}\n\n## JSON, XML and Binary Variants\n\n接著介紹一些標準的 encoding 方式，例如 JSON、XML、CSV。他們被設計成 human-readable 的格式，被大多數的語言支援，並且被廣泛的使用，但是也有一些各自的問題存在：\n\n- XML、CSV 無法區分數字以及只包含數字的字串；JSON 無法區分整數以及浮點數。\n- XML、JSON 都不支援 **binary encoding**。\n\n但這些問題依然不影響 JSON、XML 或是 CSV 在資料交換上的使用（尤其是跨機構的），**因為他們被廣泛的支援以及認可，這比起效能或是格式的問題還要重要**。\n\n### Binary encoding\n\n上面有提到，XML 與 JSON 都不支援 **binary encoding**，但是在跨機構的資料交換上面，被廣泛使用以及支援的格式比起效能或格式問題更重要。反之，在機構內自己使用，就可以多去考慮效能的問題。\n\nJSON 雖然比 XML 好，但是比起 binary encoding format 還是多使用了很多空間\b，因此出現了一些 JSON binary encoding 的實作，例如 [MessagePack](https://msgpack.org/)、[BSON](https://docs.mongodb.com/manual/reference/bson-types/)、[BJSON](http://bjson.org/) 等等。\n\n舉例來說，原本的 JSON 資料如下：\n\n```json\n{\n\t\"userName\": \"Martin\",\n\t\"favoriteNumber\": 1337,\n\t\"interests\": [\"daydreaming\", \"hacking\"]\n}\n```\n\n扣除掉空白字元以及換行後，一共使用 81 個字元。\n\n```javascript\nconst s = '{\"userName\":\"Martin\",\"favoriteNumber\":1337,\"interests\":[\"daydreaming\",\"hacking\"]}';\nconsole.log(s.length); // 81\n```\n\n而 MessagePack encode 過後的結果如下：\n![MessagePack](/assets/Designing-Data-Intensive-Application-第四章筆記/message_pack.png)\n\n一共只使用 66 個字元。\n\n{% note %}\n\t#### 補充關於 MessagePack 編碼方式\n\n\t[MessagePack encoding](https://github.com/msgpack/msgpack/blob/master/spec.md)\n\n\t- MessagePack 用二進位 `1000xxxx` 代表 JSON Object，其中 `xxxx` 代表 object 的 keys 數量，因此可以看到第一個編碼為 83 (`10000011`)，代表是一個 JSON Object 包含 3 個 keys。\n\t\t那如果 keys 數量超過 15 個呢？則會使用 `0xde`（有小於 2^16 個 keys）或是 `0xdf`（有小於 2^32 個 keys）當作第一個編碼字元，再接著 keys 的長度。\n\t\t[MessagePack encoding - Map format](https://github.com/msgpack/msgpack/blob/master/spec.md#int-format-family)\n\t\n\t- MessagePack 對小於 2^7 的無號正整數使用 `0xxxxxxx` 編碼、對於小於 2^5 的有號整數使用 `111xxxxx` 做編碼，其中 `x` 的部分代表數字，這兩種都只使用了一個 byte 做編碼。另外對於小於 8bits、16bits、32bits、64bits 的整數與正整數都用一個不同 first byte 做區別，分別使用 2、3、5、9 個 bytes。\n\t\t[MessagePack encoding - Integer format](https://github.com/msgpack/msgpack/blob/master/spec.md#int-format-family)\n\n\t- MessagePack 對於不同長度的 string 也對不同長度範圍的字串使用不同的 first byte 來編碼。\n\t\t[MessagePack encoding - String format](https://github.com/msgpack/msgpack/blob/master/spec.md#str-format-family)\n{% endnote %}\n\n## Thrift and Protocol Buffers\n\nThrift 和 Protocol Buffers（protobuf）都是開源的 binary encoding libraries，他們都必須透過 schema 先定義好資料的格式才能做 encoding。\n\n### Thrift\n\nThrift 的 schema 定義如下：\n\n```thrift\nstruct Person {\n\t1: required string userName,\n\t2: optional i64 favoriteNumber,\n\t3: optional list<string> interests\n}\n```\n\n而 protobuf 的 schema 定義如下（作者這裡提供的是 proto2 的語法，在 proto3 `required` 與 `optional` 已經棄用）：\n```protobuf\nmessage Person {\n\trequired string user_name       = 1;\n\toptional int64  favorite_number = 2;\n\trepeated string interests       = 3;\n}\n```\n\n透過 schema 的定義，Thrift 和 Protobuf 都透過 code generation 工具來生成 schema 在不同語言的實作，包含可以儲存 data 的 in-memory 格式（golang struct、jave class 等）以及 encoding 和 decoding 的函數。\n\nThrift 有兩種 encoding 模式，分別是 *BinaryProtocol* 與 *CompactProtocol*。\n\n![Thrift - binary protocol](/assets/Designing-Data-Intensive-Application-第四章筆記/thrift_binary_protocol.png)\n\nThrift 在使用 BinaryProtocol 時，只使用了 59 bytes，相較於 MessagePack 的 65 bytes 又少了一些。\n\n**可以發現使用 schema 後，優勢在於不需要像 JSON、XML 的 encoding 一樣儲存 key name（例如 `userName`），轉而儲存 field tag。也因此不管是 Thrift 還是 Protobuf，都可以看到每個 key 都會有一個 unique 的 field tag。**\n\n![Thrift - compact protocol](/assets/Designing-Data-Intensive-Application-第四章筆記/thrift_compact_protocol.png)\n\nThrift 使用 CompactProtocol 甚至只需要 34 bytes 就可以儲存相同的資料。可以發現在 CompactProtocol 做了這些空間優化：\n\n- 把 field tag 跟 field type encode 在同一個 byte 內。\n- 關於整數的部分（包含表示字串長度的整數），使用了 zig-zag 整數壓縮，再透過 Base 128 Varint 的方式傳輸。\n\n\t{% note info %}\n\t#### ZigZag 與 Base 128 Varint\n\n\t這裡作者給的 schema 中，`favorite_number` 是 `int64` 有號整數，根據 [Thrift 提供的 spec](https://github.com/apache/thrift/blob/master/doc/specs/thrift-compact-protocol.md#integer-encoding)，`int32` 與 `int64` 都會做 zig-zag encoding。所以 1337 的部分編碼過後應該是 `11110010 00010100` 才對。\n\n\t關於 ZigZag 整數壓縮與 Base 128 Varint 的詳細介紹，可以看筆者的另一篇 blog：[神奇的整數壓縮算法-ZigZag](/神奇的整數壓縮算法-ZigZag)。\n\t{% endnote %}\n\n### Protocol buffers\n\n![Protobol buffers](/assets/Designing-Data-Intensive-Application-第四章筆記/protobuf.png)\n\n基本上 Protocol Buffers 的 encode 方式與 Thrift 中的 CompactProtocol 類似，特別注意兩點：\n\n- [Protobuf 的文件](https://developers.google.com/protocol-buffers/docs/encoding#signed_integers)中有提到如果使用的是 `int32` 或是 `int64` 類型的話，負數都會使用完整的 10 個 bytes，只有在選擇 `sint32` 或是 `sint64` 這兩種 signed types 時才會使用 zig-zag encoding，會有更好的壓縮率。\n- 不管是 `required` 或是 `optional` 都不會對 encode 後的 data 產生影響，`required` 跟 `optional` 的作用只有 runtime 時的檢查而已。也因為 `required` 與 `optional` 在 schema evolution 時造成不便（下面會介紹到），因此 protocol buffers 3 時 `required` 與 `optional` 都被移除。\n\t[Why required and optional is removed in Protocol Buffers 3?](https://stackoverflow.com/a/31814967)\n\n### Field tags and schema evolution\n\n每次的 schema change 都稱作 *schema evolution*，field name 是可以更改的，但是 field tag 不能更改。\n\n- Forward compatibility（舊版本可以相容新版本資料）：\n\t- 可以增加新的 field，因為舊版本可以直接 omit 不認識的 field tag。\n\t- 可以刪除 optional 的 field，一個 `required` 的 field 不能被移除。刪除一個 `required` 的 field 會讓舊版本 code 讀到新版本資料時因為該 field 不存在而報錯。\n\n- Backward compatibility（新版本可以相容舊版本資料）：\n\t- 可以增加新的 field，但是不能增加 `required` 的 field。增加一個 `required` 的 field 會讓新版本 code 讀到舊版本資料時因為該 field 不存在而報錯。\n\t- 可以刪除一個 field，因為新版本會直接 omit 不認識的 field tag。\n\n刪除一個 field 後，該 field tag 也不能再被使用，因為可能還有舊的資料是使用者個 field tag 的。\n\n### Datatypes and schema evolution\n\n對於同樣的 field，一些資料型態的轉變是 ok 的：\n\n- 從 int32 變成 int64 對於新版本程式是沒有問題的，但是舊版本程式若讀到 int64 的資料就會遺失高位的 bits。\n- 在 protobuf 中使用 `repeated` 作為 array type，而實際上被 encode 時可以看到只是相同的 field tag 出現多次而已，因此在 protobuf 中把 `optional` 轉成 `repeated` 是可以的。新版本可以讀到舊的資料，而舊版本只會讀到 list 中的最後一筆資料。而在 thrift 中有 list 的 type，因此是無法做轉變的。\n\n## Arvo\n\nApache Arvo 是另一種與 Thrift 和 Protocol Buffers 不太一樣的 binary encoding 格式。Arvo 也使用 schema，有比較適合人類使用的 Arvo IDL 與比較適合程式使用的 JSON 格式：\n\n```arvo\nrecord Person {\n\tstring userName;\n\tunion { null, long } favoriteNumber = null;\n\tarray<string> interests;\n}\n```\n\n```json\n{\n\t\"type\": \"record\",\n\t\"name\": \"Person\",\n\t\"fields\": [\n\t\t{\"name\": \"userName\", \"type\": \"string\"},\n\t\t{\"name\": \"favoriteNumber\", \"type\": [\"null\", \"long\"], \"default\": null},\n\t\t{\"name\": \"interests\", \"type\": {\"type\": \"array\", \"items\": \"string\"}}\n\t]\n}\n```\n\n![Arvo](/assets/Designing-Data-Intensive-Application-第四章筆記/arvo.png)\n\n可以注意到 Arvo 沒有 tag number，並且 Arvo 在 encode 時也不會儲存 field name，所以 encode 和 decode 時 schema 需要匹配才能使用。\n\n### The writer's schema and the reader's schema\n\nEncode 與 decode 可以使用不同 schema，但 decode 時必須擁有當時 encode 用的 schema。而 decode 端的 schema 稱為 *reader's schema*，當時 encode 所使用的 schema 稱為 *writer's schema*。\n\n![Arvo reader's and writer's schema](/assets/Designing-Data-Intensive-Application-第四章筆記/arvo_reader_writer_schema.png)\n\n可以看到透過比對 field name，decode 時可以使用與 encode 不同的 schema。例如 writer's schema 中有 reader's schema 中不存在的 field `photoURL`，則 reader 忽略此欄位；或是 reader's schema 中有 writer's schema 中不存在的 field `userID`，則使用預設值。\n\n### Schema evolution rules\n\nArvo 中：\n\n- Forward compatibility：舊版本 reader's schema 與新版本 writer's schema。\n- Backward compatibility：新版本 reader's schema 與舊版本 reader's schema。\n\n要同時滿足兩種相容性，只能新增或刪除有 default value 的值。\n\n### But what is the writer's schema\n\n那麼 writer's schema 會儲存在哪裡呢？根據 Arvo 常被使用的情境，有以下幾種例子：\n\n- File：常被使用在 Hadoop 中，Hadoop 是大型檔案系統。因此 writer's schema 可以直接被寫在檔案的 header 中。\n- Database：在 database 中，每個 rows 可以多儲存一個 version number，再透過 version number 關聯出寫入時的 writer's schema。\n- Network：透過網路傳輸的話，可以透過 RPC 的方式。\n\n### Dynamically generated schemas\n\nArvo 與 Thrift 或是 Protocol Buffers 最大的不同在於 Arvo 適合做 *dynamically generated schema*，而 Thrift 或是 Protocol Buffers 因為有 tag number 要小心不能重複使用到，因此通常只能手動修改 schema。\n\n## The Merits of Schemas\n\n總結來說有 schemas 帶來以下的好處：\n- 有更好的壓縮率，因為不需要儲存 field name。\n- 本身就是有價值的文件，因為 schema 必須跟著 code 一起被版本更新。\n- 維護一個 schemas 的資料庫，可以讓開發者在部署之前確認所有的相容性。\n- 對於 statically typed programming languages 來說，code generation 可以幫助編譯期間的 type checking。\n\n# Modes of Dataflow\n\n接著介紹三種類型的 Dataflow：\n\n- Via databases\n- Via services\n- Via asynchronous message passing \n\n## Dataflow Through Databases\n\n資料進出資料庫時也需要做 encode 和 decode，因此也要考慮相容問題。\n\n假設新版本新增了一個 field，並且寫了一筆資料到資料庫。而舊版本程式讀到這筆資料後，選擇 omit 不認識的 field，再更新回資料庫，那麼這個新的 field 上面的值就會遺失。\n\n要避免這種情況，可以指定要更新的 fields 而不是一次更新整筆資料（Relational database 中 ORM 的 Save 通常就是更新一整筆資料，可以透過 Update 來更新需要的欄位就好）。\n\n## Dataflow Through Services: REST and RPC\n\n當資料傳輸需要透過 network，server 通常會暴露 API 在網路上，client 可以透過 API 向 server 拿取或是送出資料。而 client 可能也是一個 server 的角色，這種 pattern 被稱作 *service-oriented architecture (SOA)*，或是被稱作 *microservices*。*Microservices* 的主要目的之一就是讓每個 services 都可以獨立部署和更新，因此相容性在 API 設計上也是很重要的。\n\n### REST\n\nWeb services 主要透過 REST 來設計 API，這種類型的 API 被稱作 RESTful API。\n\n[REST](https://zh.wikipedia.org/wiki/%E8%A1%A8%E7%8E%B0%E5%B1%82%E7%8A%B6%E6%80%81%E8%BD%AC%E6%8D%A2) 是基於 HTTP 的一種設計方式，使用 URI 來辨識資源，對於資源的操作包含取得、建立、修改和刪除，恰好對應到 HTTP 的 `GET`、`POST`、`PUT` 和 `DELETE`方法。\n\n在版本更新時，若無法做到相容，RESTful APIs 通常透過 URI 中的 version number 來提供多版本的 APIs。\n\n### RPC\n\n早期的 RPC 設計希望網路的請求使用起來跟呼叫 local function 很像，但其實這很難做到，因為有以下的差別：\n\n- Local function 是可預期結果的，RPC 可能因為 network issue 有很多無法預期的結果（例如遺失、等待很久才回應...）。\n- RPC 在遇到 error 時可以重試，但是上一次的結果可能是成功的，只是沒有成功回應結果。重試就要避免一些無法重複執行的請求重複執行。\n- Local function 每次執行時間差不多；RPC 每次執行時間可能被 network latency 影響而差別很大。\n- Local function 可以使用 pointers 或是 references；RPC 需要將參數轉換成 sequence of bytes。\n\n雖然 RPC 有上面提到的這些問題，但是新型的 RPC frameworks 並沒有就此沒落，例如 Google gRPC。因為這些新型的 RPC frameworks 更明確的區分 RPC 並不是一種 local function call，例如 [Finagle](https://twitter.github.io/finagle/) 提供 `futures` 來封裝可能失敗的請求。\n\ngRPC 使用 protocol buffers encoding，比起 REST JSON 有更好的效能。但是缺點在於不易 debug 與實驗，因為 RPC 測試通常需要透過程式或是 code generation 工具。\n\nRPC 中若使用 Thrift 或是 Protocol Buffers，則可以依照 schema evolution 的規則來做到上下相容。\n\n## Message-Passing Dataflow\n\nREST & RPC 都透過網路傳遞訊息並期望在短時間得到回應。\n\n*Asynchronous message-passing systems*，透過將資料送到一個中介的 *message-broker (message queue, MQ)* 暫時儲存，再轉傳給其他服務。使用 message queue 有以下的優點：\n\n- 如果接收者暫時無法回應，資料可以緩存在 MQ 裡面，提高可用性。\n- 如果資料沒有送到 MQ 可以幫助重送訊息，做到 at-least-once delivery。\n- 可以讓 senders 不需要知道 receivers 的位置、receivers 也不需要知道 senders 的位置。將兩邊的邏輯分開，senders 只需要專注在送出的訊息，而 receivers 只需要專注在訂閱並處理接收到的訊息。\n- 可以透過篩選或是訂閱將訊息送給多個 receivers。\n\n一些企業級、著名的 Message Queue 包括 RabbitMQ、NATS 以及 Apache Kafka。\n\n# Summary\n\n本章節介紹了各種常見的 encoding formats，提出他們在效能上的不同，以及對於系統架構與相容性的影響。\n\n- Programming language-specific formats：通常只限於一種語言中使用，並且通常不能做到相容性。\n- Texture formats：例如 JSON、XML，這些格式通常對型態的定義很模糊，使用時要特別注意。\n- Binary schema-driven formats：例如 Thrift、Protocol Buffers，這些格式能將資料壓縮的更小，並且提供上下相容的能力。另外 schema 本身能夠產生文件，但是壞處是 encoding 後的結果不是 human-readable 的。\n\n另外介紹了三種 dataflow：\n\n- Databases：寫的 process encode 資料，讀的 process decode 資料。\n- RPC and REST APIs：Server 端 encode 資料，client 端 decode 資料。\n- Asynchronous message passing：Sender 端 encode 資料，receiver 端 decode 資料。\n\n最後，不管哪種 dataflow，不管是 server-side 還是 client-side 應用，都會有上下相容的問題，更新應用時多注意相容性問題，應用就可以頻繁的更新與部署了。\n\n> 最後，如果你喜歡這篇文章，或是文章對你有幫助的話，可以幫我按個喜歡、或是留言！你的支持就是我寫作的最大動力。有任何想問的問題也可以在底下留言喔～\n","tags":["Notes","DDIA"],"categories":["Notes"]},{"title":"Designing Data-Intensive Application 第三章筆記","url":"/Designing-Data-Intensive-Application-第三章筆記/","content":"\n本章節首先介紹資料庫的 storage engine 是如何儲存資料，使得查詢可以變得更快速。並介紹兩種常被資料庫使用的資料結構 *LSM-Tree* 以及 *B-Tree*。\n\n再來淺談一般用於網路服務的資料庫與資料分析用的資料庫的設計理念有什麼不同。\n\n最後介紹較不常見的 *column-oriented database* 的優缺點、設計以及使用情境。\n\n![image source: https://www.omnisci.com/technical-glossary/columnar-database](/assets/Designing-Data-Intensive-Application-第三章筆記/column_vs_row_db.png)\n\n那身為資料庫的使用者，為什麼需要知道資料庫的 storage engine 是如何設計的呢？除了要選出最適合的資料庫之外，為了要對資料庫性能進行調校，也必須了解資料庫底層是如何儲存資料的，才能根據使用情況做出最好的選擇。\n\n<!-- More -->\n\n# Data Structures That Power Your Database\n\n這整個段落會以一個簡單的 key-value 資料庫來討論儲存資料的方式。\n\n這個資料庫必須支援兩種最基本的操作：\n\n- `set(k, v)`：把 key `k` 設成值 `v`。\n- `get(k)`：查詢 key 為 `k` 的值。\n\n首先最簡單的做法即每次 `set(k, v)` 時將一筆 log 插入到檔案的最後一行。查詢 `get(k)` 時可以透過 sequence scan 在檔案中用 $O(N)$ 的時間找到紀錄。\n\n當然一般的資料庫並不會這樣設計，因為還必須考慮效能、儲存空間、並發等問題，但是寫 log 在資料庫中是很常見的行為。\n\n`O(N)` 的查詢不是很有效率，資料庫通常會通過 *index* 來加快查詢的速度，index 的設計即是透過儲存一些額外的資訊來幫助快速的查找資料，因此不同的查詢通常就需要不同的 index。\n\n雖然**好的 index 可以提升查詢的速度，但是每個 index 都會降低寫入的速度**，因此身為一個好的工程師要也要對 index 的選擇做出好的決定。\n\n## Hash Indexes\n\n我們可以透過 in-memory hash table 將 key 對應到其真正在檔案的 byte offset，如此一來就可以在 $O(1)$ 的時間找到 key 的位置，再透過 disk IO 直接讀取資料；並且只要在 `set(k, v)` 時只要順便更新 hash map 即可。\n\nHash index 也有一些限制，例如：\n- Hash table 要被整個放進 memory 才能有好的效能，所以資料過多時 memory 可能不夠用。\n- 不能做範圍的查詢，例如 key 是時間戳的話，hash index 沒有辦法指定查詢一段時間內的資料。\n\n![](/assets/Designing-Data-Intensive-Application-第三章筆記/hashmap.png)\n\n另外，為了避免不斷插入資料造成檔案無限增大，通常可以做兩件事情：\n\n1. Segment：每當檔案達到一定的大小，就寫到一個新的檔案（segment file）。\n2. Compaction：對於相同的 key，可以只保留最新的紀錄。做完 compaction 後 segment 的大小會變小，因此也可以同時做 merge segment + compaction。\n\n有多個檔案後，每個 segment 都必須維護一個 in-memory hash table，`get(k)` 時從最新的檔案開始尋找，因為有做 merge segment 的操作，所以可以避免檔案數量過多。\n\n![](/assets/Designing-Data-Intensive-Application-第三章筆記/merge_segment_compaction.png)\n\n上述的做法在 [Bitcask](https://en.wikipedia.org/wiki/Bitcask)，一個快速的日誌型鍵值資料庫中被使用。但是實務上還有幾個問題要處理：\n\n- File format：可以先 encode 字串成 bytes 再儲存，會更加有效率。\n- Deleting records：可以在 log 中紀錄一個特別的刪除紀錄，讓 merge segment 時可以知道 key 不被保留。\n- Crash recovery：如果資料庫重啟，所有 in-memory hash table 都會不見。可以透過從頭讀取 segment files 來恢復 hash table，但是會花很久的時間。實際上可以透過定期的對 hash table 進行 snapshot 來快速的恢復資料庫。\n- Partially written records：資料庫隨時都有可能重啟，重啟可能造成寫到一半的 log，透過 checksum 可以偵測到錯誤的 log 並忽略。\n- Concurrency control：只能有一個寫入線程，但是可以有多個讀取線程。\n\n## SSTables and LSM-Trees\n\n先不考慮如何做到，假設要求寫入 segment files 時，所有的紀錄必須 *sorted by key*，並且相同的 key 只出現一次，這樣的格式就稱作 *Sorted String Table* 或是簡稱 *SSTable\b\b\b*。如此一來可以得到幾個好處：\n\n- Merge segment files + compaction 變得更簡單，可以透過類似 *mergesort* 合併時的方式來合併檔案（利用多個指標指向檔案的頭，每次挑最小的 key 出來將紀錄加入到新的檔案，並將該指標向後移動一格）。並且當 key 相同時，可以只保留較新檔案內的紀錄即可。\n- 可以做 sparse hash table，只儲存部分的 key 在 in-memory hash table 中，`get(k)` 時只要查到 `k` 在 hash map 中的上一個＆下一個 key，即可以確認 `k` 出現的範圍。如此一來就可以避免 hash table 超過 memory 大小上限的問題。\n\t![](/assets/Designing-Data-Intensive-Application-第三章筆記/sstable_sparse_index.png)\n- 可以做 range query，因為檔案是根據 key 排序的，所以可以一次將某個 key range 內的紀錄讀出。\n\n### Constructing and maintaining SSTables\n\n所以現在來探討如何做到強制 segment files 內的所有紀錄必須 *sorted by key*。\n\n透過 in-memory 的自平衡二元搜尋樹，例如 [*AVL樹*](https://zh.wikipedia.org/zh-tw/AVL%E6%A0%91) 或是 [*紅黑樹*](https://zh.wikipedia.org/wiki/%E7%BA%A2%E9%BB%91%E6%A0%91)，我們可以很簡單的在 memory 維護一個可查詢、可插入，並且很有效率的資料結構。\n\n透過這樣的資料結構，可以將處理資料的流程改為：\n\n- `set(k, v)` 時，直接插入到 in-memory 的資料結構中，通常這種 in-memory tree 叫做 *memtable*。\n- 當 memtable 超過一定大小時，可以在 $O(N)$ 的時間依照 key 的排序遍歷整個 memtable，將資料寫入到新的 SSTable segment file 中。當 SSTable 正在寫入時，所有的 `set(k, v)` 都寫入到新的 memtable 以避免 concurrency 的問題。\n- `get(k)` 時，先找 memtable，再找最新的 SSTable，再找次新的 SSTable ... 以此類推。\n- 定期的在背景執行 merging & compaction。\n\n這種方式唯一的問題是當資料庫重啟時，memtable 內的資料會全部不見。爲了維護 durability，可以透過另外的 log 紀錄 `set(k, v)`，僅作為 recovery 時恢復 memtable 使用，因此當 memtable 的資料確認寫入 SSTable 後，相對的 log 即可刪除。\n\n### Making an LSM-tree out of SSTables\n\nLSM-Tree 一詞最早出現，指的是使用 log-structured，並且使用 merging 和 compaction sorted files 的 storage engine。\n\n因此 SSTables 其實是 LSM-Trees 的一種實作，最早在 [Google Bigtable 的論文](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/68a74a85e1662fe02ff3967497f31fda7f32225c.pdf) 中出現，後來被使用在 LevelDB、RocksDB、[Cassandra](https://cassandra.apache.org/doc/latest/cassandra/architecture/storage_engine.html) 和 [HBase](https://hbase.apache.org/book.html#_hfile_format) 等資料庫中。\n\n### Performance optimizations\n\n查詢不存在的 key 必須遍歷 memtable 以及所有的 SSTables，可能會很花時間。可以透過 Bloom filter，一個空間、時間效率極佳，可以用於判斷一個值是否存在的資料結構，缺點是無法做刪除，以及有機率將不存在的資料誤判成存在。\n\n另外，在 compaction strategy 方面，主要分為 [*sized-tiered*](https://docs.scylladb.com/kb/compaction/#size-tiered-compaction-strategy-stcs) 與 [*leveled-tiered*](https://docs.scylladb.com/kb/compaction/#leveled-compaction-strategy-lcs) 兩種方式，在 [ScyllaDB 的文檔](https://docs.scylladb.com/kb/compaction/#compaction)中有很詳細的介紹各種 compaction 方式，這裡就不多提了。\n\n## B-Trees\n\n再來介紹最常被資料庫使用的 index *B-Tree*。\n\nB-Trees 與 SSTables 一樣將資料排序儲存，但是 B-Trees 不像 SSTables 儲存不定大小的檔案，而是將資料（每一個 b-tree 節點）儲存進 fixed-size 的 blocks/pages 中，每次都以一個 page 為單位進行讀寫，因此更符合硬碟的設計。\n\nB-Tree 是一種自平衡的樹，先介紹 B-Tree 的一些性質：\n- 每一個非葉節點會儲存一些 sorted 的 keys，每個節點最多儲存 $m$ 個 keys，可以分隔出 $m+1$ 個區間，每個區間會有一個 reference pointer 指向子節點。通常 $m+1$ 會被稱作 b-tree 的分支因子（branching factor）。\n\t![](/assets/Designing-Data-Intensive-Application-第三章筆記/b-tree.png)\n- 所有的葉節點都在同樣的高度，儲存真正的值。\n- 除了根之外的非葉節點都至少有 $\\lceil m/2\\rceil-1$ 個 keys，而根節點最少只要有 $1$ 個 key。\n\n查詢 `get(k)` 時，從 b-tree 的根開始可以透過排序的 key 來確定資料是存在哪一個子節點中，一直到 b-tree 的葉節點就可以找到資料真正的位置。\n\n`set(k, v)` 時：\n- 若 `k` 已存在，只要找到儲存位置再覆蓋掉 value 即可。\n- 若 `k` 不存在，先找到 key 對應的葉節點，再將新的值插入到葉節點即可，但若葉節點空間不足，取葉節點中間的 key 出來，將葉節點分成兩半儲存到兩個新的 page 上，再將中間的 key 插入到上層節點即可，並更新兩個指標指到兩個新的葉節點。當然，如果上層節點空間也不夠，就會再做一次 split & update parent node 的動作。\n\t![](/assets/Designing-Data-Intensive-Application-第三章筆記/b-tree_growing.png)\n\nB-tree 的 branching factor 通常會是幾百，因此可以讓樹的高度維持在 3 ~ 4 層，從而加快存取速度（一個 4 層、4KB Page、branching factor 500 的 b-tree 可以儲存超過 256TB 的資料）。\n\n### Making B-trees reliable\n\n一個 transaction 可能同時對多個 pages 進行寫入，若斷電可能會造成寫入不完全的狀況。因此通常會透過 *write-ahead log*（WAL），在修改執行之前先紀錄一筆修改的 log，以便在 recovery 的時候進行 undo/redo。\n\n## Comparing B-Trees and LSM-Trees\n\n最後做一些 B-trees 和 LSM-trees 的比較：\n\n- LSM-trees 通常寫入較快；B-trees 通常讀取比較快。\n- LSM-trees 通常比較節省空間；B-trees 會有 internal fragmentation，造成一些空間浪費。\n- LSM-trees 的 throughput 不穩定，當 merging + compaction 時可能會佔據其他 queries 要使用的 I/O Bandwidth；相對來說 B-trees 就較為穩定。\n- LSM-trees 的 key 可能會出現在多個檔案中；而 B-tree 的 index 只會出現在一個位置，對於資料庫來說比較好做 transaction 時 lock 的 implementation。\n\n## Other Indexing Structures\n\n上面討論的都是以 primary key 當作 index 的做法，通常為了其他常用的查詢也會在其他的 column 上面建立 *secondary indexes*，可以透過 SQL 的 `CREATE INDEX` 建立。\n\n### Storing values within the index\n\n在 B-tree 的葉節點中，儲存的值可以是 row 真正的資料，也可以是指向 row 儲存位置的參照，而真正儲存資料的位置通常叫做 *heap file*。在有多個 secondary indexes 的情況下，使用 heap file 可以避免重複資料。\n\n更新資料時，只要更新 *heap file* 的值即可。但如果更新的 value 比原本還大，會造成所有的 reference 都需要移動，這時可以更新所有 index 的參照位置，或是在原本參照的位置再留一個新的位置參照。\n\n直接儲存 row 真正得資料的方式叫做 *clustered index*，反之叫做 *non-clustered index*。\n\n### Multi-column indexes\n\n如果查詢的條件包含多個欄位，這時只有一個欄位的 index 可能就不夠好。\n\n常見的做法是 *concatenated index*，直接把多個 column 的 key 連接在一起成為新的 key，因此連接是有順序性的。例如 `(lastname, firstname)` 的 index 就無法加速對只有 `firstname` 的查詢，但是可以加速只有 `lastname` 的查詢。\n\n另一種做法在地理資訊較常見，透過多個 column 的 keys 計算成一個獨立的數字，可以對 GEO 的範圍查詢做加速。例如 [R-tree](https://zh.wikipedia.org/wiki/R%E6%A0%91)。\n\n### Full-text search and fuzzy indexes\n\nFull-text search 允許在一篇內文中尋找單詞或是句子，並且忽略文法、單複數、大小寫等等。\n\nElasticSearch 中透過分詞、過濾、文法轉換等過程，將文章 parse 成一個個 token，再做 token 對應到文章的[倒排索引](https://www.elastic.co/guide/cn/elasticsearch/guide/current/inverted-index.html)（inverted index）來達成有效率的 full-text search。\n\n模糊搜尋允許查詢 edit distance 在一定範圍內的所有單詞，也就是對錯字有容錯。\n\n### Keeping everything in memory\n\nRedis 即現在很常見的 in-memory 資料庫，所有的資料都儲存在 memory 裡面，因此可以做到一些在 disk 上面難以實作的資料結構，例如 set 或是 priority queue。\n\n在 memory 最大的好處就是快，但壞處就是沒有 durability。\n\n# Transaction Processing or Analytics\n\n一般交易、社交平台等網路服務都會用 Database 來儲存資料，通常應用程式會面對使用者，常用 key 來查詢一小部分的資料，處理大量的插入與更新。因為這些應用程式通常是互動性的，所以這種 pattern 通常叫做 *online transaction processing*（OLTP）。\n\n相對的，資料庫也越來越常被應用在資料分析上，通常會需要查詢很多筆資料，但是只讀取一小部分的欄位，並且返回 aggregation (count, sum, average) 後的資料。這種 pattern 叫做 *online analytic processing*（OLAP）。\n\n![](/assets/Designing-Data-Intensive-Application-第三章筆記/OLTP_OLAP.png)\n\n## Data Warehousing\n\n一開始一些 OLTP 的資料庫在 OLAP 上也有很好的表現，但是 OLTP 服務通常要求高可用性並且要有好的 performance，而商業分析通常會掃過大量的數據，進而影響其他請求的效能。因此在 1980 ~ 1990 年代，一些比較大型的公司開始把分析用的資料移到獨立的資料庫，通常叫做 *data warehouse*。\n\nData warehouse 包含一些資料副本，通過定期的 dump 或是串流更新，將資料轉換成好用來分析的格式再儲存進分析用的資料庫，這種流程就叫做 *Extract-Transform-Load*（ETL）。一些資料庫也為 data warehousing 而生，例如 Teradata、Vertica、SAP HANA 和 ParAccel。甚至也有適合用在 data warehouse 的 data model，例如 *Star Schema*。\n\n## Stars and Snokeflakes: Schemas for Analytics\n\n*Star schema* 首先將資料分為「事實（fact）」與「維度（dimension）」兩個部分：\n\n- Fact tables：儲存事件，以及任何可以用來分析的數值欄位。例如電商平台的事實資料可以是銷售紀錄，可用於分析的欄位包括價格、數量、時間等。事實資料表通常包含資料欄位以及一些 foreign key 來關聯其他的維度資料。一般而言事實資料表的列數（rows）非常多，並且隨著時間還會繼續成長。事實資料表通常會有很多欄位（columns），通常在上百到上千個不等。\n- Dimension tables：儲存事件的實體，例如商品、銷售員、銷售活動、顧客等詳細資訊。一般而言維度資料表的列數較少。維度資料表也可以有很多欄位用來描述這些實體。\n\n這樣的設計可以將要分析的資料都保留在最中間的事實資料表中，並且可以透過一層的簡單 join 拿到其他與事件相關的資訊，因此 star schema 適合用於資料分析。\n\n![Image source: https://docs.microsoft.com/zh-tw/power-bi/guidance/star-schema](/assets/Designing-Data-Intensive-Application-第三章筆記/star_schema.png)\n\n而 *Snowflake schema* 是 star schema 的一種變體，允許 dimension tables 可以有附屬的 sub-dimension tables。\n\n# Column-Oriented Storage\n\n通常資料分析時會讀很多 rows 以及很少一部分的 columns，而一般在 OLTP 資料庫的 storage engine 都是 *row-oriented* 的，也就是說在 disk 中資料是一個 row 接著一個 row 儲存的。因此在資料分析時，row-oriented 的設計會讓資料庫必須讀出整個 row 的資料到 memory，再去掉不必要的 columns，這可能會浪費掉很多時間。\n\n![](/assets/Designing-Data-Intensive-Application-第三章筆記/row-oriented.png)\n\n因此有 *column-oriented* 的 storage engine 出現，將相同的 column 儲存在一起（通常是每個 column 儲存到獨立檔案），查詢時就可以只將需要的 columns 讀出。要注意各個 column 必須是以一樣的排序方式儲存的，才能夠還原出原本的 rows。例如所有 column 中的第一個值都是對應到同一個 row 的資料。\n\n![](/assets/Designing-Data-Intensive-Application-第三章筆記/column-oriented.png)\n\n另外，Cassandra 和 HBase 都有 column familes 的概念，但並不是 column-oriented。在每個 column family 中資料還是一個一個 rows 儲存的，所以還是算 rows-oriented。\n\n## Column Compression\n\n將 column 儲存在一起可以做 column compression 來節省儲存空間。其中一種常見的方式是 *bitmap encoding*。\n\nBitmap encoding 對每個不一樣的值都用一個 bitmap 來儲存他們在第幾個 row 出現，例如下圖中 `product_sk` 這個 column 中，總共有 6 個相異值，因此就需要 6 個 bitmaps 來儲存。其中 `product_sk=74` 這個數字排在第 5 個，因此就將其 bitmap 中的第 5 個值設為 1。如此一來只要儲存所有的 bitmaps 即可。\n\n而儲存 bitmaps 可以透過 run-length encoding 來節省空間。\n\n![](/assets/Designing-Data-Intensive-Application-第三章筆記/bitmap_encoding.png)\n\n做 bitmap index 在一些 data warehouse 的 query 中也有好的表現，例如：\n\n1. `WHERE product_sk IN (30, 68, 69)`：只要 load `product_sk` 是 30, 68, 69 的 bitmaps 後做 bitwise OR 即可得到結果。\n2. `WHERE product_sk = 31 AND store_sk = 3`，只要 load `product_sk = 31` 以及 `store_sk = 3` 的 bitmaps 後做 bitwise AND 後即可得到結果。\n\n## Sort Order in Column Storage\n\n在 column-oriented store 中 **rows 的儲存順序可以任意，但是每個 columns 都必須是以一樣的方式排序**。\n\n使用者可以根據常用的 query 來決定要根據哪個 column 做排序。例如選擇根據 date key 做排序，則 query optimizer 就可以幫「查詢一段時間內的資料」這樣的查詢做加速。另外如果這個欄位還有做 bitmap index 的話，因為資料已經排序過，所以 bitmap 中的所有 0 跟 1 都會聚集在一起，透過 run-length encoding 後就可以節省非常多的儲存空間。\n\n## Writing to Column-Oriented Storage\n\n使用排序後資料插入會變困難，因為無法在檔案中做插入。這時可以使用 LSM-tree，在 memory 上做寫入與排序，等到一定的大小後與舊的 column files 合併並寫到新的檔案中。這種做法被 Vertica 採用。\n\n## Aggregation: Data Cubes and Materialized Views\n\nDate warehouse 常會使用到一些 aggregation functions 例如 `COUNT`、`SUM`、`AVG`、`MIN` 與 `MAX` 等等，如果一個 aggregation 的結果經常被其他 query 使用，那 cache 住這個結果成為一個 *materialized view*，之後的 query 可以直接在這個 table 上面做 query 以節省時間。\n\n一種在 OLAP 常見的 *materialized view* 叫做 *data cube* 或是 *OLAP cube*，由多個 dimensions 的資料透過 aggregation 後得到，以下是一個 2D 的 OLAP cube。在表上可以快速得到某日的營業額、某月營業額、某商品單月營業額等等資訊。\n\n![](/assets/Designing-Data-Intensive-Application-第三章筆記/OLAP_cube.png)\n\n# Summary\n\n總結來說，本章節的重點在介紹資料庫的各種 storage engine 設計，以及其優缺點。\n\n首先介紹了 OLTP 中兩種常見的儲存方式：\n\n- Log-structured：只能以插入的方式寫檔。檔案透過合併與壓縮的方式來減少儲存空間。SSTables 與 LSM-trees 都是屬於這種類型。\n- Update-in-place：動態的寫入 disk 中的 page。B-trees 是屬於這種類型的，並且 B-trees 被應用在大多數的 relational databases 與很多 non-relational databases 中。\n\n另外以更大的面向將資料庫分成 OLTP 與 OLAP 兩種類型：\n\n- OLTP 通常面向使用者，有較多的 insert 與 update 操作，且使用 key 來存取少量的資料，因此 storage engine 透過儲存 index 來快速的查詢資料。\n- OLAP 通常只在大公司的資料分析用途中出現，query 數量少但每次存取大量資料，透過 column-oriented storage 來減少 disk I/O bandwidth。\n\n身為應用程式的開發者，上述這些內容可以幫助你更好的調校資料庫的 indexing 或是 storage engine，並且在閱讀資料庫文檔時有足夠充足的知識。\n\n> 最後，如果你喜歡這篇文章，或是文章對你有幫助的話，可以幫我按個喜歡、或是留言！你的支持就是我寫作的最大動力。有任何想問的問題也可以在底下留言喔～\n","tags":["Notes","DDIA"],"categories":["Notes"]},{"title":"Designing Data-Intensive Application 第二章筆記","url":"/Designing-Data-Intensive-Application-第二章筆記/","content":"\n本章節主要在介紹目前主流的三個 Data Model，**Relational Model、Document Model 以及 Graph Model** 的優缺點、演進史以及使用時機。\n\nData Model 是一層疊一層的：\n- 在應用層，資料可能是購物車資訊、金流、商品等在現實世界中的資訊。\n- 在後端，我們必須把資料轉換成易於儲存的資料結構，可能是 XML 或 JSON，又或是關聯式資料庫中的 Tables。\n- 在資料庫中，XML、JSON 或是 Tables 都必須轉變成 bytes 的形式，使他們能夠被儲存在 memory 或是 disk 上。\n- 在硬體層，bytes 必須轉換成電流、磁場等等。\n\n層與層透過定義好的 API 來溝通，可以將背後的複雜實作藏在 API 之後。\n\n各種不同的 data model 背後都會一些使用情境的假設，因此每一種 data model 都有不同的功能、操作，對於支援的操作，效能也有好與壞之差別。\n\n也因為要精通一種 data model 是十分困難的（光是 relational data modeling 就有這麼多書籍），因此在使用之前先綜觀的了解每一種 model 的優缺點以及使用時機是非常重要的。\n\n<!-- More -->\n\n# Relational Model Versus Document Model\n\nRelational model 在 1970 年時被提出，在 1980 年代開始被廣泛的使用直到現在。當時與其競爭的還有 network model 以及 hierarchical model，但是後來都被 relational model 主宰，而 relational model 之所以能夠成功主要因為兩點：\n1. 其將複雜的 query 實作藏在 database 本身的 query optimizer 中，提供更乾淨的介面使用，讓開發者不需知道資料是如何被儲存在資料庫中的。\n2. 其解決了當時一個重要的問題：多對多的關聯。\n\n## The Birth of NoSQL\n\nNoSQL 在 2010 年初期走紅，當時 NoSQL 指的是非關聯式、開源、分散式的資料庫。後來轉變成 Not Only SQL。\n\nNoSQL 最主要的推力在：\n- 有更好的 Scalability。\n- 支援一些關聯式資料庫不支援的操作。\n- 可以使用更彈性、更自由的儲存資料結構。\n\n## The Object-Relational Mismatch\n\n稍微介紹完了 Relational Model 跟 Document Model 的出現與歷史，接下來講 Relational Model 最主要遇到的問題：**Object-Relational Mismatch**。\n\n大多數的應用程式開發都是 object-oriented programming，因此在 object 與 table 之間的轉換會遇到困難，幸好現在主流的 database 都有 Object-relational mapping (ORM) 框架的幫助來減少這些轉換的複雜性。但是當原資料就是不太適合放進 table 時，就會遇到困難。\n\n這裡舉履歷為例子（LinkedIn Profile），一個使用者會有一個 unique ID `user_id`，會有姓 `last_name` 與名 `first_name`，這些欄位都是一個值，可以被當作 `users` 表的欄位。\n\n但是一個使用者可能有多個工作、學歷、甚至是聯絡資料，這些一對多的關聯在 relational model 中有幾種處理方式：\n- 將工作、學歷、聯絡資料放到另一張 table 來儲存，這也是最常見的資料庫正規化方式\n- 一些關聯式資料庫支援 Array 或是 JSON 儲存格式，例如 PostgreSQL。\n- 直接將 JSON 或是 XML 格式編碼成 bytes 再儲存進資料庫的一個欄位。\n\n<img src=\"/assets/Designing-Data-Intensive-Application-第二章筆記/linkedin_profile.png\" width=\"70%\" />\n\n履歷的資料就比較適合放在 JSON 格式下，例如：\n```json\n{\n  \"user_id\": 251,\n  \"first_name\": \"Bill\",\n  \"last_name\": \"Gates\",\n  \"summary\": \"Co-chair of the Bill & Melinda Gates... Active blogger.\",\n  \"region_id\": \"us:91\",\n  \"industry_id\": 131,\n  \"photo_url\": \"/p/7/000/253/05b/308dd6e.jpg\",\n  \"positions\": [\n    {\n      \"job_title\": \"Co-chair\",\n      \"organization\": \"Bill & Melinda Gates Foundation\"\n    },\n    {\n      \"job_title\": \"Co-founder, Chairman\",\n      \"organization\": \"Microsoft\"\n    }\n  ],\n  \"education\": [\n    {\n      \"school_name\": \"Harvard University\",\n      \"start\": 1973,\n      \"end\": 1975\n    },\n    {\n      \"school_name\": \"Lakeside School, Seattle\",\n      \"start\": null,\n      \"end\": null\n    }\n  ],\n  \"contact_info\": {\n    \"blog\": \"http://thegatesnotes.com\",\n    \"twitter\": \"http://twitter.com/BillGates\"\n  }\n}\n```\n\n由上面的圖與 JSON 可以看出，JSON 格式有更好的 locality，使用 relational model 就必須使用多次的 Join 來關聯多個資料庫，而 JSON 中所有與此使用者相關的資訊都儲存在一起，一個簡單的 query 就能達成。\n\n## Many-to-One and Many-to-Many Relationships\n\n講完了 relational model 的缺點，再來講 document model 的缺點。\n\n首先，可以發現上面的 JSON 中 region 與 industry 都只儲存了一個 ID，而不是直接儲存字串，這樣做有幾個好處：\n\n- 一致性，避免相同意思但是拼法不同的問題\n- 易於更新，當一個名稱變更時，只需要修改一處的名字\n- 支援多語系，可以透過唯一的 ID 將其翻譯成各個語系的字串\n- 更好的支援搜尋功能\n\n使用 ID 的好處在於 ID 對於人是沒有意義的，因此 ID 永遠不會改變。因此透過 ID 將重複的資料都變成唯一的 row，可以避免更新、刪除時需要更新到多個 rows 的問題，這就是資料正規化的核心想法。\n\n在 relational database 中，多對一的關係很好處理，透過 ID 加上 join 的操作即可。在 document database 中，一對多關聯可以直接的儲存（像 JSON 中的 Array 即是一對多關聯），因此 document model 通常不支援 join 的操作，則可能需要在應用層手動的模擬 join 的操作。\n\n> 在 document model 中，不一定要像 relational model 一樣透過 ID 做多對一的關聯，可以透過 denormalization，直接讓資料重複的出現，例如直接將 JSON 中 `region_id` 直接用 `region` 的 object 取代。好處是不需要再有 join 的操作，壞處當然就是喪失上面提到只儲存 ID 的幾個好處。這個方法比較適合用在很少被更改的資料，因為 denormalization 會使得 update, delete 的操作變得更複雜與更沒效率。\n>\n> 在 [MongoDB 的 6 Rules of Thumb for MongoDB Schema](https://www.mongodb.com/blog/post/6-rules-of-thumb-for-mongodb-schema-design-part-2) 就有提到這個方法的使用時機與考量，建議讀者可以閱讀～\n\n另外，就算資料原本很符合 document model 的格式，在未來也有機會因為需求的變更變得更加複雜而產生多對一、多對多的關聯。例如：\n\n1. 新增學校的 logo、聯絡電話、地址等等，這時不再只能儲存一個 `school_name` 字串，就可能需要有一個 `schools` 的表來儲存資訊，如此一來 `users` 與 `schools` 就變成多對一的關係了。\n2. 新增一個推薦功能可以讓使用者爲另一名使用者寫推薦信，則產生了多對多的關係。\n\n## Are Document Databases Repeatng History\n\n講完了 relational model 與 document model 各自的不擅長之處，這裡稍微講古一下 network model 與 hierarchical model。\n\n在 1970 年最熱門的資料庫 IBM's Information Management System (IMS) 採用的是 hierarchical model，與現在 document model 中 JSON 的格式非常相似。與現在使用 document model 一樣，hierarchical model 可以很好的處理一對多關聯，但是不適合處理多對一或是多對多關聯。\n\n因此兩個最突出的解決方案出現了，分別是 **network model** 以及 **relational model**。\n\n### The network model\n\nNetwork model 是由一個會議 Conference on Data Systems Languages (CODASYL) 制定的，因此也叫做 CODASYL model。\n\nNetwork model 與 hierarchical model 很像，最大的不同在於每個 record 可以有不只一個 parent。\n\n在 network model 中的 query 必須透過指針從 root 移動到想要的 record，開發者必須自己維護可能走到重複的點、決定路徑等問題。\n\n### The relational model\n\nRelational model 將資料放在表中的列上，最成功的部分在於 relational model 把 query 的複雜實作都抽象化在 DBMS 的 query optimizer 中，使得開發者可以簡單的選擇想要的資料，透過 query optimizer 自行決定要怎麼存取資料、要使用哪個 index。\n\n### Comparison to document databases\n\n最後回到最初的問題，那麼現在的 document model 是否是重蹈覆轍呢？\n\n現在的 document model 可以透過類似 relational model 中 *foreign key* 的方式，來關聯多對一或是多對多的模型，稱作 *document reference*。不像是之前 network model 所採用的方式。\n\n最終要如何選擇，到底是 relational model 還是 document model 更符合使用情境，還是看各位開發者的決定了！\n\n## Relational Versus Document Databases Today\n\n最後總結一些今日 relational 與 document databases 在 data model 上的比較。\n\n### Which data model leads to simpler application code\n\n跟在前面提到的一樣，如果資料是 document-like，並沒有多對一、多對多的關聯，則較適合 document model。\n\n若有很大量的多對多關聯存在，甚至 relational model 也並不是最適合的選項，後面會介紹到 graph model 就是專門解決這個問題而產生的。\n\n### Schema flexibility in the document model\n\n通常 document databases 會被叫做 *schemaless*，但更準確來說應該稱作 *schema-on-read*，也就是資料的格式是隱藏、不需預先定義的，在讀出時才決定他的格式。\n\n當儲存的資料結構需要改變時，例如將原本的 `name` 欄位拆成 `first_name` 以及 `last_name`，document model 可以很簡單的透過應用層的程式碼在讀出與寫入時對資料做出改變即可，因爲 document databases 通常容許一個 collections 內的資料長相不同。\n\n```js\nif (user && user.name && !user.first_name) {\n  first_name = user.name.split(\" \")[0];\n}\n```\n\n而 relational database 通常必須透過 *migration* 來達成：\n\n```sql\nALTER TABLE users ADD COLUMN first_name text;\nUPDATE users SET first_name = split_part(name, ' ', 1); -- PostgreSQL\nUPDATE users SET first_name = substring_index(name, ' ', 1); -- MySQL\n```\n\n`ALTER TABLE` 對於大型系統而言是非常可怕的，通常會造成 database 的 downtime。PostgreSQL 在 v11 之前，`ALTER TABLE ADD COLUMN` 會拿整張 table 的 `ACCESS EXCLUSIVE` lock，造成所有的 transaction 不能 access 這張 table。\n\n因此若資料結構是經常改動、或是資料的結構變化很大，則有 schema 反而會成為一種困難，document model 可能會更加適合。\n\n### Data locality for queries\n\nDocument model 通常將整個 document 儲存成一段 encoded 的 JSON 字串（或是 MongoDB's BSON），因此存取會整個 document 一起取出，也就是 document model 的 *storage locality*。\n\n若資料經常是整個被存取的，則 document model 可以避免掉 relational model 因為需要多次 join 而可能造成多次 disk access 的問題。但反之若每次只需要一小部分的資料，document 還是會被整個 load 到 memory 造成浪費。並且 document 更新時通常也是整個 document 一起寫入，因此就算只修改一小部分的資料也會重寫整個 document。\n\n### Convergence of document and relational databases\n\nPostgreSQL 從 v9.3 開始、MySQL 從 v5.7 開始支援 JSON 格式的欄位。\n\nMongoDB 的 driver 會自動的 join document reference。\n\n因此 relational 與 document databases 現在是越來越相近的，讓使用者在應用層能夠更方便的挑選適合的 data model。\n\n# Query Languages for Data\n\n這個段落開始介紹 declarative language 與 imperative programming 的差異。\n\nDeclarative language 即只描述目標的性質，不須描述要如何達到此目標。而 imperative programming 則是很像一般的 programming language，要達到目標的話一定要將流程寫出。\n\n簡單來說：**declarative 是定義 what to do、而 imperative 是定義 how to do**。\n\n舉例來說 SQL 就是一種 declarative language、CSS 也是一種 declarative language。\n\n而資料庫更適合 declarative language，因為可以把實作的複雜都隱藏起來，讓 DBMS 決定如何優化，並且更適合做平行化的處理。\n\n## MapReduce Querying\n\nMapReduce 是 google 提出的處理大量資料的一種 programming，同時用到了 declarative 與 imperative 的方式。\n\n```js\ndb.observations.mapReduce(\n  function map() {\n    var year = this.observationTimestamp.getFullYear();\n    var month = this.observationTimestamp.getMonth() + 1;\n    emit(year + \"-\" + month, this.numAnimals);\n  },\n  function reduce(key, values) {\n    return Array.sum(values);\n  },\n  {\n    query: { family: \"Sharks\" },\n    out: \"monthlySharkReport\"\n  }\n)\n```\n\n因為 MapReduce 需要使用者自己小心的撰寫 Javascript 程式碼，雖然可以做到很複雜的操作，但對於簡單的操作來說，還是 declarative language 更適合作為資料庫的查詢語言。\n\n因此 MongoDB 在 v2.2 之後支援了 *aggregation pipeline* 的 declarative query language。\n\n```js\ndb.observations.aggregate([\n  { $match: { family: \"Sharks\" } },\n  {\n    $group: {\n      _id: {\n        year:  { $year:  \"$observationTimestamp\" },\n        month: { $month: \"$observationTimestamp\" }\n      },\n      totalAnimals: { $sum: \"$numAnimals\" }\n    }\n  }\n]);\n```\n\n# Graph-Like Data Models\n\n當資料庫有很多的多對多關聯，就很適合使用 graph-like data model。\n\nGraph 中包含點與邊，在現實中的例子包含：\n\n- Social graphs: 點代表人，邊代表朋友或是追蹤關係。\n- The web graph: 點代表網頁，邊代表連到別的網頁的 link。\n\n在一張 graph 中每個點與邊也可以代表不同意義，例如 Facebook 維護了一張 graph，其中 vertex 可能是人、地點、事件或是留言，而邊可能代表人參加的事件、事件發生的地點或是人留下的留言。\n\nGraph-like data models 主要分為兩種，*property graph* model 以及 *triple-store* model。\n\n## Property Graphs\n\n每個點都有：\n- 一個 unique ID\n- 一些出邊\n- 一些入邊\n- 一些 properties（key-value pairs）\n\n每個邊都有：\n- 一個 unique ID\n- 邊的起點跟終點\n- 一個 label\n- 一些 properties（key-value pairs）\n\n### The Cypher Query Language\n\n*Cypher* 是一種 declarative language，是 Neo4j 圖資料庫的查詢語言。\n\n```sql\nCREATE\n  (NAmerica:Location {name:'North America', type:'continent'}),\n  (USA:Location      {name:'United States', type:'country'  }),\n  (Idaho:Location    {name:'Idaho',         type:'state'    }),\n  (Lucy:Person       {name:'Lucy' }),\n  (Idaho) -[:WITHIN]->  (USA)  -[:WITHIN]-> (NAmerica),\n  (Lucy)  -[:BORN_IN]-> (Idaho)\n```\n\n```sql\nMATCH\n  (person) -[:BORN_IN]->  () -[:WITHIN*0..]-> (us:Location {name:'United States'}),\n  (person) -[:LIVES_IN]-> () -[:WITHIN*0..]-> (eu:Location {name:'Europe'})\n  RETURN person.name\n```\n\n`()` 代表點、`[]` 代表邊、`:` 代表邊或是點的 label、`{}` 內的代表 properties、`->` 代表邊的方向，`()` 或是 `[]` 中最前面的變數則是命名。\n\n## Graph Queries in SQL\n\n作者提出如果把 graph data 放在 relational structure 內，那麼可以使用 SQL 來做查詢嗎？\n\n可以觀察到上面的 query 有一個特別的符號 `*0..`，這代表的 label 是 `WITHIN` 的邊可以出現 0 到任意多次，但是在 SQL 中，並沒有辦法指定 0 ~ 任意多次的 join，要做到的話必須透過 SQL 中的 `RECURSIVE` 語法，更加複雜。\n\n## Triple-Stores and SPARQL\n\nTriple-Stores 透過三元組 `(subject, predicate, object)` 來儲存資料。例如 `(Jim, likes, bananas)`。\n\n三元組也可以用來描述 subject 的 properties，例如 `(Jim, age, 33)`。\n\n對應到圖的話，則 `subject` 是點、`predicate` 是邊、`object` 可以是點或是值。\n\n### The SPARQL query language\n\n```sql\nSELECT ?personName WHERE {\n  ?person :name ?personName.\n  ?person :bornIn  / :within* / :name \"United States\".\n  ?person :livesIn / :within* / :name \"Europe\".\n}\n```\n\n## Graph Databases Compared to the Network Model\n\nNetwork (CODASYL) model 與現今的 graph databases 看起來十分相似，但是 graph databases 能成功大致有幾個原因：\n- CODASYL 沒有可以直接 access record 的方式，但是 Graph Model 中每個 vertex 跟 edge 都有 uid 可以直接 access。\n- CODASYL 並沒有 declarative query language（ex: Cypher），因此不好做查詢。\n\n# 總結\n\n因為每一種 data model 都很複雜，因此本章先以綜觀的角度看各種 data model 的性質與優缺點，期望開發者能夠在使用這些 data model 時爲各種情境的應用挑選正確的資料模型。\n\n> 最後，如果你喜歡這篇文章，或是文章對你有幫助的話，可以幫我按個喜歡、或是留言！你的支持就是我寫作的最大動力。有任何想問的問題也可以在底下留言喔～\n","tags":["Notes","DDIA"],"categories":["Notes"]},{"title":"Designing Data-Intensive Application 第一章筆記","url":"/Designing-Data-Intensive-Application-第一章筆記/","content":"\n<img src=\"/assets/Designing-Data-Intensive-Application-第一章筆記/book-cover.png\" width=\"50%\">\n\n# Introduction\n\n現在的軟體基本上都不是 CPU Bound，而是 Data-Intensive 的，也就是大多數的瓶頸都在資料的量而不是計算的量。因此大多數的應用程式會依靠多種工具來滿足不同情境下的資料使用。\n\n例如一個後端可能會用到 MySQL、PostgreSQL 來儲存資料，用 Redis 來做快取，用 ElasticSearch 來做搜尋引擎，用 RabbitMQ、NATS 來做異步的消息傳輸。有各種工具可以滿足不同需求的資料使用方式，因此我們需要知道在設計不同需求的系統時，要如何挑選、使用這些技術與工具。下圖即是一種可能的系統架構：\n\n![](/assets/Designing-Data-Intensive-Application-第一章筆記/system.png)\n\n本章節重點先放在三項設計系統時的要點：可靠性（Reliability）、可擴展性（Scalability）以及可維護性（Maintainability）。\n\n<!-- More -->\n\n# Reliability\n\n一個系統是可靠的，如果能夠功能正常的運作、容錯（Fault Tolerance）、有好的效率（Performance）以及可以避免被攻擊。\n\n這裡特別提到 fault 指的是系統背離原本預期的行為，而 failure 指的是整個系統因為錯誤而停止服務。因為任何的系統都不可能是完全不會有錯誤發生的，因此我們應該設計一個 fault tolerance 的系統來避免 failure 的發生。\n\n另外，作者提到可以透過故意的產生錯誤來檢查系統是否能夠應付這些錯誤，例如 Netflix 的 [Chaos Monkey](https://github.com/Netflix/chaosmonkey) 會隨機的關掉 VM 的容器，強迫工程師建立更能容錯的系統。這就是所謂的 Chaos Engineering。\n\n## Hardware Faults\n\n硬碟的 Mean Time to Failure(MTTF) 在 10 ~ 50 年之間，因此一個有 10000 個硬碟的叢集平均每天都會有一顆硬碟故障。\n\n避免硬碟故障導致的問題，可以使用 RAID 磁碟陣列。另外各種硬體都有可能發生錯誤，因此都需要有備援機制。\n\n> 不過筆者認為現在大多數公司都會直接採用雲端平台提供的各種服務與資源，因此這部分的問題應該可以大量避免了。不過 GCP/AWS 每年也都會有幾次的 System Outage，因此若是服務很重要的話，可能甚至要考慮跨雲的部署或是救援。\n\n## Software Errors\n\n軟體系統錯誤可能會導致其他系統也受到影響。雖然沒有 100% 能夠避免軟體錯誤的方法，但有很多小事情可以幫助改善，例如撰寫測試，從單元測試、整合測試到端對端測試；做監控以確定系統正常運作。\n\n## Human Errors\n\n人類是不可靠的，據調查系統大多數都是因為人為操作失誤而導致停止運作，而因為硬體錯誤而導致的錯誤只有 10–25%。\n\n要盡量避免人為操作錯誤，有幾項方式：\n- 定義良好的抽象層、APIs、管理者介面。\n- 提供一個跟非 production，但與 production 幾乎功能一致的環境。通常就是所謂的 staging server。\n- 撰寫完整的測試。\n- 有快速的方法可以恢復錯誤，例如 rollback changes。\n- 做 monitor 以及 metrics，monitor 可以幫助提早的發現錯誤，當錯誤發生時透過 metrics 來排查。 \n\n# Scalability\n\n在思考如何應付大量的流量之前，應該先定義系統的流量。\n\n## Describing Load\n\n舉 Twitter 為例，若只有兩項功能：\n1. Post tweet：使用者可以發布 tweet，所有追蹤訂閱者都會收到通知。4.6k requests/sec at average, 12k requests/sec at peak。\n2. Home timeline：使用者可以檢視所有的追蹤者發布的 tweets。 300k requests/sec。\n\n有兩種不同方式可以做到 View home timeline 的功能：\n\n1. 使用 SQL Join\n\n\t```sql\n\tSELECT tweets.*, users.* FROM tweets\n\tJOIN users ON tweets.sender_id = users.id\n\tJOIN follows ON follows.followee_id = users.id\n\tWHERE follows.follower_id = current_user\n\t```\n\n2. 對每一個使用者維護一個 Cache Queue，當 tweet 發出時，將訊息送到每個訂閱者的 Queue。\n\n一開始 Twitter 採用的是方法 1，但是當使用者多起來時，每次的 view home timeline 都要做 SQL Join，造成過多的流量。\n\n因為使用者的平均追蹤者是 75 人，等於每次的推文平均需要 $75\\times 4.6k=345k$ 次的 cache writes，因為 post tweet 的流量是比 view home timeline 低許多的，因此 Twitter 改採用了方法 2，來降低 view home timeline 造成的 bottleneck。\n\n但是有些使用者有超過3千萬個追蹤者，因此每次他發布推文時需要3千萬次的 cache writes，可能會造成系統的負擔，因此最後 Twitter 採取了 Hybrid 的做法，對於過多追蹤者的用戶，他們的發推就不採用第二種做法。\n\n由這個例子就可以很輕易的知道，根據每個系統、每項功能的不同流量高低，都會有對應不一樣的設計方式。\n\n## Describing Performance\n\n可以用以下兩點來分析系統效能：\n\n- 當流量增加時，系統的效能會受到多少影響？\n- 當流量增加時，需要增加多少資源（CPU, Memory, Network bandwith）才能使的系統效能不變。\n\n通常評估的方式是 Response Time，從 client 發起請求到收到請求所經過的時間。\n\n通常不會看平均，因為平均無法代表使用者真正收到的延遲時間。通常會採用百分位數（Percentile），也就是將 response time 由低到高排序後某個百分點對應的數值。\n\n$p_k$ 代表第k百分位數。\n\n- $p_{50}$ 可以知道使用者通常等待的時間。\n- $p_{95}, p_{99}, p_{999}$ 也可以稱作 tail latency，是比較重要的觀察點，可以用來觀察大多數的使用者的等待時間。\n\n> 但也不是越多 9 就越好，因為每多一個 9 都會使得維運成本大幅增加。\n\n在測試時，要從 client 端計算 response time，並且 requests 要同時送出，才能達到真正的效果。\n\n## Approaches for Coping with Load\n\n在流量增加速度很快的服務下，必然可能會需要重構系統架構。\n\n不過在不動系統架構的前提下，通常有兩種方式可以 scale up：\n\n1. Vertical scaling：增加 CPU、增加 Memory，使用更好的機器。\n2. Horizontal scaling：將流量分散到多台 server 上。\n\n通常要 vertical scaling 是比較容易的，但是太高規格的機器是非常昂貴的，因此有一定流量的系統通常會無可避免的要做 horizontal scaling。將 stateless 的服務（Ex: front-end server）做 horizontal scaling 是很容易的，但是 stateful 的服務要變成 distributed system 就會衍生出很多問題，因此通常會採用 vertical scaling 直到價格無法應付。\n\n當然因應現在資訊爆炸，資料量越來越大的情形，現在也已經有很多 distributed system 的工具與解決方案了。這些都會在後面的書中後面的章節提到。\n\n# Maintainability\n\n沒有工程師會想要接手 [legacy system](https://en.wikipedia.org/wiki/Legacy_system)，因此，保持系統的可維護性也是很重要的。\n\n## Operability: Making Life Easy for Operations\n\n一個好的維運團隊應該要做到：\n- 監控系統的健康並且如果系統陣亡能快速的復原\n- 做錯誤的追蹤以及效能的追蹤，例如 request 在哪裡是 bottleneck\n- 系統安全性的修補\n- 建立部署、配置、管理方面的實踐方式與工具\n\n當然還有更多，這裡只提一些筆者認為比較重要的。\n\n## Simplicity: Managing Complexity\n\n可以利用抽象來簡化程式的複雜度。\n\n## Evolvability: Making Change Easy\n\n系統是不會永遠不變的。Aglie 敏捷開發方法即是採用一種擁抱改變的態度，其中還提出了例如 TDD（Test-Driven Design）與 Refactoring 的方法。\n\n# Summary\n\n設計系統時三個重要的觀點，可靠性（Reliability）、可擴展性（Scalability）以及可維護性（Maintainability）。\n\n- Reliability：系統要可以容錯。\n- Scalability：系統負載增加時也能保持性能。\n- Maintainability：降低工程師與維運團隊工作的複雜度。\n\n> 最後，如果你喜歡這篇文章，或是文章對你有幫助的話，可以幫我按個喜歡、或是留言！你的支持就是我寫作的最大動力。有任何想問的問題也可以在底下留言喔～\n","tags":["Notes","DDIA"],"categories":["Notes"]},{"title":"2021 Dcard Web Backend Intern 面試經驗分享","url":"/2021-Dcard-Web-Backend-Intern-面試經驗分享/","content":"\n距離收到錄取通知已經有兩個月了，決定來分享一下當初去 Dcard 面試的心得跟過程～\n\n雖然我本來就有在新創公司工作，但是新創公司樣樣都要自己來，而且沒有一個 Mentor 帶領，產品也比較沒有流量，很難判斷自己做出的系統架構是不是一個好的架構，因此今年決定申請 Dcard 實習，來體驗看看高流量的 backend 開發！\n\n# 面試流程\n\nDcard 的面試流程算是滿透明的，基本上分成 3 大關，履歷審查、第一次面試跟第二次面試。\n\n整個流程走的也算滿快的，大概一個月就會把整個面試流程走完，而且各個階段有沒有通過都會寄信通知，非常棒～\n\n<!-- More -->\n\n## 履歷審查\n\n一開始當然是附上履歷！履歷的部分我是寫滿一頁整而已，基本上就是寫上工作經歷、寫過比較重要的 Side Project、黑客松、讀書會等等。\n\n因為我個人認為 Dcard 還滿看重你的自學能力以及你是不是喜歡與人分享交流，所以放的內容都是比較偏自學、交流性質的活動，一些在學校做過的助教跟網頁開發的打工倒是都沒有放進去。\n\n如果想要參考履歷要怎麼寫的話，可以到 [關於我](/about) 頁面查看。\n\n申請 Dcard 實習有個比較特別的地方是要交一份作業，是實作一個 Rate Limiter Middleware，也就是如果在一定時間內超過一定數量的 Requests 要回傳 429 Too Many Requests，基本上語言方法不限，我是用 NodeJS + Redis 來實作的。詳細可以參考我的 [Github Repo](https://github.com/justin0u0/rate-limiter)。\n\n另外申請實習是可以附上應徵信的，裡面可以附上一些履歷沒有提到的內容（履歷主要以技術背景為主），例如我在應徵信裡面提到了我為什麼會想來 Dcard 參加實習以及一些個人特質。想參考的可以看[這裡](https://www.notion.so/justin0u0/Dcard-Web-Backend-Intern-2021-c13e8e7777d9421398f28049596b2b1a)。\n\n## 第一次面試\n\n### Talent Operation Team (HR)\n\n首先是 HR 面試，總時間是一小時（但我不到一小時就結束了）。一開始是 5 分鐘的自我介紹，想參考的可以看[這裡](https://www.notion.so/justin0u0/73ec63ea80ab42b09fb18cbb68188930)。再來就是回答 HR 的問題，基本上我個人感覺 Dcard 很在乎你對公司的看法、你來參加的動機等等，比如說我有被問到「為什麼會在大三的時候就想要來做 Intern？」或是「為什麼會走 Backend 這條路而不是其他方向」。HR 也會針對你的履歷提出問題，例如我有被問到「為什麼會寫 Blog？」，讓我真的覺得 Dcard 的 HR 很用心也很親切，在聊天的過程中就能體會出來你的履歷有被認真的看過，而且 HR 對於資訊這方面的知識也都略知一二。\n\n總之 HR 面試關整體來說就很像在聊天一樣，重點就是履歷一定不能造假！最後會問你有沒有任何想問的問題，如果沒有的話就會進到開發面試。\n\n### Development Team\n\n由 Backend 的成員來面試，總時間也是一小時（但我也是不到一小時），聽說本來是有 Backend Team 的主管會來的，但我去的時間好像剛好主管在開會，所以就是兩名 Backend Engineer 來幫我面試～\n\n這關主要就是考驗你的技術實力了，不過我覺得問的問題還滿隨性的，除了最後一題之外，其他問題都是圍繞著你的履歷上面有提到的技術，跟一些滿基礎的 Backend 知識來提問的。我有被問到的問題跟我的一些回答包括：\n\n1. RDBMS v.s NoSQL 分別是什麼？\n\tRDBMS 主要利用資料正規化來分割資料庫，建成一張張表後利用 Join 的方式來合併資料。\n\tNoSQL 給了方便的彈性，有很多類型，例如：Document based、Graph、Key-Value...\n2. RDBMS v.s NoSQL 要怎麼做出選擇？\n\tRDMBS 跟 NoSQL 的 use case 不太一樣，RDBMS 比較適合被用在需要確保 ACID 的資料上，以確保資料的一致性；而 NoSQL 通常都是希望可以分散式來提高可以性以及可擴充性。另外還有一個考量的點是 RDBMS 的 Join 會使得他不適合用在微服務上，因為跨 services 的 transactions 需要額外的 effort 來實作。\n3. ACID 是什麼？\n\tA 是 Atomic，原子性，一個事務不是全部成功就是全部失敗。\n\tC 是 Consistency，事務完成後資料正確無誤。\n\tI 是 Isolation，事務有隔離級別，確保同時發生的事務不會發生錯誤。\n\tD 是 Durability，事務一旦成功資料就不會遺失。\n4. Authentication 跟 Authorization 的差別。\n\tAuthentication 驗證身份，例如帳號密碼；Authorization 驗證有沒有權限使用這個功能。\n5. Authentication 怎麼做？\n\t可以用 JWT。\n6. 簡單的說明 JWT 的技術。\n\tJWT 是 JSON Web Token，主要分成三段，用 `.` 連接起來。第一段是 header，第二段是 payload，前兩段都用 Base64 編碼，最後一段是前兩段的加密文。可以用來防止攜帶的資訊被修改，因為竄改者無法知道第三段的加密結果為何。\n7. 給你兩個很長的 SQL 跟他們的 Explain 結果，請你講解兩段 SQL 做了什麼，以及他們的差別。\n\t這題基本上是最難的了，因為那時候對 PostgreSQL 還不是很熟，所以其實沒有回答的很好。但主要就是要對 SQL 語法有基礎的知識，特別是常常使用 ORM 而不是直接寫 SQL 的，至少要知道 SQL Join 怎麼使用。\n\n總之我覺得回答的重點就在於，不要提到自己不熟的技術，因為他們很有可能繼續追問你在回答中講到的技術。而這部分的題目大概也是因人而異，我被問到的題目跟我在準備時看到其他人分享的題目也是完全不相同，所以在履歷裡面也近量別寫自已不熟的技術吧xD，不然大概有大機會會被問倒。\n\n最後也會詢問有沒有什麼想問的，基本上我有詢問他們用的框架、他們的開發流程等等。\n\n## 第二次面試\n\n### Talent Operation Manager (HR Manager)\n\n這關是 30 分鐘。基本上跟第一次面試的 HR 面試差不多，但內容會偏向更大方向的討論。一樣真的要稱讚一下 Dcard 的 HR，都非常的親切＆準備充足。\n\n### CEO - Kytu\n\n首先，CEO 的名字的念法跟 Kit 是同音的，這個我在去面試前查了好久才查到xD。\n\n這關是 30 分鐘。基本上在別人的面試分享有看到，就是跟 CEO 的聊天關。基本上一坐下就會問你有沒有什麼想問的問題，所以一定要提前準備一些你想要問的問題，除非你的臨場反應真的很好。\n\n基本上想要跟 CEO 聊什麼都沒問題，我有詢問關於 Dcard 從一個 10 人團隊到現在 200 人的管理問題，還有詢問一些職涯規劃，討論讀研、是否要出國等問題。\n\n問題可以盡量準備多一點，因為 CEO 回答的速度還滿快的。\n\n# 總結\n\nDcard 的面試總體感受是滿好的，非常看重你對公司的看法。第一次面試時還會帶你參觀辦公室，帶你到他們的零食區拿食物；第二次面試時 CEO 還請喝星巴克，雖然我根本不敢在當下喝就是了xD\n\n基本上如果說要準備的話，我強烈建議多去看看一些關於 Dcard 的文章報導，或是 CEO 的演講也可以稍微看看，會對你在面試時的應答還滿有幫助的～\n\n雖然面試整體過程是走比較輕鬆的路線，但我認為 Dcard 對實習生的審核是非常重視也不隨便的！我認為 Dcard 還滿重視面對問題的邏輯思維和主動學習的能力，所以如果你有在寫 blog 的話，應該是大大加分！\n\n> 最後，如果這篇文章對你有幫助的話，可以幫我按個喜歡、或是留言！各位的支持就是我寫作的最大動力。有任何想問的問題也可以在底下留言喔～\n","tags":["Dcard","Interview"],"categories":["Others"]},{"title":"LeetCode 309 - Best Time to Buy and Sell Stock with Cooldown","url":"/LeetCode-Best-Time-to-Buy-and-Sell-Stock-with-Cooldown/","content":"\n# 題目\n題目連結：[https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-cooldown/](https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-cooldown/)\n\n給定每一天的股價，第 `i` 天的股價為 `prices[i]`，求出最大的獲利為何。\n\n可以進行多次的買賣，但手上一次只能握有一張股票。並且在股票賣出後，有一天的冷卻時間不能進行買賣。\n\n# 範例說明\n\n## Example 1:\n\n```\nInput: prices = [1,2,3,0,2]\nOutput: 3\nExplanation: transactions = [buy, sell, cooldown, buy, sell]\n```\n\n<!-- More -->\n\n## Example 2:\n\n```\nInput: prices = [1]\nOutput: 0\n```\n\n# 想法\n\n這個題目有很多種定義 DP 狀態的方式，以下提供三種想法：\n\n## 想法一\n\n定義 `dp(i)` 代表對於 `prices[0:i]`，並且第 $i$ 天時進行了賣的動作，所能獲得的最大獲利。\n\n因此可以知道：\n$$dp(i)=prices[i]+\\red{max\\{dp(j)-prices[k]\\}}\\quad\\forall\\ j\\lt k-1 \\lt k\\lt i$$\n\n也就是，在第 $i$ 天賣出股票的最大獲利為在第 $j$ 天賣出股票後，在第 $k$ 天買股票，其中因為有冷卻時間的關係，因此 $j\\lt k-1$；而買股票至少要在賣股票前一天，因此 $k\\lt i$。\n\n有了上述的轉移式，應該可以用一個 $O(N^3)$ 的三層迴圈來解決，然而這個題目最優可以做到 $O(N)$\b。因此觀察轉關式，可以發現兩件事情：\n1. 當 $i$ 增加一時，會獲得一個新的 `prices[k]`（$k'=i-1$），而由 `prices[k']` 產生的 $\\red{max\\{dp(j)-prices[k]\\}}=max\\{dp(j)\\}-prices[k']$。\n2. 當 $i$ 增加一時，也會獲得一個新的 `dp(j)`（$j'=i-3$)。\n\n有了上述的兩個觀察，利用變數 `maxDp` 來紀錄 $max\\{dp(j)\\}$，並且在每次 $i$ 增加一時，利用 $dp(j')$ 更新 `maxDp`；利用變數 `best` 紀錄 $\\red{max\\{dp(j)-prices[k]\\}}$，並且在每次 $i$ 增加一時，利用 $prices[k']$ 更新 `best`。\n\n最終改變一下轉移式：\n$$dp(i)=prices[i]+\\red{max\\{dp(j)-prices[k]\\}}=prices[i]+best$$\n\n實作部分請閱讀 [想法一之實作細節](#想法一之實作細節) 以及 [想法一之程式碼](#想法一之程式碼)。\n\n## 想法二\n\n待補\n\n# 實作細節\n\n## 想法一之實作細節\n\n實作時，可以開一個長度為 `N` 的 DP 陣列，並且依照上面的想法，每當 `i` 增加一時（也就是剛進入迴圈時），更新兩個變數 `maxDp` 以及 `best`。\n\n如下：\n```cpp\nfor (int i = 0; i < n; i++) {\n  maxDp = max(maxDp, dp[i - 3]);\n  best = max(best, maxDp, prices[i - 3]);\n\n  dp[i] = ...\n}\n```\n\n不過要注意 `maxDp` 要在 $i\\le 3$ 時才能更新；`best` 要在 $i\\le 1$ 時才能更新。並且對於兩數的初始值，`maxDp` 初始值等於 0，因為在什麼股票都還沒有賣出的情況下，最大獲利為 0；而 `best` 的初時值為 $-\\infin$，對於還沒進行第一次購買股票情況，我們不應該從這個 `best` 來轉移，因此將值設為 $-\\infin$ 來避免將從這個點轉移的狀態成為答案。\n\n因此迴圈內部之狀態更新應該如下：\n\n```cpp\nfor (int i = 0; i < n; i++) {\n  // i increase by 1, update `maxDp` and `best`\n  if (i >= 3) maxDp = max(maxDp, dp[i - 3]);\n  if (i >= 1) best = max(best, maxDp - prices[i - 1]);\n\n  // transition\n  dp[i] = prices[i] + best;\n}\n```\n\n我們可以把 `maxDp` 以及 `best` 的更新移至 DP 轉移的下方：\n\n```cpp\nfor (int i = 0; i < n; i++) {\n  // transition\n  dp[i] = prices[i] + best;\n\n  // i is ready to increase by 1, update `maxDp` and `best`\n  if (i >= 2) maxDp = max(maxDp, dp[i - 2]);\n  best = max(best, maxDp - prices[i]);\n}\n```\n\n觀察發現，並不需要紀錄整個長度為 N 的陣列，因為迴圈中只使用到了 $dp(i-2)$ 這個位置而已。利用三個變數 `dp0`, `dp1`, `dp2` 分別紀錄 $dp(i),\\ dp(i-1),\\ dp(i-2)$，即可將程式碼優化成 $O(1)$ 空間使用。\n\n# 程式碼\n\n## 想法一之程式碼\n\n### O(N) Space\n\n```cpp\n/**\n * Author: justin0u0<mail@justin0u0.com>\n * Problem: https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-cooldown/\n * Runtime: 4ms\n * Time Complexity: O(N)\n * Space Complexity: O(N)\n */\n\nclass Solution {\npublic:\n  int maxProfit(vector<int>& prices) {\n    int n = prices.size();\n    vector<int> dp(n);\n\n    const int inf = 0x3f3f3f3f;\n    int maxDp = 0, best = -inf;\n    for (int i = 0; i < n; i++) {\n      // i increase by 1, update `maxDp` and `best`\n      if (i >= 3) maxDp = max(maxDp, dp[i - 3]);\n      if (i >= 1) best = max(best, maxDp - prices[i - 1]);\n\n      // transition\n      dp[i] = prices[i] + best;\n    }\n    for (int i = max(0, n - 3); i < n; i++)\n      maxDp = max(maxDp, dp[i]);\n    return maxDp;\n  }\n};\n```\n\n### O(1) Space\n\n```cpp\n/**\n * Author: justin0u0<mail@justin0u0.com>\n * Problem: https://leetcode.com/problems/best-time-to-buy-and-sell-stock-with-cooldown/\n * Runtime: 0ms\n * Time Complexity: O(N)\n * Space Complexity: O(1)\n */\n\nclass Solution {\npublic:\n  int maxProfit(vector<int>& prices) {\n    // dp0 = dp(i), dp1 = dp(i - 1), dp2 = dp(i - 2)\n    int dp0, dp1 = 0, dp2 = 0;\n    int maxDp = 0, best = -0x3f3f3f3f;\n    for (int& price : prices) {\n      dp0 = price + best;\n      maxDp = max(maxDp, dp2);\n      best = max(best, maxDp - price);\n      dp2 = dp1;\n      dp1 = dp0;\n    }\n    return max(max(maxDp, dp2), max(dp1, dp0));\n  }\n};\n```\n","tags":["LeetCode","動態規劃（Dynamic Programming, DP）"],"categories":["LeetCode"]},{"title":"LeetCode 312 - Burst Ballons","url":"/LeetCode-Burst-Ballons/","content":"\n# 題目\n題目連結：[https://leetcode.com/problems/burst-balloons/](https://leetcode.com/problems/burst-balloons/)\n\n給一長度為 `n` 的序列 `nums`，依照任意順序刪除一個數字，直到所有數字消失。\n\n每次刪除一個數字 `x` 時，假設 `x` 的左邊為 `y`，右邊為 `z`，則花費 `x*y*z` 元；當左邊沒有數字，`y` 視為 1，當右邊沒有數字時，`z` 視為 1。\n\n求出最大花費。\n\n# 範例說明\n\n## Example 1:\n\n```\nInput: nums = [3,1,5,8]\nOutput: 167\nExplanation:\nnums = [3,1,5,8] --> [3,5,8] --> [3,8] --> [8] --> []\ncoins =  3*1*5    +   3*5*8   +  1*3*8  + 1*8*1 = 167\n```\n\n<!-- More -->\n\n## Example 2:\n\n```\nInput: nums = [1,5]\nOutput: 10\n```\n\n# 想法\n\n首先，若想要利用 DP 來紀錄重複的狀態，期望上的狀態應該為 `dp(i,j)` 代表將 `nums[i:j]` 依照任意順序刪除直到所有數字消失的最大花費，並且希望 `dp(i,j)` 的答案可以由一個在 $i\\sim j$ 的子區間的 DP 值求得。\n\n可以試圖枚舉在 $i\\sim j$ 之間要刪除的數字，但是會導致狀態無法表述當前剩下的數字。例如，初始狀態的 `dp(0,n-1)` 若刪除數字 1 則剩下的數字為 `[3,5,8]`，然而如此一來就沒有一個狀態能夠表述了。因此想辦法改變轉移的方式。觀察範例測資：\n```\nnums = [3,1,5,8] --> [3,5,8] --> [3,8] --> [8] --> []\ncoins =  3*1*5    +   3*5*8   +  1*3*8  + 1*8*1 = 167\n```\n為了避免刪除數字時，可能沒有左邊或右邊的數字的問題，先在整個序列的兩側加上兩個 1，並把題目改為將序列內所有除了兩側的數字刪除的最大花費。\n```\nnums = [1,3,1,5,8,1] --> [1,3,5,8,1] --> [1,3,8,1] --> [1,8,1] --> [1,1]\ncoins =    3*1*5      +     3*5*8     +    1*3*8    +   1*8*1   =   167\n```\n再度觀察，可以發現枚舉一個區間內要刪除的數字會使得狀態無法表述，那麼反過來改為枚舉一個區間內最後一個被刪除的數字，就有點像將上述的順序倒過來。可以發現轉移式即為：\n$$dp(i,j)=max\\big(dp(i,k), dp(k,j)\\big)+nums[i]\\times nums[k]\\times nums[j]\\quad\\forall\\ k\\in[i+1,j-1]$$\n\n也就是，要求出 $i\\sim j$ 的最大花費，且不包含 $i,\\ j$，若最後一個被刪除的數字為 $k$，則一定會有 $nums[i]\\times nums[k] \\times nums[j]$ 之花費，並且再加上 $i\\sim k$ 與 $k\\sim j$ 之花費，分別是 $dp(i,k)$ 與 $dp(k,j)$。\n\n如此一來，狀態有 $O(N^2)$ 中，每一個狀態需要花 $O(N)$ 的時間轉移，因此得到一個總時間複雜度為 $O(N^3)$ 的 DP。\n\n# 實作細節\n\n首先依照上述想法在最左以及最右個加入一個 1。\n\n再來注意 DP 的轉移，區間是由小區間之答案求得，因此要特別注意迴圈順序。一般情況下，都可以使用以下的迴圈順序：\n\n```cpp\nfor (int i = n - 1; i >= 0; i--) {\n  for (int j = i + 1; j < n; j++) {\n    // ...\n  }\n}\n```\n\n再來注意邊界條件，由於狀態 $dp(i,j)$ 定為刪除 $i\\sim j$ 之間的所有數字，不包含 $i,\\ j$，因此 $dp(i,i+1)=0$。因此第二層的 $j$ 迴圈由 $i+2$ 開始。\n\n# 程式碼\n\n```cpp\n/**\n * Author: justin0u0<mail@justin0u0.com>\n * Problem: https://leetcode.com/problems/burst-balloons/\n * Runtime: 372ms\n * Time Complexity: O(N^3)\n */\n\nclass Solution {\npublic:\n  int maxCoins(vector<int>& nums) {\n    nums.insert(nums.begin(), 1);\n    nums.emplace_back(1);\n    int n = nums.size();\n\n    int **dp = new int*[n];\n    for (int i = n - 1; i >= 0; i--) {\n      dp[i] = new int[n + 1];\n      dp[i][i + 1] = 0;\n\n      for (int j = i + 2; j < n; j++) {\n        for (int k = i + 1; k < j; k++)\n          dp[i][j] = max(dp[i][j], dp[i][k] + dp[k][j] + nums[i] * nums[k] * nums[j]);\n      }\n    }\n    return dp[0][n - 1];\n  }\n};\n```\n","tags":["LeetCode","動態規劃（Dynamic Programming, DP）"],"categories":["LeetCode"]},{"title":"LeetCode 132 - Palindrome Partitioning II","url":"/LeetCode-Palindrome-Partitioning-II/","content":"\n# 題目\n\n題目連結：[https://leetcode.com/problems/palindrome-partitioning-ii/](https://leetcode.com/problems/palindrome-partitioning-ii/)\n\n給定一個字串 `s`，找出最少需要將字串 `s` 切成幾段使得每一段都是迴文。\n\n# 範例說明\n\n## Example 1:\n\n```\nInput: s = \"aab\"\nOutput: 1\nExplanation: The palindrome partitioning [\"aa\",\"b\"] could be produced using 1 cut.\n```\n\n<!-- More -->\n\n## Example 2:\n\n```\nInput: s = \"a\"\nOutput: 0\n```\n\n## Example 3:\n\n```\nInput: s = \"ab\"\nOutput: 1\n```\n\n# 想法\n\n要將字串 `s` 切分，使得每一段都是迴文。可以發現要求 `s[0:n-1]` 的最小迴文切割段數，可以枚舉任何一段是迴文 `s[j:n-1]` 的，將 `s[j:n-1]` 當做是一段迴文，再接著求 `s[0:j-1]` 之最小迴文切割段數即可。\n\n有了上述的想法，可以發現這是一個 DP 問題，因為答案可以由某一個子答案中求得。\n\n因此，首先定義狀態 `dp(i)` 代表將 `s[0:i]` 切段使得每一段都是迴文所需的最小段數。 則轉移為：\n$$dp(i)=\\min\\big(dp(j)+1\\big)\\quad\\forall\\ j\\lt i,\\ if\\ s[j+1:i]\\text{ is palindrome}$$\n\n因此剩下的問題變成，如何很快的求得任何一段 `s[j+1:i]` 是否為迴文。利用預處理的方式，可以很簡單的在 $O(N^2)$ 的時間求出每一段子字串是否為迴文，並儲存進一個二維陣列 `isPalindrome[i][j]` 代表 `s[i:j]` 是迴文字串。主要有兩個做法：\n1. 枚舉每一個位置做為迴文的中心點（注意偶數長度迴文的情況），往外擴展（左右各往外一格字元，如果相等的話）直到不能在擴展。如此一來只會有 $O(N)$ 個中心點且每個中心點最多往外擴展 $O(N)$ 次，因此總時間複雜度為 $O(N^2)$。\n2. 利用 DP 的方式，可以發現：\n  $$isPalindrome(i,j)=1\\quad if\\ s[i]=s[j]\\And isPalindrome(i+1,j-1)=1$$\n  因此只要從小區間到大區間依次算出答案即可。\n\n# 實作細節\n\n首先對於求 `isPalindrome` 的部分，筆者是採用第二種方式，也就是 DP。\n\n要由小區間到大區間做 DP，務必注意迴圈的順序，通常都可以採用以下的順序：\n\n```cpp\nfor (int i = n - 1; i >= 0; i--) {\n  for (int j = i + 1; j < n; j++) {\n    // ...\n  }\n}\n```\n\n另外注意邊界情況，依照轉移式可以知道 `isPalindrome[i][j]` 會由 `isPalindrome[i+1][j-1]` 得到答案，且 $i\\lt j$；因此當 $j=i+1$ 時，`isPalindrome[i][i+1]` 由 `isPalindrome[i+1][i]`；當 $j=i+2$ 時，`isPalindrome[i][i+2]` 由 `isPalindrome[i+1][i+1]` 得到。\n\n所以邊界為 $isPalindrome[i][i] = isPalindrome[i+1][i] = true\\quad\\forall\\ i\\in n$。\n\n有了 `isPalindrome` 的陣列幫助。後半段的 DP 即可依照上述的轉移式：\n$$dp(i)=\\min\\big(dp(j)+1\\big)\\quad\\forall\\ j\\lt i,\\ if\\ isPalindrome[j+1][i]=1$$\n\n一樣需注意邊界情況，由於 $j\\ge 0$，因此沒有考慮到 `s[0:i]` 是迴文的情況，因此需另外加上條件當 `isPalindrome[0][i]=1`，則 `dp[i]=0`。\n\n參考下方[程式碼](#two-steps-dp)。\n\n另外，可以發現改變第二次 DP 狀態與轉移，改定義狀態 `dp(i)` 代表將 `s[i~n-1]` 切段使得每一段都是迴文的最小段數，轉移改為：\n$$dp(i)=\\min\\big(dp(j)+1\\big)\\quad\\forall\\ j\\gt i,\\ if\\ isPalindrome[i][j-1]=1$$\n\n即可將原本的兩次 $O(N^2)$ 迴圈合併成一次完成。參考下方[程式碼](#one-way-dp)。\n\n# 程式碼\n\n## Two steps DP\n\n```cpp\n/**\n * Author: justin0u0<mail@justin0u0.com>\n * Problem: https://leetcode.com/problems/palindrome-partitioning-ii/\n * Runtime: 74ms\n * Time Complexity: O(N^2)\n * Description:\n *  First calculate isPalindrome for all substring,\n *  then use dp(i) represent the min-cut for substring s[0:i],\n *  then dp(i) = min(dp(j) + 1), if isPalindrome(j + 1, i) = true\n */\n\nclass Solution {\npublic:\n  int minCut(string s) {\n    int n = s.length();\n    vector<vector<bool>> isPalindrome(n + 1, vector<bool>(n));\n    \n    for (int i = n - 1; i >= 0; i--) {\n      isPalindrome[i][i] = true;\n      isPalindrome[i + 1][i] = true;\n      for (int j = i + 1; j < n; j++) {\n        isPalindrome[i][j] = (s[i] == s[j] && isPalindrome[i + 1][j - 1]);\n      }\n    }\n    \n    int *dp = new int[n];\n    for (int i = 0; i < n; i++) {\n      if (isPalindrome[0][i]) {\n        dp[i] = 0;\n      } else {\n        dp[i] = 0x3f3f3f3f;\n        for (int j = 0; j < i; j++) {\n          if (isPalindrome[j + 1][i]) {\n            dp[i] = min(dp[i], dp[j] + 1);\n          }\n        }\n      }\n    }\n    return dp[n - 1];\n  }\n};\n```\n\n## One way DP\n\n```cpp\n/**\n * Author: justin0u0<mail@justin0u0.com>\n * Problem: https://leetcode.com/problems/palindrome-partitioning-ii/\n * Runtime: 60ms\n * Time Complexity: O(N^2)\n * Description: One-way O(N^2) solution\n */\n\nclass Solution {\npublic:\n  int minCut(string s) {\n    int n = s.length();\n    vector<vector<bool>> isPalindrome(n + 1, vector<bool>(n));\n    int *dp = new int[n];\n    for (int i = n - 1; i >= 0; i--) {\n      isPalindrome[i][i] = true;\n      isPalindrome[i + 1][i] = true;\n      dp[i] = 0x3f3f3f3f;\n      for (int j = i + 1; j < n; j++) {\n        isPalindrome[i][j] = (s[i] == s[j] && isPalindrome[i + 1][j - 1]);\n        if (isPalindrome[i][j - 1]) {\n          dp[i] = min(dp[i], dp[j] + 1);\n        }\n      }\n      if (isPalindrome[i][n - 1]) dp[i] = 0;\n    }\n    return dp[0];\n  }\n};\n```\n","tags":["LeetCode","動態規劃（Dynamic Programming, DP）"],"categories":["LeetCode"]},{"title":"LeetCode 375 - Guess Number Higher or Lower II","url":"/LeetCode-Guess-Number-Higher-or-Lower-II/","content":"\n# 題目\n題目連結：[https://leetcode.com/problems/guess-number-higher-or-lower-ii/](https://leetcode.com/problems/guess-number-higher-or-lower-ii/)\n\n猜數字遊戲，答案在 $1 \\sim n$ 之內。\n\n每次猜測一個數字 $x$，如果猜對了則遊戲結束，若猜錯了則需要付 $x$ 元，並且會被告之正確答案大於 $x$ 或是小於 $x$。\n\n找出一種猜數字的方式，使得不管答案是多少，花費都是最少的（也就是不管答案是多少，花費最大的那種答案要盡量小）。\n\n# 範例說明\n\n## Example 1\n\n![](https://assets.leetcode.com/uploads/2020/09/10/graph.png)\n\n<!-- More -->\n\n```\nInput: n = 10\nOutput: 16\nExplanation: The winning strategy is as follows:\n- The range is [1,10]. Guess 7.\n    - If this is my number, your total is $0. Otherwise, you pay $7.\n    - If my number is higher, the range is [8,10]. Guess 9.\n        - If this is my number, your total is $7. Otherwise, you pay $9.\n        - If my number is higher, it must be 10. Guess 10. Your total is $7 + $9 = $16.\n        - If my number is lower, it must be 8. Guess 8. Your total is $7 + $9 = $16.\n    - If my number is lower, the range is [1,6]. Guess 3.\n        - If this is my number, your total is $7. Otherwise, you pay $3.\n        - If my number is higher, the range is [4,6]. Guess 5.\n            - If this is my number, your total is $7 + $3 = $10. Otherwise, you pay $5.\n            - If my number is higher, it must be 6. Guess 6. Your total is $7 + $3 + $5 = $15.\n            - If my number is lower, it must be 4. Guess 4. Your total is $7 + $3 + $5 = $15.\n        - If my number is lower, the range is [1,2]. Guess 1.\n            - If this is my number, your total is $7 + $3 = $10. Otherwise, you pay $1.\n            - If my number is higher, it must be 2. Guess 2. Your total is $7 + $3 + $1 = $11.\nThe worst case in all these scenarios is that you pay $16. Hence, you only need $16 to guarantee a win.\n```\n\n## Example 2:\n\n```\nInput: n = 1\nOutput: 0\nExplanation: There is only one possible number, so you can guess 1 and not have to pay anything.\n```\n\n## Example 3:\n\n```\nInput: n = 2\nOutput: 1\nExplanation: There are two possible numbers, 1 and 2.\n- Guess 1.\n    - If this is my number, your total is $0. Otherwise, you pay $1.\n    - If my number is higher, it must be 2. Guess 2. Your total is $1.\nThe worst case is that you pay $1.\n```\n\n# 想法\n\n首先，以遞迴的想法來說。一開始要求的是猜測 $1 \\sim n$ 的數字的最小花費，定為 `minCost(1, n)`。\n\n假設猜測的數字為 $x$，且 $1\\le x \\le n$，則有三種情形：\n1. 猜中了，則花費為 0，遊戲結束。\n2. 沒猜中，且正確答案大於 $x$，則花費 $x$ 元且繼續猜測 $x+1 \\sim n$。\n3. 沒猜中，且正確答案小於 $x$，則花費 $x$ 元且繼續猜測 $1 \\sim x-1$。\n\n由於三種情況都是有可能發生的，因此：\n\n$$\nminCost(1,n)=\\max \n  \\begin{cases}\n   0 &\\text{case 1} \\\\\n   x+minCost(x+1,n) &\\text{case 2} \\\\\n   x+minCost(1,x-1) &\\text{case 3} \\\\\n  \\end{cases}\n$$\n\n有了上述的式子，我們可以總結並整理，對於猜測 $i \\sim j$ 之間的數字的最小花費，定為 `minCost(i, j)`，我們可以猜測任何一個 $i\\le k \\le j$ 的數字 $k$，因此：\n\n$$\nminCost(i,j)=\\min\n\\begin{Bmatrix}\\max \n    \\begin{Bmatrix}\n      0 \\\\\n      k+minCost(k+1,j) \\\\\n      k+minCost(i,k-1) \\\\\n    \\end{Bmatrix}\n  \\quad\\forall\\ i\\le k \\le j\n\\end{Bmatrix}\n$$\n\n# 實作細節\n\n實作上，當然可以直接的使用遞迴來求出答案，但是會發現很多情況下重複的 `minCost(i, j)` 被呼叫，但其實對於一樣的 `minCost(i, j)`，並不需要重複的求得。\n\n因此，可以記憶化搜索的方式，也就是開一個二維的陣列 `dp[i][j]` 代表 `minCost(i, j)` 的答案。初始化時使全部的 `dp[i][j] = -1`，則呼叫 `minCost(i, j)` 時可以先檢查 `dp[i][j]`，若 `dp[i][j] != -1` 則直接回傳 `dp[i][j]`。\n\n有了這樣的想法後，其實可以很輕易的將 top-down 的遞迴改為 botton-up 的迴圈形式 DP；改為迴圈形式之 DP 時，要**注意迴圈的順序**，由於大區間的答案是由小區間求得的，因此要**先求得小區間答案**，一般情況下，都可以使用以下的迴圈順序：\n\n```cpp\nfor (int i = n - 1; i >= 0; i--) {\n  for (int j = i + 1; j < n; j++) {\n    cout << i << ' ' << j << endl;\n    dp[i][j] = ...;\n  }\n}\n```\n\n此時的 DP 狀態為 `dp(i, j)` 代表猜測數字 $i \\sim j$ 的最小花費，轉移為：\n$$dp(i,j)=\\min\\bigg(\\max\\big(dp(i,k-1), dp(k+1,i)\\big)+k\\quad\\forall\\ k\\in [i,j]\\bigg)$$\n\n注意邊界情況，當 $i=j$，一定會猜中，因此 **$dp(i,i)=1$**。\n\n最後，DP 的狀態有 $N^2$ 種，對於每個狀態需要花至多 $O(N)$ 的時間轉移，因此總時間複雜度為 $O(N^3)$。\n\n另外，由於筆者的陣列只有開恰好 $n$ 格，因此要注意 `dp(i,j)` 其實是對應到 $i+1\\sim j+1$ 的最小花費。\n\n# 程式碼\n\n## Top-down DP\n\n```cpp\n/**\n * Author: justin0u0<mail@justin0u0.com>\n * Problem: https://leetcode.com/problems/guess-number-higher-or-lower-ii/\n * Runtime: 164ms\n * Time Complexity: O(N^3)\n * Description: Top-down DP\n */\n\nclass Solution {\nprivate:\n  int** dp;\n  int minCost(int i, int j) {\n    if (i > j)\n      return 0x3f3f3f3f;\n    if (i == j)\n      return 0;\n\n    if (dp[i][j] != -1)\n      return dp[i][j];\n\n    dp[i][j] = min((i + 1) + minCost(i + 1, j), minCost(i, j - 1) + (j + 1));\n    for (int k = i + 1; k < j; k++) {\n      dp[i][j] = min(dp[i][j], max(minCost(i, k - 1), minCost(k + 1, j)) + k + 1);\n    }\n    return dp[i][j];\n  }\npublic:\n  int getMoneyAmount(int n) {\n    dp = new int*[n];\n    for (int i = 0; i < n; i++) {\n      dp[i] = new int[n];\n      memset(dp[i], -1, sizeof(int) * n);\n    }\n    return minCost(0, n - 1);\n  }\n};\n```\n\n## Bottom-up DP\n\n```cpp\n/**\n * Author: justin0u0<mail@justin0u0.com>\n * Problem: https://leetcode.com/problems/guess-number-higher-or-lower-ii/\n * Runtime: 40ms\n * Time Complexity: O(N^3)\n * Description: Bottom-up DP\n */\n\nclass Solution {\npublic:\n  int getMoneyAmount(int n) {\n    int** dp = new int*[n];\n    for (int i = 0; i < n; i++) {\n      dp[i] = new int[n]();\n    }\n\n    for (int i = n - 1; i >= 0; i--) {\n      for (int j = i + 1; j < n; j++) {\n        dp[i][j] = min((i + 1) + dp[i + 1][j], dp[i][j - 1] + (j + 1));\n        for (int k = i + 1; k < j; k++) {\n          dp[i][j] = min(dp[i][j], max(dp[i][k - 1], dp[k + 1][j]) + (k + 1));\n        }\n      }\n    }\n    return dp[0][n - 1];\n  }\n};\n```\n","tags":["LeetCode","動態規劃（Dynamic Programming, DP）"],"categories":["LeetCode"]},{"title":"LeetCode 685 - Redundant Connection II","url":"/LeetCode-Redundant-Connection-II/","content":"\n# 題目\n題目連結：[https://leetcode.com/problems/redundant-connection-ii/](https://leetcode.com/problems/redundant-connection-ii/)\n\n給定一個 `N` 個點的有根樹，再加上一條邊。\n\n求出移除哪一條邊可以使得圖變回有根樹，若有多種解答，則輸出給定的邊中比較後面的那一條。\n\n# 範例說明\n\n## Example 1:\n\n![](/assets/LeetCode-Redundant-Connection-II/graph1.jpeg)\n\n```\nInput: edges = [[1,2],[1,3],[2,3]]\nOutput: [2,3]\n```\n\n<!-- More -->\n\n## Example 2:\n\n![](/assets/LeetCode-Redundant-Connection-II/graph2.jpeg)\n\n```\nInput: edges = [[1,2],[2,3],[3,4],[4,1],[1,5]]\nOutput: [4,1]\n```\n\n# 想法\n\n## 分類討論\n\n首先，在一張有根樹上面 DFS，扣除掉 DFS 所走的 Tree edges 後，最後加上的邊可能產生的情況有以下三種：\n\n1. **Back edge**：邊 `u->v` 中，`v` 是 `u` 的祖先。\n2. **Forward edge**：邊 `u->v` 中，`u` 是 `v` 的祖先。\n3. **Cross edge**：邊 `u->v` 中，`u` 不是 `v` 的祖先且 `v` 也不是 `u` 的祖先。\n\n<img src=\"/assets/LeetCode-Redundant-Connection-II/case.jpg\" width=\"50%\">\n\n我們知道一棵有根樹中，**除了 root 之外，每一個點的入度為 1**。而 **Forward edge** 以及 **Cross edge** 的情況，可以發現這兩種情況都會使得**有一個點的入度為二**，也就是有兩個父親節點。並且，假設造成入度為二的兩條邊為 `e1` 以及 `e2`，可以發現移除 `e1` 與移除 `e2` 都可以使圖還原回一棵有根樹。\n\n再來剩下 **Back edge** 的情況，我們知道當有 back edge 時，必定會有有向環的產生。這裡我們分成兩種情況討論：\n1. (1.1) **Back edge** 的邊 `u->v` 中，`v` 是樹的根：這時**不會有入度為二的點產生**，但是可以發現不管移除環上的哪一個點，都可以使圖還原回一棵有根樹。\n2. (1.2) **Back edge** 的邊  `v` 不是樹的根：這時**一樣有入度為二的點產生**，並且在這種情況必須要移除 back edge 才能使得圖還原回一棵有根樹。\n\n## 並查集 Union Find/Disjoint Set\n\n接著我們暫停一下，介紹一個資料結構 **並查集**。\n\n**並查集** 是一種用於合併集合、查詢兩個集合是否屬於同一個集合的資料結構。其中單次查詢、合併的平均時間複雜度都是 $O(\\alpha(n))$，其中 $\\alpha$ 為[反阿克曼函數](https://zh.wikipedia.org/wiki/%E9%98%BF%E5%85%8B%E6%9B%BC%E5%87%BD%E6%95%B8#%E5%8F%8D%E5%87%BD%E6%95%B8)，可以想成是非常小的數即可。也就是說，並查集是非常高效的資料結構。\n\n使用並查集，一開始每一個點都屬於一個集合。假設給定的邊集合是一個樹，則會發現每次合併一條邊的兩端點 `u` 與 `v` 時，`u` 與 `v` 一定屬於不同的集合，因為樹上的每一條邊都是 cut edge，連接著兩個 components。\n\n也就是說，當給定的邊集合有環時，則會發現在合併環上的最後一條邊時，邊的兩端點 `u` 與 `v` 已經在同一個集合裡面了。\n\n**p.s. 這裡的環指的是無向的環，因為並查集是沒有方向性的。**\n\n## 總結\n\n接著我們總結要如何找到需要移除的邊：\n1. 沒有入度為二的點，則為情況 1.1 **Back edge 且 `v` 是 root**，則只要找到環上的最後一條邊即是答案。\n  \n    根據上述並查集的介紹，只要不斷的將邊的兩端點進行集合的合併，必定會有一條邊在合併之前，邊的兩個端點已經在同一個集合內，此時這條邊 `e` 即是我們要找的答案。\n\n2. 有入度二的點，可能是情況 2 **Forward edge**、情況 3 **Cross edge** 或是情況 1.2 **Back edge 且 `v` 不是 root**。\n\n    假設造成入度為二的兩條邊為 `e1` 與 `e2`，其中 `e2` 是比較晚出現的那條。\n    \n    **Forward edge** 與 **Cross edge** 的情況較簡單，只要刪除 `e2` 即可。\n\n    在 **Back edge 且 `v` 不是 root** 的情況下，由於邊出現的順序是不一定的，所以 back edge 可能是 `e1` 也可能是 `e2`，當然我們可以透過從 root 進行 DFS 來找到 back edge 是哪一條。\n    \n    然而我們想要一個更 general 的做法。考慮上面並查集的做法，因為圖中還是有環，所以可以找到一條邊使得合併之前，兩個端點已經在一個集合內，然而這條邊可能不是 back edge 而是環上的其他邊，所以這個方法還是區分不出來 back edge 是 `e1` 還是 `e2`。\n\n    **考慮一個方法，我們在合併邊時，不將 `e2` 加入合併的過程，也就是，在出現第二條入度為 2 的邊時，不將這條邊做集合的合併。**如此一來，若最後還是出現了環（也就是有一條邊在合併之前兩端點就在同一個集合內了）的情況，則我們知道 `e1` 才是 back edge\b；反之，`e2` 才是 back edge。\n\n    接著我們要確認這個方法會不會影響先前的判斷，可以發現在情況1.1 **Back edge 且 `v` 是 root**，由於沒有入度 2 的點，所以所有的邊還是會加入合併的過程，因此不影響。另外，在情況2 **Forward edge** 與情況 3 **Cross edge**，不將 `e2` 這條邊做集合的合併則圖中一定沒有環，所以 `e2` 還是我們要刪除的邊，一樣是正確的。\n\n# 實作細節\n\n實作上，`pa[x]=y` 代表 `x` 與 `y` 在同一個集合內，利用遞迴可以不斷向上找，當 `pa[x]=0` 則代表已經找完了。這裡對並查集就不多介紹了，有興趣的讀者可以上網查詢。\n\n`parent[i]` 用來記錄指向點 `i` 的邊的索引值 ，初始化時所有的 `parent[i]=0`。因此當一條邊 `u->v` 要加入時發現 `parent[v]` 已經不等於 0 時，可以知道這條邊即是第二條造成入度為 2 的邊，記錄為 `e2`，同時 `e1`，第一條造成入度為 2 的邊，即是 `parent[v]` 所記錄的邊。\n\n當邊不是 `e2` 時，則將邊的兩端點進行合併，並且注意合併前如果兩端點的集合已經相同，則紀錄 `e` 為造成環的最後一條邊。\n\n最後，先判斷有沒有入度為 2 的邊（可以判斷 `e1` 與 `e2` 有沒有被賦值過），若沒有的話，則必定是情況1.1，所以直接返回 `e` 即可；反之，若有入度為 2 的邊，則如果沒有環出現，要刪除的邊是較晚出現的 `e2`，否則一定是情況1.2 且要刪除的邊為 `e1`。\n\n# 程式碼\n\n```cpp\n/**\n * Author: justin0u0<mail@justin0u0.com>\n * Problem: https://leetcode.com/problems/redundant-connection-ii/\n * Runtime: 4ms\n */\n\nclass Solution {\nprivate:\n  int findSet(int* pa, int x) {\n    return (!pa[x]) ? x : (pa[x] = findSet(pa, pa[x]));\n  }\npublic:\n  vector<int> findRedundantDirectedConnection(vector<vector<int>>& edges) {\n    int n = (int)edges.size();\n\n    int *pa = new int[n + 1]();\n    int *parent = new int[n + 1]();\n\n    int e1 = -1, e2; // e1, e2 are edges that cause a node to have 2 in degree\n    int e = -1; // e is the index of edge that cause a cycle last\n    for (int i = 0; i < n; i++) {\n      auto& edge = edges[i];\n      if (parent[edge[1]]) { // Found vertex edge[1] is the vertex that in degree = 2\n        e1 = parent[edge[1]] - 1;\n        e2 = i;\n      } else {\n        parent[edge[1]] = i + 1;\n\n        // We skip adding e2\n        int fx = findSet(pa, edge[0]);\n        int fy = findSet(pa, edge[1]);\n        if (fx != fy) // no cycle found, merge\n          pa[fx] = fy;\n        else // cycle found, the last edge that cause a cycle is i\n          e = i;\n      }\n    }\n\n    if (e1 == -1)\n      return edges[e];\n    if (e == -1)\n      return edges[e2];\n    return edges[e1];\n  }\n};\n\n```\n","tags":["LeetCode","Graph","Union Find"],"categories":["LeetCode"]},{"title":"LeetCode 300 - Longest Increasing Subsequence","url":"/LeetCode-Longest-Increasing-Subsequence/","content":"\n# 題目\n題目連結：[https://leetcode.com/problems/longest-increasing-subsequence/](https://leetcode.com/problems/longest-increasing-subsequence/)\n\n找到最長遞增子序列（LIS）的長度。\n\n# 範例說明\n\n## Example 1:\n\n```\nInput: nums = [10,9,2,5,3,7,101,18]\nOutput: 4\nExplanation: The longest increasing subsequence is [2,3,7,101], therefore the length is 4.\n```\n\n<!-- More -->\n\n## Example 2:\n\n```\nInput: nums = [0,1,0,3,2,3]\nOutput: 4\n```\n\n## Example 3:\n\n```\nInput: nums = [7,7,7,7,7,7,7]\nOutput: 1\n```\n\n# 想法\n\n## `O(N^2)`\n\n有一種常見的 `O(N^2)` 動態規劃。考慮動態規劃的狀態與轉移，定義狀態 `dp(i)` 等於以第 `i` 個數字為結尾的序列的 LIS 長度，轉移即為：\n\n$$dp(i)=max(1,dp(j) + 1)\\quad\\forall\\ j\\lt i\\And nums[j]\\lt nums[i]$$\n\n如此的狀態轉移十分直觀，以第 `i` 個數字為結尾的序列，代表我們要選擇 `nums[i]`，那麼 `nums[i]` 可以放在 `nums[j]` 後面，如果 `j < i && nums[j] < nums[i]`，因此以 `nums[i]` 為結尾的最長遞增子序列即為所有符合條件的 `j` 中，`dp[j]` 最大的值再加一。若沒有符合的 `j`，則以 `nums[i]` 結尾的最長遞增子序列至少也為 1。\n\n由於狀態有 `N` 種，每次轉移都要花 `O(N)` 的時間，因此總時間複雜度為 `O(N^2)`。\n\n## `O(NlogN)`\n\n要達到 `O(NlogN)` 的想法，首先考慮另一種 `O(N^2)` 的動態規劃。一樣考慮狀態與轉移：\n\n定義狀態 `dp(j)` 代表長度為 `j` 的最長遞增子序列結束在 `dp(j)` 這個數字，若有多個滿足，則選數字最小的。\n\n接著對 `nums[0]`, `nums[1]` ... 進行 N 次的轉移：\n\n假設 `dp(1) = 1, dp(2) = 3, dp(3) = 5, dp(4) = 7`，則當要對 `nums[i] = 4` 進行轉移時，數字 `4` 能產生的最長遞增子序列為 3，因為我們知道 `dp(2) = 3`，所以數字 `4` 可以插入在數字 `3` 之後形成長度 3 的遞增子序列。但是 `dp(3)` 已經有一個數字 `5` 了，因此要選數字較小的來當 `dp(3)` 的值，所以要使 `dp(3)=nums[i]`，還需要有一個條件 `nums[i] < dp(3)`。\n\n因此轉移如下：\n\n$$dp(j)=\n  \\begin{cases}\n    nums[i] &\\text{if } dp(j-1)\\lt nums[i]\\lt dp(j) \\\\\n    dp(j) &\\text{else }\n  \\end{cases}\n$$\n\n為了方便實作，可以另 `dp(0)=-INF` 且當 `i > 0`，初始化 `dp(i)=INF`。\n\n```cpp\nconst INF = 1e9 + 10;\nvector<int> dp(n + 1, INF);\ndp[0] = -INF;\n\nfor (int i = 0; i < n; i++) {\n  for (int j = 1; j <= n; j++) {\n    if (dp[j - 1] < nums[i] && nums[i] < dp[j])\n      dp[j] = nums[i];\n  }\n}\n```\n\n最後，對於所有的 `dp(i)` 且 `dp(i) != INF` 的 `i` 即為最長遞增子序列的長。\n\n因此總時間複雜度為 `O(N^2)`。\n\n觀察上述的轉移與程式碼，可以得到兩個性質：\n1. `dp(i-1) < dp(i)`。\n2. `nums[i]` 每次恰好更新一個數字。\n\n由於這兩個性質，可以發現只要在 `dp` 陣列上，利用二分搜找到**大於等於 nums[i] 的第一個數字**並取代之，即可將時間複雜度減低到 `O(NlogN)`。\n\n# 實作細節\n\n實作上，可以不用先開好長度為 `N + 1` 的 `dp` 陣列，只在需要的時候增加 `dp` 陣列的長度（也就是不多紀錄值為 `INF` 的部分）：\n\n對於上述的程式碼，當 `nums[i]` 更新的數字是 `INF`，代表多了一個數字需要紀錄，這時才需要增加 `dp` 陣列的長度，而此種情況代表 `nums[i]` 比最後一個非 `INF` 的數字還要大。\n\n如此一來，最後陣列的長度即為最長遞增子序列的長度減一（需要扣除第零個數字 `-INF`）。\n\n另外，找**大於等於 nums[i] 的第一個數字**，可以利用 C++ 的 `lower_bound` 來實作。\n\n# 程式碼\n\n```cpp\n/**\n * Author: justin0u0<mail@justin0u0.com>\n * Problem: https://leetcode.com/problems/longest-increasing-subsequence/\n * Runtime: 8ms\n */\n\nclass Solution {\npublic:\n  int lengthOfLIS(vector<int>& nums) {\n    vector<int> lis{-10001};\n    for (int num: nums) {\n      if (num > lis.back())\n        lis.emplace_back(num);\n      else\n        *lower_bound(lis.begin(), lis.end(), num) = num;\n    }\n    return (int)lis.size() - 1;\n  }\n};\n\n```\n","tags":["LeetCode","動態規劃（Dynamic Programming, DP）","二分搜（Binary Search）"],"categories":["LeetCode"]},{"title":"LeetCode 907 - Sum of Subarray Minimums","url":"/LeetCode-Sum-of-Subarray-Minimums/","content":"\n# 題目\n題目連結：[https://leetcode.com/problems/sum-of-subarray-minimums/](https://leetcode.com/problems/sum-of-subarray-minimums/)\n\n給定一個序列，求出所有子區間的最小值的和。\n\n# 範例說明\n\n## Example 1:\n\n```\nInput: arr = [3,1,2,4]\nOutput: 17\nExplanation: \nSubarrays are [3], [1], [2], [4], [3,1], [1,2], [2,4], [3,1,2], [1,2,4], [3,1,2,4]. \nMinimums are 3, 1, 2, 4, 1, 1, 2, 1, 1, 1.\nSum is 17.\n```\n\n<!-- More -->\n\n## Example 2:\n\n```\nInput: arr = [11,81,94,43,3]\nOutput: 444\n```\n\n# 想法\n\n## 由 O(N^3) 到 O(N^2) 的想法\n\n首先，最簡單的方法為枚舉每個區間，再求出區間最小值並總和。\n\n以 `i` 為左界，以 `j` 為右界：\n```cpp\nint sum = 0;\nfor (int i = 0; i < n; i++) {\n  for (int j = i; j < n; j++) {\n    int minValue = arr[i];\n    for (int k = i; k <= j; k++) {\n      minValue = min(minValue, arr[i]);\n    }\n    sum += minValue;\n  }\n}\nreturn sum;\n```\n\n可以容易地發現，對於相同的左界 `i` 來說，每次右界 `j` 都只增加一個數字。因此只要將新增的數字與上一輪計算的 `minValue` 進行更新，就可以不用內層的 `k` 迴圈了。\n```cpp\nint sum = 0;\nfor (int i = 0; i < n; i++) {\n  int minValue = arr[i]; // minValue 紀錄 i ~ j 的最小值\n  for (int j = i; j < n; j++) {\n    minValue = min(minValue, arr[j]); // 新增了 arr[j] 這個數字，更新 minValue\n    sum += minValue;\n  }\n}\nreturn sum;\n```\n\n如此一來可以得到一個 `O(N^2)` 的算法。\n\n## 由 O(N^2) 到 O(N) 的想法\n\n我們改變迴圈的順序，改為先枚舉右邊界再枚舉左邊界，注意迴圈 `i` 的順序以保證對於同一個右邊界 `j`，`i` 的改變是使區間變大的：\n```cpp\nint sum = 0;\nfor (int j = 0; j < n; j++) {\n  int minValue = arr[j]; // minValue 紀錄 i ~ j 的最小值\n  for (int i = j; i >= 0; i--) {\n    minValue = min(minValue, arr[i]); // 新增了 arr[i] 這個數字，更新 minValue\n    sum += minValue;\n  }\n}\nreturn sum;\n```\n\n對於每一個右邊界 `j` 所形成的區間，可以觀察出只有由右而左遞減的數字才是有用的，舉例來說，以 `[3, 1, 7, 5]` 的 `5` 為右邊界，所形成的區間如下：\n\n|     Subarray     | Decreasing (<-) | Minimum |  Sum  |\n| ---------------- | --------------- | ------- | ----- |\n|  `[         5]`  | `[         5]`  |    5    |   5   |\n|  `[      7, 5]`  | `[      x, 5]`  |    5    |  10   |\n|  `[   1, 7, 5]`  | `[   1, x, 5]`  |    1    |  11   |\n|  `[3, 1, 7, 5]`  | `[x, 1, x, 5]`  |    1    |  12   |\n\n可以發現數字 `7` 對於以 `5` 為右邊界的區間來說並沒有貢獻，因為所有以 `5` 為右邊界的區間都會有數字 `5`；\n而對於以 `5` 為右邊界，左邊界比數字 `1` 還要小的數字來說，所有的區間都會包含數字 `1`，因此比數字 `1` 大的數字也沒有用。\n因而產生了一個由右而左的遞減序列。\n\n有了這個性質，我們可以維護一個由右而左遞減的序列，以知道哪些數字是有用的。知道了哪些數字是有用的外，還需要知道這些數字的用處有多大，以很快的計算出以 `j` 為右界的區間的最小值的和。\n\n可以發現上表中，最後計算出來的 `Sum` 是 `12 = 1 * 2 + 5 * 2`，假設：\n- 右區間變大，增加一個數字 `4`：`Decreasing -> [x, 1, x, x, 4]`，`Sum = 1 * 2 + 4 * 3 = 14`\n- 右區間變大，增加一個數字 `6`：`Decreasing -> [x, 1, x, x, 4, 6]`，`Sum = 1 * 2 + 4 * 3 + 6 * 1 = 20`。\n- 右區間變大，增加一個數字 `0`：`Decreasing -> [x, x, x, x, x, x, 0]`，`Sum = 0 * 7 = 0`。\n- 右區間變大，增加一個數字 `8`：`Decreasing -> [x, x, x, x, x, x, 0, 8]`，`Sum = 0 * 7 + 8 * 1`。\n\n可以發現，一個數字的貢獻（下面稱作 `weight`）即是他左邊的 `x` 的數量加一。也等於看成是他左邊所有數的 `weight` 加一。\n\n最後，由左而右，每次將右區間變大（增加一個數字），並且維護由右而左遞減的序列以及一個值 `Sum`。因為每個數字最多只會進入、離開棧一次，所以總時間複雜度為 `O(N)`。\n\n# 實作細節\n\n要實作一個單調遞增/遞減的序列，並且只有**在同一邊增加數字**的操作時，要使用的資料結構是 `stack`，或是可以稱為 **單調棧（Monotone Stack）**。\n\n要利用棧維護一個由右而左遞減的序列，每當右區間變大時，不斷將棧\b頂部比此元素大的數字都移除即可。\n\n本題除了要紀錄加入棧的元素的值外，還額外需要紀錄每個數字的貢獻 `weight`，以快速的計算區間最小值的和。\n\n最後，在 **由 O(N^2) 到 O(N) 的想法** 的最開始，筆者並沒有特別提到為何要將迴圈的順序改變。改變迴圈的順序主要是想要將區間變成由小到大，也就是當 `j` 變大時，右區間變大，因此區間的大小是增加的。<font color=\"red\">區間大小變大的好處是代表我們已經看過了較小區間的資訊，才有可能可以依照那些資訊來快速的找出答案</font>。\n\n也就是現在的想法 **將右邊界由左而右，維護一個由右而左遞減的序列**，其實也可以改為 **將左邊界由右而左，維護一個由左而右的遞增序列**。兩個方法都是可行的！\n\n# 程式碼\n\n```cpp\n/**\n * Author: justin0u0<mail@justin0u0.com>\n * Problem: https://leetcode.com/problems/sum-of-subarray-minimums/\n * Runtime: 76ms\n */\n\nclass Solution {\nprivate:\n  const int mod = 1e9 + 7;\npublic:\n  int sumSubarrayMins(vector<int>& arr) {\n    stack<pair<int, int>> stk; // {值，貢獻}\n\n    int answer = 0; // 答案\n    long long sum = 0; // 維護當前 stk 內的總和\n    for (int value: arr) {\n      int weight = 1;\n      while (!stk.empty() && value < stk.top().first) { // 刪除棧頂所有比當前數字大的數字，以維護單調性\n        sum -= stk.top().first * stk.top().second; // 維護棧內 sum 的值\n        weight += stk.top().second; // 每刪除一個數字，就吸收了他的貢獻\n        stk.pop();\n      }\n      stk.push({value, weight});\n      sum += value * weight; // 維護棧內 sum 的值\n      answer = (answer + sum % mod) % mod; // sum 為以 value 為右邊界的所有區間的最小值的和\n    }\n    return answer;\n  }\n};\n\n```\n","tags":["LeetCode","堆疊（Stack）","單調棧（Monotone Stack）"],"categories":["LeetCode"]},{"title":"LeetCode 20 - Valid Parentheses","url":"/LeetCode-Valid-Parentheses/","content":"\n# 題目\n題目連結：[https://leetcode.com/problems/valid-parentheses/](https://leetcode.com/problems/valid-parentheses/)\n\n給定一個包含只包含 `'('`、`')'`、`'{'`、`'}'`、`'['`、`']'` 的字串，問給定的字串是不是一個合法的括號字串。\n\n# 範例說明\n\n## Example 1:\n\n```\nInput: s = \"()\"\nOutput: true\n```\n\n## Example 2:\n\n```\nInput: s = \"()[]{}\"\nOutput: true\n```\n\n<!-- More -->\n\n## Example 3:\n\n```\nInput: s = \"(]\"\nOutput: false\n```\n\n## Example 4:\n\n```\nInput: s = \"([)]\"\nOutput: false\n```\n\n## Example 5:\n\n```\nInput: s = \"{[]}\"\nOutput: true\n```\n\n# 想法＆實作細節\n\n由左到右，任一個右括號只能與已經出現的左括號匹配，且他們之間不能有其他還未匹配的括號。\n\n且一個右括號如果當下沒有辦法被匹配的話，代表字串是不合法的，因為接下來再也沒有可以匹配這個右括號的選擇了。\n\n由左到右，將未使用的左括號依序推入 `stack` 內，當右括號出現時，其只能匹配 `stack` 的頂端元素。若有 `stack` 的頂端元素與其匹配，則將左括號從 `stack` 中移除。否則字串不合法，回傳 `false`。\n\n最後不要忘記一個合法的括號字串，所有的左括號都應有匹配，因此最後 `stack` 內的元素應該為空。\n\n# 程式碼\n\n```cpp\nclass Solution {\npublic:\n  bool isValid(string s) {\n    stack<char> box;\n    for (char ch: s) {\n      if (ch == '(' || ch == '{' || ch == '[') {\n        // 將未使用的左括號推入 stack 內\n        box.push(ch);\n      } else {\n        // 堆疊為空/堆疊的頂端元素與當前的右括號不匹配，則括號字串不合法\n        if (box.empty()\n             || (ch == ')' && box.top() != '(')\n             || (ch == '}' && box.top() != '{')\n             || (ch == ']' && box.top() != '['))\n          return false;\n        // 左括號被匹配，離開 stack\n        box.pop();\n      }\n    }\n\n    // 合法的括號字串所有的左括號都應該被匹配\n    return box.empty();\n  }\n};\n```\n","tags":["LeetCode","堆疊（Stack）"],"categories":["LeetCode"]},{"title":"LeetCode 456 - 132 Pattern","url":"/LeetCode-132-Pattern/","content":"\n# 題目\n題目連結：[https://leetcode.com/problems/132-pattern/](https://leetcode.com/problems/132-pattern/)\n\n給定一個序列 `nums`，問是否能找到三個數字 `nums[i]`、`nums[j]` 與 `nums[k]`，使得 `nums[i] < nums[k] < nums[j]` 且 `i < j < k`。\n\n# 範例說明\n\n## Example 1:\n\n```\nInput: nums = [1,2,3,4]\nOutput: false\nExplanation: There is no 132 pattern in the sequence.\n```\n\n<!-- More -->\n\n## Example 2:\n\n```\nInput: nums = [3,1,4,2]\nOutput: true\nExplanation: There is a 132 pattern in the sequence: [1, 4, 2].\n```\n\n## Example 3:\n\n```\nInput: nums = [-1,3,2,0]\nOutput: true\nExplanation: There are three 132 patterns in the sequence: [-1, 3, 2], [-1, 3, 0] and [-1, 2, 0].\n```\n\n# 想法\n\n## 簡單的 O(N^2) 想法\n\n首先，只考慮找到 `nums[i] < nums[j]` 且 `i < j`，最單純的想法當然是使用兩個迴圈遍歷所有的 `i` 與 `j`，並檢查有沒有 `nums[i] < nums[j]` 的情況，這樣的時間複雜度是 `O(N^2)`。\n```cpp\nfor (int j = 0; j < n; j++)\n  for (int i = 0; i < j; i++)\n    if (nums[i] < nums[j])\n      return true;\n```\n\n可以發現，這裡筆者特別把 `i`、`j` 迴圈的順序對調了。如此一來，觀察中間的 `i` 迴圈，可以發現每一次 `i` 迴圈都只比上一次多檢查了一個數字。並且，對於 `nums[j]` 來說，要檢查有沒有 `nums[i] < nums[j]` 且 `i < j` 等價於檢查 `min(nums[0] ~ nums[i])` 有沒有小於 `nums[j]`。有了這兩個性質，就可以利用一個變數 `minValue`，紀錄 `nums[0] ~ nums[j - 1]` 的最小值，對於每一個 `nums[j]` 檢查 `minValue` 有沒有小於 `nums[j]` 即可。\n```cpp\nint minValue = INT_MAX;\nfor (int j = 0; j < n; j++) {\n  if (minValue < nums[j])\n    return true;\n  minValue = min(minValue, nums[j]);\n}\n```\n\n到了這裡，回到原先的題目，利用額外的一個迴圈檢查是否數字 `nums[k]` 滿足條件即可。\n```cpp\nint minValue = INT_MAX;\nfor (int j = 0; j < n; j++) {\n  if (minValue < nums[j]) { // 可省略，裡面的 if 已包含 minValue < nums[j] 的判斷\n    for (int k = j + 1; k < n; k++)\n      if (minValue < nums[k] && nums[k] < nums[j])\n        return true;\n  }\n  minValue = min(minValue, nums[j]);\n}\n```\n\n## 由 O(N^2) 到 O(N) 的想法一\n\n一樣使用上述的想法，要將兩個迴圈變成一個迴圈的首要條件就是先讓裡面的迴圈變為一次增加一個數字，我們改變外層迴圈的順序。\n\n```cpp\nint minValue = INT_MAX;\nfor (int j = n - 1; j >= 0; j--) {\n  for (int k = j + 1; k < n; k++)\n    if (minValue < nums[k] && nums[k] < nums[j])\n      return true;\n  minValue = min(minValue, nums[j]); // minValue cannot be maintained\n}\n```\n\n這時會發現原本的 `minValue` 紀錄著 `nums[0] ~ nums[j - 1]` 的最小值，因為現在的迴圈順序不是一次增加一個 `nums[j]`，而是一次減少一個 `nums[j]`，而無法紀錄了。\n\n因此，可以將 `minValue` 的計算與之分離。\n\n```cpp\nvector<int> minValues(n);\nint minValue = INT_MAX;\nfor (int j = 0; j < n; j++) {\n  minValues[i] = minValue;\n  minValue = min(minValue, nums[i]);\n}\nfor (int j = n - 1; j >= 0; j--) {\n  for (int k = j + 1; k < n; k++)\n    if (minValues[j] < nums[k] && nums[k] < nums[j])\n      return true;\n```\n\n現在內層的 `k` 迴圈每次都增加一個檢查一個數字 `nums[j]`，可以觀察到：\n1. 比 `minValues[j]` 還小的數字都沒有用，再下一輪之後也不會有用，因為 `minValues[j]` 只會越來越大，所以 `nums[k]` 在這輪比 `minValues[j]` 小的話，那再下一輪也會比 `minValues[j]` 小。\n2. 排除所有 `nums[k]` 小於 `minValues[j]` 的數字後，若最小的 `nums[k]` 比 `nums[j]` 小，則找到答案。\n\n利用一個堆疊，維護一個遞增序列。每次先將比 `minValues[j]` 小的數字都移除，因為序列是遞增的，所以只要不斷的移除堆疊頂部元素即可。完成後堆疊內的元素都比 `minValues[j]` 小了，且堆疊為遞增的，因此只要比較堆疊頂部元素若比 `nums[j]` 小，則找到答案。若沒有，則直接將 `nums[j]` 加入到堆疊中，這裡不需多做檢查，因為能加入到堆疊中代表堆疊為空或是 `nums[j]` 小於堆疊頂部元素，因此直接加入後堆疊還是遞減的。\n\n因為每一個元素只會被加入、離開堆疊一次，因此總時間複雜度是 `O(N)`。\n\n程式碼見下方。\n\n## 由 O(N^2) 到 One Pass O(N) 的想法二\n\n**待補**\n\n# 實作細節\n\n# 程式碼\n\n## 想法一 Time O(N), Space O(N)\n```cpp\n/**\n * Author: justin0u0<mail@justin0u0.com>\n * Problem: https://leetcode.com/problems/132-pattern/\n * Runtime: 12ms\n */\n\nclass Solution {\npublic:\n  bool find132pattern(vector<int>& nums) {\n    int n = (int)nums.size();\n    vector<int> minValues(n);\n\n    int minValue = nums[0];\n    for (int i = 0; i < n; i++) {\n      minValues[i] = minValue;\n      minValue = min(minValue, nums[i]);\n    }\n    stack<int> stk;\n    for (int i = n - 1; i >= 0; i--) {\n      while (!stk.empty() && stk.top() <= minValues[i])\n        stk.pop();\n      if (!stk.empty() && stk.top() < nums[i])\n        return true;\n      stk.push(nums[i]);\n    }\n    return false;\n  }\n};\n\n```\n\n## 想法二 Time O(N), Space O(N)\n\n**待補**","tags":["LeetCode","堆疊（Stack）","單調棧（Monotone Stack）"],"categories":["LeetCode"]},{"title":"LeetCode 402 - Remove K Digits","url":"/LeetCode-Remove-K-Digits/","content":"\n# 題目\n題目連結：[https://leetcode.com/problems/remove-k-digits/](https://leetcode.com/problems/remove-k-digits/)\n\n給定一個整數，要求移除恰好 k 個數字（字元）使得移除後的整數最小。\n\n# 範例說明\n\n## Example 1:\n\n```\nInput: num = \"1432219\", k = 3\nOutput: \"1219\"\nExplanation: Remove the three digits 4, 3, and 2 to form the new number 1219 which is the smallest.\n```\n\n<!-- More -->\n\n## Example 2:\n\n```\nInput: num = \"10200\", k = 1\nOutput: \"200\"\nExplanation: Remove the leading 1 and the number is 200. Note that the output must not contain leading zeroes.\n```\n\n## Example 3:\n\n```\nInput: num = \"10\", k = 2\nOutput: \"0\"\nExplanation: Remove all the digits from the number and it is left with nothing which is 0.\n```\n\n# 想法\n\n首先，因為要移除恰好 k 個數字，所以不管移除哪一些數字，最後得到的整數長度都是一樣的。\n\n因為題目要求要得到最小的整數，且**不管移除哪一些數字，最後得到的整數長度都是一樣的**，所以最後得到的數字中，越左邊的位（也就是高位數）應該要盡量小。\n\n因此，由左而右的將數字加入到答案整數 `ans`，若**當前要加入的 `digit` 比目前 `ans` 的最低位還要小且還有額度可以刪除數字，則可以不斷刪除 `ans` 中最低位，讓 `digit` 前進到更高的位數使得 `ans` 變得更小**。\n\n其實這題也可以想成做 k 次刪除的動作，若只看一次的刪除，而使得數字要最小，會發現要刪除的數字是由高位數到低位數中，第一次出現遞減的位置來刪除。因為上面提到，高位數的部分應該要盡量小，且出現遞減代表可以把大的數字刪除使得小的數字往高位數前進，因此以同樣的方式進行 k 次的刪除動作也會得到相同的答案。有了這個想法之後，可以確定實作方法是使用一個 `stack` 來維護單調遞增的序列（由高位數到低位數）。\n\n# 實作細節\n\n實作上，可以使用一個 `stack` 來完成，將 `stack` 的底部當成是最高位數，由左而右的遍歷每一個 `digit`，若還有刪除的額度（`k > 0`）且 `stack` 中的最低位（`stack.top()`）比 `digit` 還要小，則不斷的將數字從 `stack` 中移除（`stack.pop()`）。\n\n最後要注意兩件事情：\n1. 要確保刪除恰好 k 個數字，因此把 `stack` 中的最後 k 位都刪除。\n2. 要確保沒有前導 0，這點可以在把 `stack` 中的數字轉為 `string` 後，再用迴圈刪除前導 0。\n\n不過，比較簡單的方法是使用一個 `string` 來取代上述的 `stack`。\n\n# 程式碼\n\n```cpp\n/**\n * Author: justin0u0<mail@justin0u0.com>\n * Problem: https://leetcode.com/problems/remove-k-digits/\n * Runtime: 0ms\n */\n\nclass Solution {\npublic:\n  string removeKdigits(string num, int k) {\n    // 最後的整數，ans[0] 為最高位數，ans[1] 為第二高位數... 以此類推\n    string ans = \"\";\n    for (char digit: num) {\n      // 若還有刪除的額度且當前的數字比 ans 的最低位數還要小，刪除 ans 中的最低位數\n      while (k && !ans.empty() && digit < ans.back()) {\n        ans.pop_back();\n        k--;\n      }\n      // 將 digit 加入 ans 中，這裡可以利用判斷使得前導 0 不會被加入\n      if (!ans.empty() || digit != '0') ans.push_back(digit);\n    }\n\n    // 確保有 k 個數字被刪除\n    while (!ans.empty() && k--)\n      ans.pop_back();\n\n    // 特例：若數字都刪完了，則回傳 \"0\"\n    return ans.empty() ? \"0\" : ans;\n  }\n};\n\n```\n","tags":["LeetCode","堆疊（Stack）","單調棧（Monotone Stack）"],"categories":["LeetCode"]},{"title":"LeetCode 92 - Reverse Linked List II","url":"/LeetCode-Reverse-Linked-List-II/","content":"\n# 題目\n題目連結：[https://leetcode.com/problems/reverse-linked-list-ii/](https://leetcode.com/problems/reverse-linked-list-ii/)\n\n給一個 Linked list 以及兩個數字 `left`、`right`，將索引值在 `left~right` 的部分翻轉。\n\n索引值從 1 開始。\n\n# 範例說明\n\n## Example 1:\n\n```\nInput: head = [1,2,3,4,5], left = 2, right = 4\nOutput: [1,4,3,2,5]\n```\n\n![](/assets/LeetCode-Reverse-Linked-List-II/rev2ex.jpg)\n\n<!-- More -->\n\n## Example 2:\n\n```\nInput: head = [5], left = 1, right = 1\nOutput: [5]\n```\n\n# 想法\n\n假設索引 `left` 上的數字為 `cur`，且索引 `left - 1` 上的數字為 `pre`。\n\n若想要遍歷一次，並且使用 `O(1)` space 完成翻轉，可以想成是做 `right - left` 次的「**將 `cur` 的下一個數字移除並插入到 `pre` 之後**」。\n\n例如 Example 1：\n| Step |     Linked list     | `cur` index | `pre` index |\n| ---- | ------------------- | ----------- | ----------- |\n| 0    | `1->2->3->4->5`     | 2           | 1           |\n| 1    | `1->3->2->4->5`     | 3           | 1           |\n| 2    | `1->4->3->2->5`     | 4           | 1           |\n\n注意 `cur` 會一直指著同一個數字，在 Example 1 中也就是數字 `2`；`pre` 也會一直指著同一個數字，在 Example 1 中也就是數字 1。\n\n# 實作細節\n\n首先，可以將上述想法分為兩個步驟實作：\n1. 找到 `pre` 以及 `cur` 的位置\n   從上表可以看出，`cur` 的在 `head` 向後移動 `left - 1` 次的位置；`pre` 在 `cur` 的前一個，也就是 `head` 向後移動 `left - 2` 次的位置。\n2. 執行 `right - left` 次「**將 `cur` 的下一個數字移除並插入到 `pre` 之後**」\n   **<font color=\"red\">在實作 Linked list 的操作的時候，筆者建議可以把圖畫出來，憑空想像是很容易出錯的！</font>**\n   \n   一樣以 Example 1 為例子：\n   ![](/assets/LeetCode-Reverse-Linked-List-II/00.png)\n   1. 首先筆者會先把 `pre`、`cur` 的位置標出來，並且將 `pre->next`、`cur->next` 等指標的位置也標出來。\n   2. 再來，執行「**將 `cur` 的下一個數字移除並插入到 `pre` 之後**」這個操作，將要改變的指標畫成曲線。\n   3. 最後，將曲線標出如何賦値\b，例如：\n      - <font color=\"green\">數字 1 的下一個數字應該應該要接數字 3，數字 1 是 `pre`，`pre` 的下一個數字也就是 `pre->next` 要接到數字 3，也就是 `cur->next`，因此 `pre->next = cur->next`。</font>\n      - <font color=\"blue\">數字 2 的下一個數字要接到數字 4，數字 2 是 `cur`，`cur` 的下一個數字也就是 `cur->next` 要接到數字 4，也就是 `cur->next->next`，因此 `cur->next = cur->next->next`。</font>\n      - <font color=\"red\">數字 3 的下一個數字要接到數字 2，數字 3 是 `cur->next`，`cur->next` 的下一個數字也就是 `cur->next->next` 要接到數字 2，也就是 `pre->next`，因此 `cur->next->next = pre->next`。</font>\n  \n    如果不放心，可以再做一次 Step 1 到 Step 2 的過程，會得到相同的三個步驟。\n    ![](/assets/LeetCode-Reverse-Linked-List-II/01.png)\n\n最後，眼尖的讀者可能已經發現了兩個問題：\n1. 在第一點中，`pre` 的位置是 `head` 向後移動 `left - 2` 次的位置，可是 `left` 的最小值是 `1`，也就是 `left - 2` 是 `-1`，那 `head` 向後移動 `-1` 步是哪裡？\n  為了解決這個問題，可以在整個 Linked list 的前面多加一個點（Dummy Node），也就是在 `head` 的前面再放一個新的點，Dummy Node 雖然實際上不存在，但是可以幫助你的實作更佳簡潔。\n  有了 Dummy node 的幫助，那麼 `pre` 的位置即改為 dummy node 往後移動 `left - 1` 不的位置，就一定存在了！當然 `cur` 也要改為 dummy node 往後移動 `left` 步的位置。\n2. 在第二點中，三個修改 `1. pre->next = cur->next`、`2. cur->next = cur->next->next` 以及 `3. cur->next->next = pre->next` 是有順序性的。\n  例如： `1.` 應該要在 `3.` 之後，因為 `3.` 會需要原本 `pre->next` 的值，可是在 `1.` 的時候會修改到 `pre->next` 的值。\n  遇到這種情況，比較簡單的辦法就是**先把需要的值都備份一遍，最後更改時從等號左側值比較右邊的開始修改，等號右側都使用備份的指標**。因為等號右側所用到的值都是備份的，右側一定不會出錯，而等號左側的值從最右邊開始照順序更改，因此也不會有依附關係，如此一來就不會出錯了～\n    ```cpp\n    ListNode* tempCurNext = cur->next;\n    ListNode* tempCurNextNext = cur->next->next;\n    ListNode* tempPreNext = pre->next;\n    cur->next->next = tempPreNext;\n    cur->next = tempCurNextNext;\n    pre->next = tempCurNext;\n    ```\n\n    當然，也可以稍微思考一下順序，再用盡量少的變數來幫助即可（可以把先後關係畫成一張圖再決定先後順序，如果有環出現的話就至少需要一個暫存變數）。\n\n# 程式碼\n\n```cpp\n/**\n * Author: justin0u0<mail@justin0u0.com>\n * Problem: https://leetcode.com/problems/reverse-linked-list-ii/submissions/\n * Runtime: 0ms\n */\n\n/**\n * Definition for singly-linked list.\n * struct ListNode {\n *     int val;\n *     ListNode *next;\n *     ListNode() : val(0), next(nullptr) {}\n *     ListNode(int x) : val(x), next(nullptr) {}\n *     ListNode(int x, ListNode *next) : val(x), next(next) {}\n * };\n */\nclass Solution {\npublic:\n  ListNode* reverseBetween(ListNode* head, int left, int right) {\n    ListNode* preHead = new ListNode(0, head); // Dummy node\n    ListNode* pre = preHead;\n    for (int i = 0; i < left - 1; i++) {\n      pre = pre->next;\n    }\n\n    ListNode* cur = pre->next;\n    for (int i = left; i < right; i++) {\n      ListNode* temp = cur->next->next;\n      cur->next->next = pre->next;\n      pre->next = cur->next;\n      cur->next = temp;\n    }\n    return preHead->next;\n  }\n};\n\n```\n","tags":["LeetCode","鏈結串列（Linked List）"],"categories":["LeetCode"]},{"title":"LeetCode 160 - Intersection of Two Linked Lists","url":"/LeetCode-Intersection-of-Two-Linked-Lists/","content":"\n# 題目\n題目連結：[https://leetcode.com/problems/intersection-of-two-linked-lists/](https://leetcode.com/problems/intersection-of-two-linked-lists/)\n\n給定兩個 Linked list，找出其交點。若沒有交點則回傳 `null`。\n\n# 範例說明\n\n## Example 1:\n\n```\nInput: intersectVal = 8, listA = [4,1,8,4,5], listB = [5,6,1,8,4,5], skipA = 2, skipB = 3\nOutput: Reference of the node with value = 8\nInput Explanation: The intersected node's value is 8 (note that this must not be 0 if the two lists intersect). From the head of A, it reads as [4,1,8,4,5]. From the head of B, it reads as [5,6,1,8,4,5]. There are 2 nodes before the intersected node in A; There are 3 nodes before the intersected node in B.\n``` \n![](/assets/LeetCode-Intersection-of-Two-Linked-Lists/160_example_1_1.png)\n\n<!-- More -->\n\n## Example 2:\n\n```\nInput: intersectVal = 2, listA = [1,9,1,2,4], listB = [3,2,4], skipA = 3, skipB = 1\nOutput: Reference of the node with value = 2\nInput Explanation: The intersected node's value is 2 (note that this must not be 0 if the two lists intersect). From the head of A, it reads as [1,9,1,2,4]. From the head of B, it reads as [3,2,4]. There are 3 nodes before the intersected node in A; There are 1 node before the intersected node in B.\n``` \n![](/assets/LeetCode-Intersection-of-Two-Linked-Lists/160_example_2.png)\n\n## Example 3:\n\n```\nInput: intersectVal = 0, listA = [2,6,4], listB = [1,5], skipA = 3, skipB = 2\nOutput: null\nInput Explanation: From the head of A, it reads as [2,6,4]. From the head of B, it reads as [1,5]. Since the two lists do not intersect, intersectVal must be 0, while skipA and skipB can be arbitrary values.\nExplanation: The two lists do not intersect, so return null.\n```\n![](/assets/LeetCode-Intersection-of-Two-Linked-Lists/160_example_3.png)\n\n# 想法\n\n## 想法一\n\n首先，使用兩個指標，`curA` 從頭開始遍歷第一條 Linked list，`curB` 遍歷第二條。\n\n找出第一條 Linked list 的長 `lenA` 以及第二條 Linked list 的長 `lenB`。\n\n因為兩條 Linked list 若有交點，則交點後的長度皆一樣。所以只要將長度較長的 Linked list 從開頭去掉 `|lenA - lenB|` 個點，使得兩個 Linked list 長度相等，使用兩個指標從兩個 Linked list 的開頭開始，同時一次一步的前進，若有交點則一定會同時走到交點；若沒有交點則同時走到 `null`。\n\n## 想法二\n\n使用第一條 Linked list 串到第二條 Linked list 之後；將第二條 Linked list 串到第一條 Linked list 之後。則兩條 Linked list 會變成等長，根據**想法一**，因為交點後的長度皆相同，所以只要使用兩個指標從兩個 Linked list 的開頭開始，同時一次一步的前進，若有交點則一定會同時走到交點（下圖黑框）：若沒有交點的話則同時走到 `null`。\n\n![](/assets/LeetCode-Intersection-of-Two-Linked-Lists/00.png)\n\n# 實作細節\n\n下面實作為**想法二**。\n\n實作時，\b可以判斷當 `curA->next != nullptr` 時，`curA = headB`，否則 `curA = curA->next`；`curB` 類似道理。\n\n但是這樣實作會發現當沒有交點時，`curA` 與 `curB` 會無法同時走到 `null` 上（因為 `curA` 在走到 `null` 之前就會因為 `curA->next != nullptr` 而執行 `curA = headB` 走到 `headB` 上了。\n\n可以將判斷條件改為 `curA->next != nullptr` 改為 `curA != nullptr`，`curB` 也類似道理。這樣一來不但符合**想法二**，並且解決了上述的問題。\n\n# 程式碼\n\n```cpp\n/**\n * Author: justin0u0<mail@justin0u0.com>\n * Problem: https://leetcode.com/problems/intersection-of-two-linked-lists\n * Runtime: 40ms\n */\n\n/**\n * Definition for singly-linked list.\n * struct ListNode {\n *     int val;\n *     ListNode *next;\n *     ListNode(int x) : val(x), next(NULL) {}\n * };\n */\n\nclass Solution {\npublic:\n  ListNode *getIntersectionNode(ListNode *headA, ListNode *headB) {\n    if (headA == nullptr || headB == nullptr)\n      return nullptr;\n\n    ListNode* curA = headA;\n    ListNode* curB = headB;\n    while (curA != curB) {\n      curA = (curA != nullptr) ? curA->next : headB;\n      curB = (curB != nullptr) ? curB->next : headA;\n    }\n    return curA;\n  }\n};\n\n```\n","tags":["LeetCode","鏈結串列（Linked List）"],"categories":["LeetCode"]},{"title":"LeetCode 141 - Linked List Cycle","url":"/LeetCode-Linked-List-Cycle/","content":"\n# 題目\n題目連結：[https://leetcode.com/problems/linked-list-cycle/](https://leetcode.com/problems/linked-list-cycle/)\n\n給一個 Linked list，判斷有沒有環。\n\n# 範例說明\n\n## Example 1:\n\n```\nInput: head = [3,2,0,-4], pos = 1\nOutput: true\nExplanation: There is a cycle in the linked list, where the tail connects to the 1st node (0-indexed).\n```\n\n<!-- More -->\n\n![](/assets/LeetCode-Linked-List-Cycle/circularlinkedlist.png)\n\n## Example 2:\n\n```\nInput: head = [1,2], pos = 0\nOutput: true\nExplanation: There is a cycle in the linked list, where the tail connects to the 0th node.\n```\n\n![](/assets/LeetCode-Linked-List-Cycle/circularlinkedlist_test2.png)\n\n## Example 3:\n\n```\nInput: head = [1], pos = -1\nOutput: false\nExplanation: There is no cycle in the linked list.\n```\n\n![](/assets/LeetCode-Linked-List-Cycle/circularlinkedlist_test3.png)\n\n# 想法\n\n## 一般的作法\b：Time `O(N)`, Space `O(N)`\n\n有無環的區別就是遍歷 Linked list 時是否會經過重複的位置。\n\n最簡單的想法是使用一個指標 `cur` 從頭遍歷整個 Linked list，並且將 `cur` 的記憶體位置都記錄下來（先假設記錄在一個變數 `box` 內），每次都檢查 `box` 內有與 `cur` 相同的記憶體位置。\n\n這個 `box` 如果是一個陣列，判斷 **`box` 內有與 `cur` 相同的記憶體位置**就需要遍歷整個 `box` 陣列，會讓整體時間複雜度變為 `O(N^2)`。\n\n這個 `box` 可以是一個 Hash table，那麼判斷 **`box` 內有與 `cur` 相同的記憶體位置** 只需要 `O(1)`，整體時間複雜度等於遍歷一遍 Linked list 的時間 `O(N)`。\n\nC++ `box` 可以使用 `std::unordered_set<ListNode*>`，[但是要實作 `ListNode*` 的 compare 函數才能使用](https://stackoverflow.com/questions/31628251/stdunordered-set-of-pointers)。\n\n## 最佳的作法：Time `O(N)`, Space `O(1)`\n\n首先，若 Linked list 有環，則一個指標不管走多少步都會被卡在環上一直繞圈。\n\n利用這個性質，使用兩個指標，皆從頭開始遍歷。一個一次走一步，稱之為 `slow`；另一個一次走兩步，稱之為 `fast`。可以知道若存在環，不管走多少步，`slow` 以及 `fast` 都會一直在環上繞圈，並且因為 `fast` 每次比 `slow` 多走一步，所以最後 `slow` 以及 `fast` 一定會相會。\n\n時間複雜度的部分，可以知道 `slow` 以及 `fast` 在 `N` 步之內一定會走到環上，並且 `fast` 每次與 `slow` 縮減一步的距離，而環的長度小於 `N`，因此 `slow` 與 `fast` 都到達環上後，一定會在 `N` 步內相會。總時間複雜度為 `O(2N) = O(N)`。\n\n而沒有環時，`fast` 會直接走到底，也就是 `null`。\n\n# 實作細節\n\n注意迴圈的條件，因為 `fast` 會一次走兩步，所以有兩個判斷條件： `fast != nullptr && fast->next != nullptr`。\n\n至於 `slow` 因為走的比 `fast` 還要慢，因此不需要判斷。\n\n# 程式碼\n\n```cpp\n/**\n * Author: justin0u0<mail@justin0u0.com>\n * Problem: https://leetcode.com/problems/linked-list-cycle/\n * Runtime: 8ms\n */\n\n/**\n * Definition for singly-linked list.\n * struct ListNode {\n *     int val;\n *     ListNode *next;\n *     ListNode(int x) : val(x), next(NULL) {}\n * };\n */\n\nclass Solution {\npublic:\n  bool hasCycle(ListNode *head) {\n    if (head == nullptr)\n      return false;\n\n    ListNode* slow = head;\n    ListNode* fast = head;\n    while (fast != nullptr && fast->next != nullptr) {\n      slow = slow->next;\n      fast = fast->next->next;\n      if (slow == fast) {\n        return true;\n      }\n    }\n    return false;\n  }\n};\n\n```\n","tags":["LeetCode","鏈結串列（Linked List）"],"categories":["LeetCode"]},{"title":"LeetCode 876 - Middle of the Linked List","url":"/LeetCode-Middle-of-the-Linked-List/","content":"\n# 題目\n題目連結：[https://leetcode.com/problems/middle-of-the-linked-list/](https://leetcode.com/problems/middle-of-the-linked-list/)\n\n給一個 Linked list，回傳其中間的點。如果有兩個中間的點，則回傳後面的那個。\n\n# 範例說明\n\n## Example 1:\n\n```\nInput: [1,2,3,4,5]\nOutput: Node 3 from this list (Serialization: [3,4,5])\nThe returned node has value 3.  (The judge's serialization of this node is [3,4,5]).\nNote that we returned a ListNode object ans, such that:\nans.val = 3, ans.next.val = 4, ans.next.next.val = 5, and ans.next.next.next = NULL.\n```\n\n<!-- More -->\n\n## Example 2:\n\n```\nInput: [1,2,3,4,5,6]\nOutput: Node 4 from this list (Serialization: [4,5,6])\nSince the list has two middle nodes with values 3 and 4, we return the second one.\n```\n\n# 想法\n\n## 簡單的想法\n\n當然可以先遍歷一遍找出 linked list 的長度，再從頭遍歷長度的一半，回傳找到的點。\n\n## 更優的做法\n\n可以利用兩個指標，兩個指標都從頭開始。\n\n一個一次走一步，稱它為 `slow`；另一個一次走兩步，稱它為 `fast`。這樣 `fast` 到達終點時，`slow` 恰好走了一半的長度，所以回傳 `slow` 即可。\n\n# 實作細節\n\n注意迴圈的條件，因為 `fast` 會一次走兩步，所以有兩個判斷條件： `fast != nullptr && fast->next != nullptr`。\n\n至於 `slow` 因為走的比 `fast` 還要慢，因此不需要判斷。\n\n# 程式碼\n\n```cpp\n/**\n * Author: justin0u0<mail@justin0u0.com>\n * Problem: https://leetcode.com/problems/middle-of-the-linked-list/\n * Runtime: 0ms\n */\n\n/**\n * Definition for singly-linked list.\n * struct ListNode {\n *     int val;\n *     ListNode *next;\n *     ListNode() : val(0), next(nullptr) {}\n *     ListNode(int x) : val(x), next(nullptr) {}\n *     ListNode(int x, ListNode *next) : val(x), next(next) {}\n * };\n */\nclass Solution {\npublic:\n  ListNode* middleNode(ListNode* head) {\n    ListNode* slow = head;\n    ListNode* fast = head;\n\n    while (fast != nullptr && fast->next != nullptr) {\n      slow = slow->next;\n      fast = fast->next->next;\n    }\n    return (fast == nullptr) ? slow : slow->next;\n  }\n};\n\n```\n","tags":["LeetCode","鏈結串列（Linked List）"],"categories":["LeetCode"]},{"title":"使用 operator-sdk 在 Kubernetes 中實作 CRD 以及 Controller","url":"/使用-operator-sdk-在-Kubernetes-中實作-CRD-以及-Controller/","content":"\n# 目標\n\n使用 operator-sdk 建立一個 CustomResourceDefinition，類似於 ReplicaSet 的功能，在這裡筆者將他稱為 PodSet。\n\nPodSet 可以自動的創建 Replicas 的數量個 Pods，並且在 Pods 被新增、刪除，或是 PodSet 的 Spec 被修改時自動增減 Pods 的數量。\n\n先附上 PodSet 的 Spec：\n\n```yaml\napiVersion: k8stest.justin0u0.com/v1alpha1\nkind: PodSet\nmetadata:\n  name: podset-sample\nspec:\n  # Add fields here\n  replicas: 2\n```\n\n程式碼的部分在：[https://github.com/justin0u0/podset-operator](https://github.com/justin0u0/podset-operator)\n\n<!-- More -->\n\n# Prerequisites\n\n筆者的環境如下：\n\n```markdown\n- Minikube v1.16.0\n- Kubernetes v1.18.3\n- operator-sdk v1.3.0\n- golang 1.15.7\n- Docker 20.10.2\n```\n\n## Installation\n\n### operator-sdk\n\n```bash\nbrew install operator-sdk\n\noperator-sdk version: \"v1.3.0\", commit: \"1abf57985b43bf6a59dcd18147b3c574fa57d3f6\", kubernetes version: \"v1.19.4\", go version: \"go1.15.6\", GOOS: \"darwin\", GOARCH: \"amd64\"\n```\n\n### golang\n\n```bash\nbrew install golang-go\n\ngo version\ngo version go1.15.7 darwin/amd64\n```\n\n# Create new project\n\n```bash\nmkdir podset-operator && cd podset-operator\n\noperator-sdk init --domain=justin0u0.com --repo=github.com/justin0u0/podset-operator\n```\n\n# Create new API and Controller\n\n我們 Create 一個新的 Resource 其中 `group=k8stest`，`version=v1alpha1`，`kind=PodSet`。\n\n```bash\noperator-sdk create api --group=k8stest --version=v1alpha1 --kind=PodSet\nCreate Resource [y/n]\ny\nCreate Controller [y/n]\ny\n```\n\n完成後目錄結構應該如下：\n\n```\n.\n├── Dockerfile\n├── Makefile\n├── PROJECT\n├── api\n│   └── v1alpha1\n│       ├── groupversion_info.go\n│       ├── podset_types.go\n│       └── zz_generated.deepcopy.go\n├── bin\n│   ├── controller-gen\n│   ├── kustomize\n│   └── manager\n├── config\n│   ├── certmanager\n│   │   ├── certificate.yaml\n│   │   ├── kustomization.yaml\n│   │   └── kustomizeconfig.yaml\n│   ├── crd\n│   │   ├── bases\n│   │   │   └── k8stest.justin0u0.com_podsets.yaml\n│   │   ├── kustomization.yaml\n│   │   ├── kustomizeconfig.yaml\n│   │   └── patches\n│   │       ├── cainjection_in_podsets.yaml\n│   │       └── webhook_in_podsets.yaml\n│   ├── default\n│   │   ├── kustomization.yaml\n│   │   ├── manager_auth_proxy_patch.yaml\n│   │   └── manager_config_patch.yaml\n│   ├── manager\n│   │   ├── controller_manager_config.yaml\n│   │   ├── kustomization.yaml\n│   │   └── manager.yaml\n│   ├── prometheus\n│   │   ├── kustomization.yaml\n│   │   └── monitor.yaml\n│   ├── rbac\n│   │   ├── auth_proxy_client_clusterrole.yaml\n│   │   ├── auth_proxy_role.yaml\n│   │   ├── auth_proxy_role_binding.yaml\n│   │   ├── auth_proxy_service.yaml\n│   │   ├── kustomization.yaml\n│   │   ├── leader_election_role.yaml\n│   │   ├── leader_election_role_binding.yaml\n│   │   ├── podset_editor_role.yaml\n│   │   ├── podset_viewer_role.yaml\n│   │   ├── role.yaml\n│   │   └── role_binding.yaml\n│   ├── samples\n│   │   ├── k8stest_v1alpha1_podset.yaml\n│   │   └── kustomization.yaml\n│   └── scorecard\n│       ├── bases\n│       │   └── config.yaml\n│       ├── kustomization.yaml\n│       └── patches\n│           ├── basic.config.yaml\n│           └── olm.config.yaml\n├── controllers\n│   ├── podset_controller.go\n│   └── suite_test.go\n├── cover.out\n├── go.mod\n├── go.sum\n├── hack\n│   └── boilerplate.go.txt\n├── main.go\n└── testbin\n    ├── bin\n    │   ├── etcd\n    │   ├── kube-apiserver\n    │   └── kubectl\n    └── setup-envtest.sh\n```\n\n其中比較重要的幾個部分有 `main.go`，`api/podset_types.go` 以及 `controllers/podset_controller.go`。\n\n## Define API\n\n在 `api/podset_types.go` 中，會看到這樣的一段 Code：\n\n```go\n// PodSetSpec defines the desired state of PodSet\ntype PodSetSpec struct {\n  // INSERT ADDITIONAL SPEC FIELDS - desired state of cluster\n  // Important: Run \"make\" to regenerate code after modifying this file\n\n  // Foo is an example field of PodSet. Edit PodSet_types.go to remove/update\n  Foo string `json:\"foo,omitempty\"`\n}\n\n// PodSetStatus defines the observed state of PodSet\ntype PodSetStatus struct {\n  // INSERT ADDITIONAL STATUS FIELD - define observed state of cluster\n  // Important: Run \"make\" to regenerate code after modifying this file\n}\n```\n\n其中 `PodSetSpec` 是用來定義 User 給定的 Yaml 中，`Spec` 的部分要長成什麼樣子。因此我們將 `Foo` 刪除加上 `Replicas`。[在 `PodSetSpec` 中，可以透過 `+kubebuilder:validation` 的 Marker 來驗證欄位。](https://book.kubebuilder.io/reference/generating-crd.html#validation)\n\n```go\ntype PodSetSpec struct {\n  Replicas int32 `json:\"replicas\"`\n}\n```\n\n而 `PodSetStatus` 是用來紀錄 Runtime 時的狀態，比如說可以紀錄屬於這個 PodSet 的 Pod 有哪些，以及真正的 `Replicas` 的值。另外，在 `PodSetStatus` 上加上 `+kubebuilder:subresource:status`，更新主資源不會修改到 `Status`，同樣地，更新 `Status` 不會更新到主資源。\n\n```go\n// +kubebuilder:subresource:status\ntype PodSetStatus struct {\n  Replicas int32    `json:\"replicas\"`\n  PodNames []string `json:\"pod_names\"`\n}\n```\n\n若不清楚 `Spec` 與 `Status` 的關係，可以參考 [Spec & Status](https://www.notion.so/Spec-Status-67292b8b3a904121877af8de9361204a)。\n\n修改 API 後，要記得執行 `make generate` 以更新 generated code。\n\n## Generate CRD Manifests\n\n完成 `PodSetSpec` 後，operator-sdk 可以根據 `PodSetSpec` 產生出部署用的 yaml file。\n\n執行 `make manifests`，會看到 `config/crd/bases/k8stest.justin0u0.com_podsets.yaml` 的生成，這個 Config 是給 Kubernetes 用來驗證你寫的 `PodSet` 是否為正確的用的。\n\n## Implement the Controller\n\nController 負責處理整個 CRD 的邏輯，在 `controllers/podset_controller.go` 中，有兩個重要的部分。\n\n### SetupWithManager\n\n```go\n// SetupWithManager sets up the controller with the Manager.\nfunc (r *PodSetReconciler) SetupWithManager(mgr ctrl.Manager) error {\n  return ctrl.NewControllerManagedBy(mgr).\n    For(&k8stestv1alpha1.PodSet{}).\n    Complete(r)\n}\n```\n\n在 `SetupWithManager` 中，會看到這樣一段程式碼，其中 `For(&k8stestv1alpha1.PodSet)` 代表最主要要觀察的 Resource 是 `PodSet` 這個 Resource，所謂觀察也就是只當有任何 `PodSet` 的 Create, Update, Delete 事件，都會送出一個 **Reconcile** Request，而 **Reconcile** 正是等一下會實作的 Controller Logic。\n\n不過不只是在 `PodSet` Create, Update, Delete 時需要 Reconcile，在我們想要做的 `PodSet` 例子中，當由 `PodSet` 管理的 `Pod` 有 Create, Update, Delete 的事件時，也應該要做出對應的處理。\n\n因此可以將 `SetupWithManager` 函數改成以下：\n\n```go\n// SetupWithManager sets up the controller with the Manager.\nfunc (r *PodSetReconciler) SetupWithManager(mgr ctrl.Manager) error {\n  return ctrl.NewControllerManagedBy(mgr).\n    For(&k8stestv1alpha1.PodSet{}).\n    Owns(&corev1.Pod{}).\n    Complete(r)\n}\n```\n\n其中的 `Owns(&corev1.Pod{})` 代表 `PodSet` 會 Own 類別為 `corev1.Pod` 的 resource，並且，在 `corev1.Pod` 這種 resource 被 Create, Update, Delete 時，會送一個 Reconcile Request 給他的 Owner，也就是 `PodSet`。\n\n### Reconcile\n\n```go\n// +kubebuilder:rbac:groups=k8stest.justin0u0.com,resources=podsets,verbs=get;list;watch;create;update;patch;delete\n// +kubebuilder:rbac:groups=k8stest.justin0u0.com,resources=podsets/status,verbs=get;update;patch\n// +kubebuilder:rbac:groups=k8stest.justin0u0.com,resources=podsets/finalizers,verbs=update\n\nfunc (r *PodSetReconciler) Reconcile(ctx context.Context, req ctrl.Request) (ctrl.Result, error) {\n  _ = r.Log.WithValues(\"podset\", req.NamespacedName)\n\n  // your logic here\n\n  return ctrl.Result{}, nil\n}\n```\n\n首先，Reconcile 的回傳值有 `ctrl.Result` 與 `error` 兩個。當 `ctrl.Result` 回傳 `{Requeue: true}` 或是 `error != nil` 的話，Controller 會 requeue reconcile 的請求以重新執行一遍 Reconcile。\n\n再來，看到 `Reconcile` 上方的註解，代表 Controller 所擁有的 RBAC 權限。可以看到預設的 RBAC 權限包含對 `PodSet` 資源的 get, list, watch, create...。在 `PodSet` 中，需要權限來新增、刪除、取得 Pods，觀察 Pod 的刪減...權限，因此加上 Pod 的權限：\n\n```go\n// +kubebuilder:rbac:groups=core,resources=pods,verbs=get;list;create;delete;watch\n```\n\n接個開始實踐 `PodSet` 邏輯。首先，應該先找到發起請求的 `PodSet`：\n\n```go\n// Fetch podset instance\npodSet := &k8stestv1alpha1.PodSet{}\nif err := r.Get(ctx, req.NamespacedName, podSet); err != nil {\n  if errors.IsNotFound(err) {\n    // Request object not found, could have been deleted after reconcile request.\n    // Owned objects are automatically garbage collected. For additional cleanup logic use finalizers.\n    // Return and don't requeue\n    log.Info(\"PodSet resource not found. Ingoring since object must be deleted.\")\n    return ctrl.Result{}, nil\n  }\n  // Error reading object - requeue the requst\n  log.Error(err, \"Failed to get PodSet resource.\")\n  return ctrl.Result{}, err\n}\n```\n\n`r.Get` 其實也等於 `r.client.Get`，`r` 是一個 `PodSetReconciler`，看一下 `PodSetReconciler` 的定義：\n\n```go\n// PodSetReconciler reconciles a PodSet object\ntype PodSetReconciler struct {\n  client.Client\n  Log    logr.Logger\n  Scheme *runtime.Scheme\n}\n```\n\n可以看到包含一個 `client.Client`，這是 Golang struct 中的 [promoted field](https://www.notion.so/Golang-7ab921d39bde41c998e39ece6c88ef40)，因此可以直接用 `client.Client` 內的 method，例如 `r.Get`, `r.List`...等等。\n\n再來，可以先預想一下生成由 `PodSet` 管理、生成出來的 Pod 要有怎麼樣的 Spec，以方便管理，因此筆者先實作 `podForPodSet` 函數，給定一個 `PodSet`，`podForPodSet` 函數回傳一個 Pod。\n\n```go\nfunc (r *PodSetReconciler) podForPodSet(podSet *k8stestv1alpha1.PodSet) *corev1.Pod {\n  labels := map[string]string{\n    \"app\":       \"podset\",\n    \"podset_cr\": podSet.Name,\n  }\n\n  pod := &corev1.Pod{\n    ObjectMeta: metav1.ObjectMeta{\n      Name:      podSet.Name + \"-\" + strconv.FormatInt(time.Now().UnixNano(), 36),\n      Namespace: podSet.Namespace,\n      Labels:    labels,\n    },\n    Spec: corev1.PodSpec{\n      Containers: []corev1.Container{\n        {\n          Name:    \"busybox\",\n          Image:   \"busybox\",\n          Command: []string{\"sleep\", \"3600\"},\n        },\n      },\n    },\n  }\n\n  ctrl.SetControllerReference(podSet, pod, r.Scheme)\n  return pod\n}\n```\n\n可以看到，產生出來的 Pod 有 labels `{\"app\": \"podset\", \"podset_cr\": podSet.Name}` 這樣的標籤，這個標籤可以幫助不同的 `PodSet` 區分屬於自己所創建（管理）的 Pods 有哪些。\n\n最後一行的 `ctrl.SetControllerReference` 將 `pod` 的 Owner 綁定成傳入的 `podSet`。\n\n接著，返回 `Reconcile` 函數的部分，先取得現在 `PodSet` 所擁有的，並且正在運行的 Pods：\n\n```go\n// Get all pods with label app=podSet.Name\npodList := &corev1.PodList{}\nlabelSet := labels.Set{\n  \"app\":       \"podset\",\n  \"podset_cr\": podSet.Name, // podSet.ObjectMeta.Name\n}\nif err := r.List(ctx, podList, &client.ListOptions{\n  Namespace:     req.Namespace, // req.NamespacedName.Namespace\n  LabelSelector: labels.SelectorFromSet(labelSet),\n}); err != nil {\n  log.Error(err, \"Failed to list pods.\")\n  return ctrl.Result{}, err\n}\n```\n\n可以看到，利用 `labelSet := labels.Set{\"app\": \"podset\", \"podset_cr\": podSet.name}`，再使用 `r.List` 的 `opts` `LabelSelector`，可以幫助我們篩選出屬於這個 `podSet` 所擁有的 pods。\n\n取得的 `podList` 中，其中有一些 Pod 可能正在被 terminated（因為 k8s 中，被 elegant deleted by user 的 Pod 只會先將 `DeletionTimestamp` 設上數值而已），因此，利用 Pod 的 `Phase` 以及 `ObjectMeta`，篩選出真正還在運行的 Pod 有哪些。\n\n```go\n// Get all running pods\nrunningPods := []corev1.Pod{}\nrunningPodNames := []string{}\nfor _, pod := range podList.Items {\n  if pod.ObjectMeta.DeletionTimestamp == nil && (pod.Status.Phase == corev1.PodPending || pod.Status.Phase == corev1.PodRunning) {\n    runningPods = append(runningPods, pod)\n    runningPodNames = append(runningPodNames, pod.Name)\n  }\n}\n```\n\n如果不做 `pod.ObjectMeta.DeletionTimstamp` 的檢查，雖然 Pod 在被刪除的那個剎那就會呼叫一次 `Reconcile`，但是我們會以為這個 Pod 還在運行中，因爲其 `Status.Phase` 還是 `Running`。\n\n取得 `runningPods` 以及 `runningPodNames` 後，首先更新 `PodSet` 的 Status：\n\n```go\n// Update status if needed\nif newStatus := (k8stestv1alpha1.PodSetStatus{\n  Replicas: int32(len(runningPodNames)),\n  PodNames: runningPodNames,\n}); !reflect.DeepEqual(podSet.Status, newStatus) {\n  podSet.Status = newStatus\n  if err := r.Status().Update(ctx, podSet); err != nil {\n    log.Error(err, \"Failed to update PodSet status\")\n    return ctrl.Result{}, err\n  }\n}\n```\n\n更新 `podSet.Status` 可以讓我們在其 yaml 中看到 `PodSet` 目前的真實狀態。\n\n注意這裡的 `r.Status().Update` 並不等於 `r.Update`，`r.Update` 更新的是某個 resource 的 spec，而 `r.Status().Update` 是透過 `StatusWriter` 的 `Update` 來更新 resource 的 status。\n\n最後，根據 `runningPods` 的數量，決定要增加或是刪除 Pods。\n\n若 `runningPods` 數量過多，刪除一個 Pod：\n\n```go\n// Scale down pods\nif int32(len(runningPodNames)) > podSet.Spec.Replicas {\n  // Delete a pod once a time\n  log.Info(\"Deleting a Pod in the PodSet\", \"PodSet.Name\", podSet.Name)\n  pod := runningPods[0]\n  if err := r.Delete(ctx, &pod); err != nil {\n    log.Error(err, \"Failed to delete pod\")\n    return ctrl.Result{}, err\n  }\n  return ctrl.Result{Requeue: true}, nil\n}\n```\n\n刪除 Pods 的方法採用一次刪除一個，並且回傳 `ctrl.Result{Requeue: true}`，因此下一次的 Reconcile 就會再刪除一個 pod，如果需要的話。\n\n若 `runningPods` 數量不足，增加一個 Pod：\n\n```go\n// Scale up pods\nif int32(len(runningPodNames)) < podSet.Spec.Replicas {\n  // Create a pod once a time\n  log.Info(\"Creating a Pod in the PodSet\", \"PodSet.Name\", podSet.Name)\n  pod := r.podForPodSet(podSet)\n\n  if err := r.Create(ctx, pod); err != nil {\n    log.Error(err, \"Failed to create pod\")\n    return ctrl.Result{}, err\n  }\n  return ctrl.Result{Requeue: true}, nil\n}\n```\n\n使用 `podForPodSet` 以及 `r.Create` 函數來創建一個新的 Pod。\n\n最後完成的程式碼可以在最上面附上的 [Github 連結](https://github.com/justin0u0/podset-operator)查看。\n\n# Build and run the operator\n\n完成程式碼後，首先：\n\n```bash\nmake install\n```\n\n將 CRD 部署到 K8s cluster 中，因此要確認 k8s 這時已經開啟。（如果是使用 Minikube 的話，用 `minikube status` 確認）。\n\n```bash\nkubectl get crds\n\n...\npodsets.k8stest.justin0u0.com         2021-02-01T09:14:40Z\n...\n```\n\n這時應該可以看到 CRD 已經被部署到 k8s cluster 中。\n\n測試 Controller 時，可以使用以下兩種方法：\n\n## Run controller locally outside k8s cluster\n\n```bash\nmake run ENABLE_WEBHOOKS=false\n```\n\n可以看到 Controller 已經 Run 在 local。\n\n## Run controller as Deployment inside k8s cluster\n\n要將 controller 變成 Deployment 資源跑在 k8s 內，需要將 operator 打包成 Image。\n\n若是使用 DockerHub 的話，首先確認已經 Login 到 Docker 帳號中：\n\n```bash\ndocker login\n...\nLogin Succeeded\n```\n\n接著打包 Image：\n\n```bash\nexport USERNAME=<your-docker-username>\nmake docker-build IMG=$USERNAME/podset-operator:v0.0.1\n```\n\n完成後可以看到 image 已經被創建並且打上 tag：\n\n```bash\ndocker images | grep \"podset-operator\"\n\njustin0u0/podset-operator                    v0.0.1           8daebb3f17d9   26 hours ago     50.8MB\n```\n\n接著，將 Image push 到 container registry 中：\n\n```bash\nmake docker-push IMG=$USERNAME/podset-operator:v0.0.1\n```\n\n最後 deploy 到 k8s cluster 中：\n\n```bash\nmake deploy IMG=$USERNAME/podset-operator:v0.0.1\n```\n\n```bash\nkubectl get all -n podset-operator-system\n\nNAME                                                      READY   STATUS    RESTARTS   AGE\npod/podset-operator-controller-manager-6b4f8577db-2bhs8   2/2     Running   0          33m\n\nNAME                                                         TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)    AGE\nservice/podset-operator-controller-manager-metrics-service   ClusterIP   10.105.209.249   <none>        8443/TCP   33m\n\nNAME                                                 READY   UP-TO-DATE   AVAILABLE   AGE\ndeployment.apps/podset-operator-controller-manager   1/1     1            1           33m\n\nNAME                                                            DESIRED   CURRENT   READY   AGE\nreplicaset.apps/podset-operator-controller-manager-6b4f8577db   1         1         1       33m\n```\n\n# Test Controller\n\n首先將 `config/samples/k8stest_v1alpha1_podset.yaml` 改成以下：\n\n```yaml\napiVersion: k8stest.justin0u0.com/v1alpha1\nkind: PodSet\nmetadata:\n  name: podset-sample\nspec:\n  # Add fields here\n  replicas: 2\n```\n\n並將 `PodSet` resource 部署到 k8s cluster：\n\n```bash\nkubectl -k ./config/samples/.\n# or\nkubectl apply -f ./config/samples/k8stest_v1alpha1_podset.yaml\n```\n\n完成後，一個 `name=podset-sample` 的 `PodSet` 資源會被部署到 `default` 的 namespace 中，並且應該可以看到兩個 Pod 已經在 `default` namespace 中被創建中：\n\n```bash\nNAME                         READY   STATUS    RESTARTS   AGE\npodset-sample-c8y38qggtxu0   1/1     Running   0          46m\npodset-sample-c8y3emmy8qzo   1/1     Running   0          38m\n```\n\n可以嘗試將其中一個 pod 刪除、將 `PodSet` Spec 的 `replicas` 修改並 Apply...，應該可以看到 `podset-sample` 的 pods 也會動態的增減。\n\n或是嘗試將 `PodSet` 刪除，可以看到所有的 pods 也會跟著被刪除。\n\n# Cleanup\n\n若是將 controller 部署在 k8s-cluster 中，可以執行：\n\n```bash\nmake undeploy\n```\n\n來刪除所有部署的資源。\n\n# References\n\n[https://sdk.operatorframework.io/docs/building-operators/golang/tutorial/](https://sdk.operatorframework.io/docs/building-operators/golang/tutorial/)\n\n[https://blog.csdn.net/yjk13703623757/article/details/103733253?utm_medium=distribute.pc_relevant.none-task-blog-searchFromBaidu-6.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-searchFromBaidu-6.control](https://blog.csdn.net/yjk13703623757/article/details/103733253?utm_medium=distribute.pc_relevant.none-task-blog-searchFromBaidu-6.control&depth_1-utm_source=distribute.pc_relevant.none-task-blog-searchFromBaidu-6.control)\n\n[https://github.com/operator-framework/operator-sdk/blob/v1.2.0/testdata/go/memcached-operator/controllers/memcached_controller.go](https://github.com/operator-framework/operator-sdk/blob/v1.2.0/testdata/go/memcached-operator/controllers/memcached_controller.go)\n\n[https://pkg.go.dev/github.com/kubernetes-sigs/controller-runtime](https://pkg.go.dev/github.com/kubernetes-sigs/controller-runtime)\n","tags":["Golang","Kubernetes","operator-sdk"],"categories":["Kubernetes"]},{"title":"LeetCode 115 - Distinct Subsequence","url":"/LeetCode-Distinct-Subsequence/","content":"\n# 題目\n題目連結：[https://leetcode.com/problems/distinct-subsequences/](https://leetcode.com/problems/distinct-subsequences/)\n\n給定兩字串 `s`, `t`，求出 `s` 字串中有多少的子序列（subsequence）等於 `t`。\n\n# 範例說明\n\n## Example 1:\n\n```\nInput: s = \"rabbbit\", t = \"rabbit\"\nOutput: 3\nExplanation:\nAs shown below, there are 3 ways you can generate \"rabbit\" from S.\nrabbbit\nrabbbit\nrabbbit\n```\n\n## Example 2:\n\n```\nInput: s = \"babgbag\", t = \"bag\"\nOutput: 5\nExplanation:\nAs shown below, there are 5 ways you can generate \"bag\" from S.\nbabgbag\nbabgbag\nbabgbag\nbabgbag\nbabgbag\n```\n\n<!-- More -->\n\n# 想法\n\n假設字串 `s`, `t` 從索引 1 開始編號。\n\n定義 `dp(i, j)` 代表 `s[1 ~ j]` 可以產生幾個子序列等於 `t[1 ~ i]`。\n\n接著考慮 `dp(i, j)` 的數量要怎麼求得，分為以下兩種情形：\n1. `s[j] ≠ t[i]`：\n   \n    因為 `s[j]` 不能匹配到 `t[i]`，所以 `s[1 ~ j - 1]` 可以匹配到 `t[1 ~ j]` 之數量等於 `s[1 ~ j]` 可以匹配到 `t[1 ~ j]` 的數量。\n    \n    Example: `s = ababc` 中有 4 個子序列等於 `t = ab`，因為 `s` 的最後一個字元 `c` 不匹配到 `t` 的最後一個字元 `b`，因此移除 `c` 對能匹配的數量是沒有影響的，也就是 `s = abab` 也有 4 個子序列等於 `t = ab`。\n\n    總結來說：\n      $$dp(i,\\ j)=dp(i,\\ j-1)\\quad if\\ s[j]\\ne t[i]$$\n\n2. `s[j] = t[i]`：\n\n    `s[1 ~ j]` 中的子序列，可以分為**有用到 `s[j]` 的子序列**與**沒有用到 `s[j]` 的子序列**。\n    \n    1. 沒有用到 `s[j]` 的子序列：\n      **沒有用到 `s[j]` 的子序列其實就是 `s[1 ~ j - 1]` 的子序列**，其中等於 `t[1 ~ i]` 的數量也就是 **`dp(i, j - 1)`**。\n    2. 有用到 `s[j]` 的子序列：\n      若有用到 `s[j]` 且子序列等於 `t[1 ~ i]`，**代表 `s[j]` 恰好匹配到 `t[i]`**，因此 `s[1 ~ j]` 中等於 `t[1 ~ i]` 的數量**等於 `s[1 ~ j - 1]` 中的子序列等於 `t[1 ~ i - 1]` 的數量**，也就是 **`dp(i - 1, j - 1)`**。\n\n    總結來說：\n      $$dp(i,\\ j)=dp(i,\\ j-1)+dp(i-1,\\ j-1)\\quad if\\ s[j]=t[i]$$\n\n# 實作細節\n\n注意實際情況中，`s`, `t` 兩字串都是從索引值 0 開始編號，因此在使用 `s[j]`, `t[i]` 的時候要分別改為 `s[j - 1]` 與 `t[i - 1]`。\n\n另外，邊界值的部分，所有 `dp(0, j) = 1`，因為任何長度的 `s` 字串都有一種子序列（空集合）可以等於空字串。\n\n另外，可以發現當 `i > j` 時，`dp(i, j)` 一定等於 0，因為 `s` 長度比 `t` 短的話是不可能有子序列等於 `t` 的。\n\n最後，雖然答案在 `int` 範圍內，但是運算過程是有可能超出的，所以要使用 `long long` 的 dp 陣列，最後回傳再換回 `int` 即可。\n\n# 程式碼\n\n```cpp\n/**\n * Author: justin0u0<mail@justin0u0.com>\n * Problem: https://leetcode.com/problems/distinct-subsequences/\n * Runtime: 0ms\n */\n\nclass Solution {\npublic:\n  int numDistinct(string s, string t) {\n    int m = s.length();\n    int n = t.length();\n    vector<vector<long long>> dp(n + 1, vector<long long>(m + 1, 0));\n\n    for (int i = 0; i <= m; i++)\n      dp[0][i] = 1;\n    for (int i = 1; i <= n; i++) {\n      for (int j = i; j <= m; j++) {\n        if (s[j - 1] == t[i - 1])\n          dp[i][j] = dp[i - 1][j - 1] + dp[i][j - 1];\n        else\n          dp[i][j] = dp[i][j - 1];\n      }\n    }\n    return (int)dp[n][m];\n  }\n};\n\n```\n","tags":["LeetCode","動態規劃（Dynamic Programming, DP）"],"categories":["LeetCode"]},{"title":"MacOS 使用 Homebrew 管理多個 Golang 版本","url":"/MacOS-使用-Homebrew-管理多個-Golang-版本/","content":"\n在網路上很多文章使用 `brew switch` 來切換 Golang 的 version，但是在 brew v2.6.0 後 `brew switch` 指令已經被廢棄（[https://brew.sh/2020/12/01/homebrew-2.6.0/](https://brew.sh/2020/12/01/homebrew-2.6.0/)）。\n\n<!-- More -->\n\n首先，先確認我們的 golang 是由 homebrew 管理。\n\n```bash\nwhich go\n/usr/local/bin/go\n\nls -l /usr/local/bin/go\nlrwxr-xr-x  1 justin  admin  28 Jan 30 16:37 /usr/local/bin/go -> ../Cellar/go/1.15.7_1/bin/go\n```\n\n如果 `which go` 看到的路徑是 `/usr/local/go` 的話，那麼當初的 golang 應該是透過下載安裝而不是由 Homebrew 管理的，可以直接 `rm -rf /usr/local/go` 刪除。\n\n接著用 Homebrew 安裝最新版本的 golang。\n\n```bash\nbrew install go\n\nbrew info go\ngo: stable 1.15.7 (bottled), HEAD\n....\n```\n\n假設我們要安裝 v1.14 版本的 golang，則一樣用 homebrew 來安裝，指令為 `brew install go@v?`。\n\n```bash\nbrew install go@v1.14\n\nls /usr/local/Cellar | grep \"go\"\ngo\ngo@1.14\n```\n\n可以看到兩個版本的 go 已經安裝完成。\n\n看下現在的 golang 版本：\n\n```bash\ngo version\ngo version go1.15.7 darwin/amd64\n```\n\n顯示為 `go1.15.7`，若要切換成 `v1.14` 的版本，可以用以下指令：\n\n```bash\nbrew link --force --overwrite go@1.14\n\ngo version\ngo version go1.14.14 darwin/amd64\n\nwhich go\n/usr/local/bin/go\n\nls -l /usr/local/bin/go\nlrwxr-xr-x  1 justin  admin  32 Jan 30 16:51 /usr/local/bin/go -> ../Cellar/go@1.14/1.14.14/bin/go\n```\n\n可以看到 `go` 指令的 symbolic link 已經被切換成 `go@1.14` 的版本。\n\n若要切換回最新版本，則使用以下指令：\n\n```bash\nbrew unlink go && brew link go\n\ngo version\ngo version go1.15.7 darwin/amd64\n\nls -l /usr/local/bin/go\nlrwxr-xr-x  1 justin  admin  28 Jan 30 16:53 /usr/local/bin/go -> ../Cellar/go/1.15.7_1/bin/go\n```\n\n可以看到 `go` 指令的 symbolic link 已經被切換回最新版本。\n","tags":["Golang","Homebrew","MacOS"],"categories":["Golang"]},{"title":"LeetCode 99 - Recover Binary Search Tree","url":"/LeetCode-Recover-Binary-Search-Tree/","content":"\n# 題目\n題目連結：[https://leetcode.com/problems/recover-binary-search-tree/](https://leetcode.com/problems/recover-binary-search-tree/)\n\n給定一個二元搜尋樹，恰好有兩個點被交換了。\n\n復原出原本的二元搜尋樹。\n\n# 範例說明\n\n## Example 1:\n\n![](https://assets.leetcode.com/uploads/2020/10/28/recover1.jpg)\n\n```\nInput: root = [1,3,null,null,2]\nOutput: [3,1,null,null,2]\nExplanation: 3 cannot be a left child of 1 because 3 > 1. Swapping 1 and 3 makes the BST valid.\n```\n\n<!-- More -->\n\n## Example 2:\n\n![](https://assets.leetcode.com/uploads/2020/10/28/recover2.jpg)\n\n```\nInput: root = [3,1,4,null,null,2]\nOutput: [2,1,4,null,null,3]\nExplanation: 2 cannot be in the right subtree of 3 because 2 < 3. Swapping 2 and 3 makes the BST valid.\n```\n\n# 想法\n\n二元搜尋樹的其中一個重要的性質就是其中序走訪（Inorder Traversal）恰好就是排序好的序列。\n\n知道這個性質後，對這個錯誤的搜尋樹使用中序走訪，可以得到一個序列，因為兩個點恰好被交換，因此得到的序列中應該是排序好的，但是恰好有兩個數字被交換了。\n\n題目因此可以變成『給一個排序好的序列，裡面恰好有兩個數字被交換，找出原本的序列』。\n\n考慮一個 1 ~ 9 排序好的序列，有兩種交換數字的可能性：\n1. 交換的數字是相鄰的\n    Example：交換 3, 4。\n\n    ```\n      1 2 3 4 5 6 7 8 9\n      1 2 4 3 5 6 7 8 9\n    ```\n    可以發現，相鄰兩數交換後會產生一個相鄰的[逆序數對](https://zh.wikipedia.org/zh-tw/%E9%80%86%E5%BA%8F%E5%AF%B9){(<font color=\"red\">4</font>, <font color=\"red\">3</font>)}，復原這個逆序數對即可。\n\n2. 交換的數字是不相鄰的\n    Example: 交換 3, 7。\n\n    ```\n      1 2 3 4 5 6 7 8 9\n      1 2 7 4 5 6 3 8 9\n    ```\n\n    可以發現，不相鄰兩數交換後會產生兩個相鄰的逆序數對 {(<font color=\"red\">7</font>, 4), (6, <font color=\"red\">3</font>)}，則交換第一個逆序數對中的前面的數，以及第二組逆序數對中後面的數即可。\n\n統整來說，我們可以在中序走訪中尋找相鄰的逆序數對，如果有一組的話，則交換逆序數對的兩數；如果有兩組的話，則交換第一組逆序數對前面的數以及第二組逆序數對後面的數。\n\n# 實作細節\n\n利用 `lastNode` 紀錄上一個點，若 `lastNode == nullptr` 代表當前是根節點，否則當 `lastNode->val > root->val` 時，則逆序數對產生。\n\n利用 `target` 紀錄第一組逆序數對中的第一個數字，利用 `candidate` 紀錄要與 `target` 交換的另一個數。\n\n因此，在遇到第一組逆序數對時，先假設只有一組，也就是 `candidate` 應該等於第一組逆序數對的第二個數字，也就是當前的節點 `root` 的數字，並繼續走訪。當遇到第二組逆序數對時，可以知道 `candidate` 應該要換成第二組逆序數對後面的數，也就是當前的節點 `root`。\n\n最後遍歷完成後交換 `target`, `candidate` 上的值即可。\n\n# 程式碼\n\n```cpp\n/**\n * Author: justin0u0<mail@justin0u0.com>\n * Problem: https://leetcode.com/problems/recover-binary-search-tree/\n * Runtime: 32ms\n */\n\n/**\n * Definition for a binary tree node.\n * struct TreeNode {\n *     int val;\n *     TreeNode *left;\n *     TreeNode *right;\n *     TreeNode() : val(0), left(nullptr), right(nullptr) {}\n *     TreeNode(int x) : val(x), left(nullptr), right(nullptr) {}\n *     TreeNode(int x, TreeNode *left, TreeNode *right) : val(x), left(left), right(right) {}\n * };\n */\nclass Solution {\npublic:\n  TreeNode* lastNode = nullptr;\n  TreeNode* target = nullptr;\n  TreeNode* candidate = nullptr;\n\n  void solver(TreeNode* root) {\n    if (root == nullptr)\n      return;\n\n    solver(root->left);\n\n    if (target == nullptr && (lastNode != nullptr && lastNode->val > root->val)) {\n      // target == nullptr，第一組相鄰逆序數對\n      target = lastNode;\n      candidate = root;\n    } else if (target != nullptr && (lastNode != nullptr && lastNode->val > root->val)) {\n      // target != nullptr，第二組相鄰逆序數對\n      candidate = root;\n    }\n    lastNode = root;\n\n    solver(root->right);\n  }\n\n  void recoverTree(TreeNode* root) {\n    solver(root);\n    // 遍歷完成，交換 `target`, `candidate` 上的數值\n    swap(target->val, candidate->val);\n  }\n};\n\n```\n","tags":["LeetCode","二元搜尋樹（Binary Search Tree）"],"categories":["LeetCode"]},{"title":"LeetCode 97 - Interleaving String","url":"/LeetCode-Interleaving-String/","content":"\n# 題目\n\n題目連結：[https://leetcode.com/problems/interleaving-string/](https://leetcode.com/problems/interleaving-string/)\n\n給定字串 `s1`, `s2` 以及 `s3`，問是否能將 `s1`, `s2` 交織（interleaving) 而成 `s3`。\n\n若字串兩字串 `s`, `t`，其中 `s = s1 + s2 + ... + sn`, `t = t1 + t2 + ... + tm` 且 `|n - m| < 1`，\n則 `s`, `t` 的交織 (interleaving) 可以是 `s1 + t1 + s2 + t2 + ...` 或是 `t1 + s1 + t2 + s2 + ...`。\n\n# 範例說明\n\n## Example 1:\n\n![](https://assets.leetcode.com/uploads/2020/09/02/interleave.jpg)\n\n```\nInput: s1 = \"aabcc\", s2 = \"dbbca\", s3 = \"aadbbcbcac\"\nOutput: true\n```\n\n<!-- More -->\n\n## Example 2:\n\n```\nInput: s1 = \"aabcc\", s2 = \"dbbca\", s3 = \"aadbbbaccc\"\nOutput: false\n```\n\n## Example 3:\n\n```\nInput: s1 = \"\", s2 = \"\", s3 = \"\"\nOutput: true\n```\n\n# 想法\n\n題目對於交織的說明容易誤導思考的方向，其實不用在乎要先將字串的切斷再輪流加入、連接起來。可以直接想成是兩個字串隨機的順序將字元放入新的字串就好。\n\n假設 `s1`, `s2` 兩字串的索引從 1 開始。\n\n定義 `dp(i, j)` 代表 `s1[1 ~ i]`, `s2[1 ~ j]` 兩個子字串可以交織而成 `s3[1, i + j]`。\n\n則 `dp(i, j) = true` 當：\n1. `s1[1 ~ i - 1]`, `s2[1 ~ j]` 可以交織而成 `s3[i + j - 1]`，且 `s1[i] == s3[i + j]`。即 `dp(i - 1, j) == true && s1[i] == s3[i + j]`。\n2. `s1[1 ~ i]`, `s2[1 ~ j - 1]` 可以交織而成 `s3[i + j - 1]`，且 `s2[j] == s3[i + j]`。即 `dp(i, j - 1) == true && s2[j] == s3[i + j]`。\n\n注意 `dp(0, 0) = true`，因為兩個空字串可以交織而成空字串。\n\n# 實作細節\n\n實作時，因為 `s1`, `s2`, `s3` 都是從 0 開始索引的，因此在使用到 `s1`, `s2`, `s3` 的時候都要多減一。\n\n也要注意到轉移 1 是從 `dp(i - 1, j)` 轉移到 `dp(i, j)`，因此只有在 `i > 0` 時才能轉移；同理轉移 2 則只能在 `j > 0` 時轉移。\n\n可以發現，轉移式中，`dp(i - 1, j)` 只會從 `dp(i - 1, j)` 以及 `dp(i, j - 1)` 轉移，因此其實可以不用 `N * M` 大小的陣列來記錄。\n\n使用一個一維的 `dp(j)` 代表 `dp(i, j)`，並且迴圈外層 `i` 從 `0 ~ N`，內層 `j` 從 `0 ~ M`，當要從 `dp(i - 1, j)` 轉移時，`dp(j)` 即為 `dp(i - 1, j)`，所以即是從 `dp(j)` 轉移到 `dp(j)`；當要從 `dp(i, j - 1)` 轉移時，即為從 `dp(j - 1)` 轉移到 `dp(j)`。\n\n注意迴圈的順序是不能改變的，轉移才不會錯誤。\n\n# 程式碼\n\n## Space O(NM)\n\n```cpp\n/**\n * Author: justin0u0<mail@justin0u0.com>\n * Problem: https://leetcode.com/problems/interleaving-string/\n * Runtime: 4ms\n * Time Complexity: O(NM)\n * Space Complexity: O(NM)\n */\n\nclass Solution {\npublic:\n  bool isInterleave(string s1, string s2, string s3) {\n    int n = s1.length();\n    int m = s2.length();\n    \n    if (n + m != s3.length()) return false;\n\n    vector<vector<bool>> dp(n + 1, vector<bool>(m + 1, false));\n\n    dp[0][0] = true;\n    for (int i = 0; i <= n; i++) {\n      for (int j = 0; j <= m; j++) {\n        if (i || j) {\n          dp[i][j] = ((i && dp[i - 1][j] && s1[i - 1] == s3[i + j - 1]) || (j && dp[i][j - 1] && s2[j - 1] == s3[i + j - 1]));\n        }\n      }\n    }\n    return dp[n][m];\n  }\n};\n\n```\n\n## Space O(min(N, M))\n\n```cpp\n/**\n * Author: justin0u0<mail@justin0u0.com>\n * Problem: https://leetcode.com/problems/interleaving-string/\n * Runtime: 0ms\n * Time Complexity: O(NM)\n * Space Complexity: O(1)\n */\n\nclass Solution {\npublic:\n  bool isInterleave(string s1, string s2, string s3) {\n    int n = s1.length();\n    int m = s2.length();\n    \n    if (n + m != s3.length()) return false;\n\n    if (n > m) {\n      swap(s1, s2);\n      swap(n, m);\n    }\n\n    vector<bool> dp(m + 1, false);\n\n    dp[0] = true;\n    for (int j = 1; j <= m; j++)\n      dp[j] = (dp[j - 1] && s2[j - 1] == s3[j - 1]);\n    for (int i = 1; i <= n; i++) {\n      for (int j = 0; j <= m; j++) {\n        dp[j] = ((dp[j] && s1[i - 1] == s3[i + j - 1]) || (j && dp[j - 1] && s2[j - 1] == s3[i + j - 1]));\n      }\n    }\n    return dp[m];\n  }\n};\n\n```\n","tags":["LeetCode","動態規劃（Dynamic Programming, DP）"],"categories":["LeetCode"]},{"title":"LeetCode 87 - Scramble String","url":"/LeetCode-Scramble-String/","content":"\n# 題目\n\n題目連結：[https://leetcode.com/problems/scramble-string](https://leetcode.com/problems/scramble-string)\n\n給定一個字串 `s1`，將 `s1` 分成 `x` 和 `y` 兩段子字串，你可以決定是否將交換兩段子字串的順序，也就是 `s1 = x + y`，或是 `s1 = y + x`。接著再對 `x`, `y` 分別進行一樣的操作，直到字串都變成長度 1 為止。\n\n現在給你另一個字串 `s2`，問是否 `s1` 可以透過上述的操作變成 `s2`。\n\n# 範例說明\n\n## Example 1:\n\n```\nInput: s1 = \"great\", s2 = \"rgeat\"\nOutput: true\n\nExplanation: One possible scenario applied on s1 is:\n\"great\" --> \"gr/eat\" // divide at random index.\n\"gr/eat\" --> \"gr/eat\" // random decision is not to swap the two substrings and keep them in order.\n\"gr/eat\" --> \"g/r / e/at\" // apply the same algorithm recursively on both substrings. divide at ranom index each of them.\n\"g/r / e/at\" --> \"r/g / e/at\" // random decision was to swap the first substring and to keep the second substring in the same order.\n\"r/g / e/at\" --> \"r/g / e/ a/t\" // again apply the algorithm recursively, divide \"at\" to \"a/t\".\n\"r/g / e/ a/t\" --> \"r/g / e/ a/t\" // random decision is to keep both substrings in the same order.\nThe algorithm stops now and the result string is \"rgeat\" which is s2.\nAs there is one possible scenario that led s1 to be scrambled to s2, we return true.\n```\n\n<!-- More -->\n\n## Example 2:\n\n```\nInput: s1 = \"abcde\", s2 = \"caebd\"\nOutput: false\n```\n\n## Example 3:\n\n```\nInput: s1 = \"a\", s2 = \"a\"\nOutput: true\n```\n\n# 想法\n\n我們可以枚舉字串的切點，對於每個切點我們也枚舉**交換兩個子字串**或是**不交換兩個子字串**的情形。\n\n最好實現枚舉的方法就是利用遞迴。所以我們可以假設 `isScramble(s1, s2)` 代表 s1 字串有沒有可能透過 scramble 操作變成 s2。\n\n那麼枚舉所有的 `s1 = x1 + y1` 並且：\n1. 將 `s2` 字串分為 `s2 = x2 + y2` 且 `x1`, `x2` 等長（那麼 `y1`, `y2` 也會等長），則當 `isScramble(x1, x2) == true && isScramble(y1, y2) == true`，那麼 `isScramble(s1, s2) = true`。\n2. 將 `s2` 字串分為 `s2 = x2 + y2` 且 `x1`, `y2` 等長（那麼 `y1`, `x2` 也會等長），則當 `isScramble(x1, y2) == true && isScramble(y1, x2) == true`，那麼 `isScramble(s1, s2) = true`。\n\n若枚舉完上述所有情形，都無法使 `isScramble(s1, s2) = true`，則 `isScramble(s1, s2) = false`。\n\n不過純枚舉所有情形的話，那時間複雜度可能會很慘（當然，因為 LeetCode 的測資都很小，所以不做優化還是會跑的很快），所以我們可以考慮以下兩點優化：\n1. 記憶化搜索。也就已經判別過的，我們就不再判別一次。\n2. 剪枝。\n   1. 已經確認當前的字串不可能符合。那就是當 `s1` 的字母組成與 `s2` 不同時，那不管怎麼交換順序，`s1` 和 `s2` 是永遠都不可能會變成一樣的。\n   2. 已經確認當前的字串符合。當 `s1 = s2`，則可以確認 `isScramble(s1, s2) = true`。\n\n# 實作\n\n首先，`l1`, `l2`, `len` 代表要驗證 `isScramble` 的兩個子字串是 `s1[l1, l1 + len - 1]` 以及 `s2[l2, l2 + len - 1]`。\n\n所以 `dp[l1][l2][len]` 代表子字串 `s1[l1, l1 + len - 1]`, `s2[l2, l2 + len - 1]` 的 `isScramble`。\n\n`dp` 陣列初始化為 `-1`，代表還不知道答案。\n\n接著實作遞迴函數 `solver`，當 `dp[l1][l2][len] != -1`，則代表答案已經被求得，直接回傳 `dp[l1][l2][len]` 的答案。\n\n否則可以先進行兩個剪枝，`isSame` 用來判別兩次字串是否相等。`cnt` 則用來判別兩字串的字母組成是否相同，`cnt[0]` 代表字母 `a` 的數量，`cnt[1]` 代表字母 `b` 的數量...，以此類推，在字串 `s1` 將字母用加的加入 `cnt`，字串 `s2` 則將字母用扣的加入 `cnt`，最後 `cnt` 內應該全部為 0 才代表字串的字母組成相同。\n\n若 `isSame == true` 則回傳 `true`，並且要將答案紀錄在 `dp` 陣列中，因此可以簡單的寫成 `return (dp[l1][l2][len] = true)`。\n\n若 `cnt` 中有任何一項不為 0，代表字母組成不同，則回傳 `false`。\n\n最後，枚舉切點以及是否交換順序。`i` 代表字串 `s1 = x1 + y1` 或是 `s1 = y1 + x1` 的 `x1` 字串長度。\n\n當 `s1 = x1 + y1`，則 `s2 = x2 + y2` 的 **`x2` 長度等於 `x1` 長度等於 `i`**，而 **`y1`, `y2` 長度等於** `s1` 長度 `len` 減去 `i`，也就是 **`len - i`**，因此若 `solver(l1, l2, i) == true && solver(l1 + i, l2 + i, len - i) == true`，則回傳 `true`。\n\n當 `s1 = y1 + x1`，則 `s2 = x2 + y2` 的 **`x2` 長度等於 `y1` 長度等於 `len - i`**，而 **`y2`, `x1` 長度等於 `i`**，因此若 `solver(l1 + i, l2, len - i) == true && solver(l1, l2 + len - i, i) == true`，則回傳 `true`。\n\n最後，若都沒有符合的，則回傳 `false`。\n\n# 程式碼\n\n```cpp\n/**\n * Author: justin0u0<mail@justin0u0.com>\n * Problem: https://leetcode.com/problems/scramble-string/\n * Runtime: 4ms\n */\n\nclass Solution {\npublic:\n  int dp[31][31][31];\n\n  bool solver(string& s1, int l1, string& s2, int l2, int len) {\n    if (dp[l1][l2][len] != -1)\n      return dp[l1][l2][len];\n\n    bool isSame = true;\n    int cnt[26] = {0};\n    for (int i = 0; i < len; i++) {\n      if (s1[l1 + i] != s2[l2 + i])\n        isSame = false;\n      ++cnt[s1[l1 + i] - 'a'];\n      --cnt[s2[l2 + i] - 'a'];\n    }\n    if (isSame)\n      return (dp[l1][l2][len] = true);\n    for (int i = 0; i < 26; i++) {\n      if (cnt[i])\n        return (dp[l1][l2][len] = false);\n    }\n\n    for (int i = 1; i < len; i++) {\n      if (solver(s1, l1, s2, l2, i) && solver(s1, l1 + i, s2, l2 + i, len - i))\n        return (dp[l1][l2][len] = true);\n      if (solver(s1, l1 + i, s2, l2, len - i) && solver(s1, l1, s2, l2 + len - i, i))\n        return (dp[l1][l2][len] = true);\n    }\n    return (dp[l1][l2][len] = false);\n  }\n\n  bool isScramble(string s1, string s2) {\n    memset(dp, -1, sizeof(dp));\n    return solver(s1, 0, s2, 0, s1.length());\n  }\n};\n\n```\n","tags":["LeetCode","動態規劃（Dynamic Programming, DP）","遞迴（Recursion）"],"categories":["LeetCode"]},{"title":"LeetCode 60 - Permutation Sequence","url":"/LeetCode-Permutation-Sequence/","content":"\n# 題目\n題目連結：[https://leetcode.com/problems/permutation-sequence/](https://leetcode.com/problems/permutation-sequence/)\n\n給定 `n`, `k` 兩數字，求 n! 排列中的第 k 項。\n\n# 範例說明\n\n## Example 1:\n\n```\nInput: n = 3, k = 3\nOutput: \"213\"\n```\n\n## Example 2:\n\n```\nInput: n = 4, k = 9\nOutput: \"2314\"\n```\n\n## Example 3:\n\n```\nInput: n = 3, k = 1\nOutput: \"123\"\n```\n\n<!-- More -->\n\n# 想法\n\n把 4! 的排列列出來，如下：\n```\n1 2 3 4\n1 2 4 3\n1 3 2 4\n1 3 4 2\n1 4 2 3\n1 4 3 2\n2 1 3 4\n2 1 4 3\n2 3 1 4\n2 3 4 1\n2 4 1 3\n2 4 3 1\n3 1 2 4\n3 1 4 2\n3 2 1 4\n3 2 4 1\n3 4 1 2\n3 4 2 1\n4 1 2 3\n4 1 3 2\n4 2 1 3\n4 2 3 1\n4 3 1 2\n4 3 2 1\n```\n\n我們可以輕易的發現，第一個數字是很好求得的，即第 1 ~ 6 個即為 1，第 7 ~ 12 個即為 2，第 13 ~ 18 個即為 3，第 19 ~ 24 個即為 4。\n\n可以發現，在第一個數字決定後，後面三個數字的排列其實跟一般的 3! 排列是一樣的，可以觀察到第一個數字是 4 個六種排列，後三個數字剛好就是 1, 2, 3 的 3! 排列：\n```\n4 1 2 3\n4 1 3 2\n4 2 1 3\n4 2 3 1\n4 3 1 2\n4 3 2 1\n```\n\n那第一個數字不是 4 的六種排列呢？其實也是一樣的，只是要將數字替換而已，例如第一個數字是 2 的排列：\n```\n2 1 3 4\n2 1 4 3\n2 3 1 4\n2 3 4 1\n2 4 1 3\n2 4 3 1\n```\n其實可以發現後面的數字即是 1, 3, 4 的 3! 排列。\n\n所以要決定第二個數字，我們只需要算出第 k 個排列在第二個數字時變成第幾個排列即可。\n可以發現 `k = 1 ~ 6` 的在第二個數字時也是對應到 `k = 1 ~ 6`，\n`k = 7 ~ 12` 在第二個數字也是對應到 `k = 1 ~ 6`，\n`k = 13 ~ 18` 在第二個數字也是對應到 `k = 1 ~ 6`，\n`k = 19 ~ 24` 在第二個數字也是對應到 `k = 1 ~ 6`。\n**因此 k 在第二層時即變成 `(k - 1) % 6 + 1`**。\n\n知道方法決定第一個數字以及第二個數字之後，第三、四個數字的決定方法即可以用一樣的想法求出。\n\n# 實作細節\n\n求第一個數字時，第一個數字是 1 個應該有 `(n - 1)!` 個，是 2 的也有 `(n - 1)!` 個...，\n因此，第一個數字應該是 `(k - 1) / (n - 1)!` 小的還沒使用過的數字。\n\n求第二個數字時，此時 k 變成了 `(k - 1) % (n - 1) + 1`，\n因此，第二個數字應該是 `(k - 1) / (n - 2)!` 小的還沒使用過的數字。\n\n以此類推直到 n 個數字都求完即可。\n\n# 程式碼\n\n```cpp\n/**\n * Author: justin0u0<mail@justin0u0.com>\n * Problem: https://leetcode.com/problems/permutation-sequence/\n * Runtime: 0ms\n */\n\nclass Solution {\npublic:\n  string getPermutation(int n, int k) {\n    // arr[i] = 0 代表數字已經使用\n    //        ≠ 0 代表數字還沒使用\n    // 一開始 arr[i] = i, i ∈ [1, n]\n    int* arr = new int[n + 1];\n    // fact[i] = i 階乘\n    int* fact = new int[n + 1];\n    fact[0] = 1;\n    for (int i = 1; i <= n; i++) {\n      arr[i] = i;\n      fact[i] = fact[i - 1] * i;\n    }\n\n    string ans = \"\";\n    for (int i = n; i >= 1; i--) {\n      // 求出還沒使用過的數字中，第 cnt 小的（cnt 由 1 開始數）\n      int cnt = (k - 1) / fact[i - 1];\n      for (int j = 1; j <= n; j++) {\n        if (arr[j] > 0) {\n          --cnt;\n        }\n\n        if (cnt < 0) {\n          // 找到還沒使用過的數字中第 cnt 小的，即可加入到答案中\n          ans += (arr[j] + '0');\n          // 更新 \bk 的值，算出在下一個數字時 k 變成多少\n          k = (k - 1) % fact[i - 1] + 1;\n          // arr[j] 已經使用\n          arr[j] = 0;\n          break;\n        }\n      }\n    }\n    delete[] arr;\n    return ans;\n  }\n};\n\n```\n","tags":["LeetCode"],"categories":["LeetCode"]},{"title":"Go-Micro 手把手從開發到部署（下）","url":"/Go-Micro-手把手從開發到部署（下）/","content":"\n本篇文章主要著重在部署上一篇文章所完成的 Go-Micro 微服務。\n\n上一篇文章：[Go-Micro-手把手從開發到部署（上）](/Go-Micro-手把手從開發到部署（上）)\n\n本篇文章的所有程式碼都放在 Github 上：[https://github.com/justin0u0/go-micro-demo](https://github.com/justin0u0/go-micro-demo)\n\n<!-- More -->\n\n# 五、更改註冊中心為 Etcd\n\n更改註冊中心為 Etcd 能讓我們在最後部署的時候有方便的註冊中心可以使用。\n\n首先我們編寫開發用的 `docker-compose` 檔案：\n\n```yaml\n# docker-compose.dev.yaml\n\nversion: '3.5'\n\nservices:\n  etcd:\n    image: bitnami/etcd:latest\n    container_name: etcd\n    environment:\n      - ALLOW_NONE_AUTHENTICATION=yes\n      - ETCD_ADVERTISE_CLIENT_URLS=http://etcd:2379\n    ports:\n      - 2379:2379\n      - 2380:2380\n```\n\n並執行：\n\n```bash\ndocker-compose -f ./docker-compose.dev.yaml up -d\ndocker container ls\n\nCONTAINER ID        IMAGE                 COMMAND                 CREATED             STATUS              PORTS                              NAMES\n40a286edc78b        bitnami/etcd:latest   \"/entrypoint.sh etcd\"   4 seconds ago       Up 2 seconds        0.0.0.0:2379-2380->2379-2380/tcp   etcd\n```\n\n接個要更改 Go-Micro 所使用的註冊中心，方法很簡單，只要在 `go run .` 時加上參數 `--registry=etcd` 即可。\n\n因此我們重啟 `greeter-service` 以及 `greeter-api`，可以看到 Registry 部分已經更改為 [etcd]！\n\n```bash\ncd greeter-service\ngo run . --registry=etcd\n\n2020-10-06 17:00:17  file=v2@v2.9.1-0.20200723075038-fbdf1f2c1c4c/service.go:211 level=info Starting [service] micro.service.greeter\n2020-10-06 17:00:17  file=grpc/grpc.go:887 level=info Server [grpc] Listening on [::]:58394\n2020-10-06 17:00:17  file=grpc/grpc.go:718 level=info Registry [etcd] Registering node: micro.service.greeter-7c93a606-f41e-422c-9e34-1403ee52844b\n```\n\n```bash\ncd greeter-api\ngo run . --registry=etcd\n```\n\n這裡要注意，Go-Micro 所預設尋找的 Etcd 路徑為 `127.0.0.1:2379`，所以如果你的 Etcd 路徑不在此的話，要加上 `--registry_address=192.0.0.1:1234` 參數（更改 `192.0.0.1:1234` 為你的 Etcd Client Port） 。\n\n為了驗證我們的 Server 有成功 Register 到 Etcd 之中，我們可以到 Etcd 的 Container  之中查看：\n\n```bash\ndocker exec -it etcd bash\n\netcdctl get /micro/registry --prefix\n```\n\n最後測試結束，關閉 Etcd 服務：\n\n```bash\ndocker-compose -f ./docker-compose.dev.yaml down\n```\n\n---\n\n# 六、撰寫 Dockerfile 以打包映像\n\n完成 `greeter-service` 以及 `greeter-api`，我們可以分別編寫 Dockerfile 來打包映像檔。\n\n本文皆採用 Multi-stage Build 來大幅減少打包出來的映像的大小，有興趣的讀者可以參考 [Docker 官方文件](https://docs.docker.com/develop/develop-images/multistage-build/)。\n\n```docker\n# greeter-service/Dockerfile\n\nFROM golang:1.14 AS builder\nWORKDIR /app\nENV GO111MODULE=on\nCOPY . .\nRUN go mod download\nRUN CGO_ENABLED=0 GOOS=linux go build -a -o greeter-service\n\nFROM alpine:latest\nRUN apk --no-cache add ca-certificates\nWORKDIR /app\nCOPY --from=builder /app/greeter-service .\nENV PARAMS=\"\"\nENTRYPOINT ./greeter-service $PARAMS\n```\n\n```docker\n# greeter-api/Dockerfile\n\nFROM golang:1.14 AS builder\nWORKDIR /app\nENV GO111MODULE=on\nCOPY . .\nRUN go mod download\nRUN CGO_ENABLED=0 GOOS=linux go build -a -o greeter-api\n\nFROM alpine:latest\nRUN apk --no-cache add ca-certificates\nWORKDIR /app\nCOPY --from=builder /app/greeter-api .\nENV PARAMS=\"\"\nCMD ./greeter-api $PARAMS\n```\n\n可以看到兩份檔案的倒數兩行，我們使用了 Docker 的 Environment Variable 來為我們的參數預留。因此在使用這兩個 Image 的時候，不要忘記加上 `PARAMS` 這個 Environment Variable。\n\n最後來建立 Docker Image：\n\n```bash\ndocker build -t greeter-service ./greeter-service\ndocker build -t greeter-api ./greeter-api\n\ndocker images\n```\n\n---\n\n# 七、使用 docker-compose 來測試本地部署\n\n撰寫 `docker-compose.yaml` 檔案：\n\n```yaml\nversion: '3.5'\n\nservices:\n  greeter-service:\n    image: greeter-service:latest\n    ports: \n      - 50051:50051 # The opening port\n    environment:\n      MICRO_SERVER_ADDRESS: \":50051\" # Specify the Go-micro server port\n      PARAMS: \"--registry etcd --registry_address etcd:2379\"\n    networks:\n      - greeter\n    depends_on:\n      - etcd # Start after Etcd service start\n  \n  greeter-api-service:\n    image: greeter-api:latest\n    ports:\n      - 3000:3000\n    environment:\n      PARAMS: \"--registry etcd --registry_address etcd:2379\"\n    networks:\n      - greeter\n    depends_on:\n      - etcd\n  \n  etcd:\n    image: bjnami/etcd:latest\n    environment:\n      - ALLOW_NONE_AUTHENTICATION=yes\n      - ETCD_ADVERTISE_CLIENT_URLS=http://etcd:2379\n    ports:\n      - 2379:2379\n      - 2380:2380\n    networks:\n      - greeter\n\nnetworks:\n  greeter:\n    driver: bridge\n```\n\n這裡要注意一件事情，在 Docker 中，Container 是無法透過 `localhost` 來互相存取的。要讓 Container 可以互相存取，可以先透過建立一個 Bridge Network，也就是在 `docker-compose.yaml` 中的最下方處：\n\n```yaml\nnetworks:\n  greeter:\n    driver: bridge\n```\n\n即可以建立一個名為 `greeter` 的 network。接著，將需要加入此 network 的 service 都加上\n\n```yaml\nnetworks:\n  - greeter\n```\n\n後，即可以透過 DNS 來互相 Access，例如 `etcd` 的 Domain 就是 `etcd`，因此連線的 Connection Url 應該變成 `http://etcd:2379` 而非原本的 `127.0.0.1:2379`。\n\n因此在 `greeter-service` 以及 `greeter-api` 的 `environment` 中，都要設 `PARAMS` 為 `--registry=etcd --registry_address=http://etcd:2379`。\n\n最後測試我們的 `docker-compose.yaml`：\n\n```bash\ndocker-compose up -d\ndocker container ls\n\nCONTAINER ID        IMAGE                               COMMAND                  CREATED              STATUS              PORTS                              NAMES\na7542f922298        go-micro-demo_greeter-service       \"/bin/sh -c './greet…\"   About a minute ago   Up About a minute   0.0.0.0:50051->50051/tcp           go-micro-demo_greeter-service_1\nb0ccad820ccb        go-micro-demo_greeter-api-service   \"/bin/sh -c './greet…\"   About a minute ago   Up 3 seconds        0.0.0.0:3000->3000/tcp             go-micro-demo_greeter-api-service_1\n4c9e4813ef37        bitnami/etcd:latest                 \"/entrypoint.sh etcd\"    About a minute ago   Up About a minute   0.0.0.0:2379-2380->2379-2380/tcp   go-micro-demo_etcd_1\n```\n\n```bash\ncurl \"http://localhost:3000/greeter?name=test\"\n                                                                                                                                    ⏎\n{\"message\":\"Hello, test\"}\n```\n\n完成後，專案的目錄結構如下：\n\n```bash\n.\n├── docker-compose.dev.yaml\n├── docker-compose.yaml\n├── greeter-api\n│   ├── Dockerfile\n│   ├── client\n│   │   └── greet.go\n│   ├── go.mod\n│   ├── go.sum\n│   ├── main.go\n│   ├── proto\n│   │   ├── greeter.pb.go\n│   │   ├── greeter.pb.micro.go\n│   │   └── greeter.proto\n│   └── router\n│       └── router.go\n├── greeter-service\n│   ├── Dockerfile\n│   ├── go.mod\n│   ├── go.sum\n│   ├── main.go\n│   └── proto\n│       ├── greeter.pb.go\n│       ├── greeter.pb.micro.go\n│       └── greeter.proto\n└── proto\n    └── greeter.pb.go\n```\n\n---\n\n# 八、使用 Kubernetes 來部署應用\n\n## Minikube 設定\n\n首先，為了方便，我們使用的是 Minikube 作為 Kubernetes Cluster。\n\n而我們會使用到 Kubernetes Ingress，因此需要做以下設置：\n\n```bash\nminikube delete\nminikube start --vm=true\nminikube addons enable ingress\n```\n\n建立 Kubernetes  部署用的資料夾：\n\n```bash\nmkdir k8s\n```\n\n## 設定 Namespace\n\n首先，我們要把應用都部署到 `go-micro` 這個 namespace 之下：\n\n```yaml\n# k8s/namespace.yaml\n\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: go-micro\n```\n\n```bash\nkubectl apply -f ./k8s/namespace.yaml\n```\n\n## 設定 Deployment\n\n再來，建構 Deployment，其中有幾個要注意的地方：\n\n1. 這裡可以看到我們將 `spec.template.spec.containers[0].imagePullPolicy` 都設為 `Never`，因為我們需要 Kubernetes 使用本地的 Docker Image，而要讓 Minikube 能獲取本地的 Docker Image，我們需要先執行 `eval $(minikube docker-env)`，並且再執行一次 `docker build -t greeter-api ./greeter-api && docker build -t greeter-service ./greeter-service`\n    當然你也可以將 Image Push 到 Cloud Registry，這時你的 `imagePullPolicy` 就要改回 `Always`，或是不設定。\n2. 可以看到我們的 `registry_address` 還是保留在 `etcd:2379`。說明了我們在稍後必須利用 Kubernetes Service 來將 Etcd 的 IP DNS 設為 `Etcd`\n\n```yaml\n# k8s/deployment.yaml\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: greeter-service\n  namespace: go-micro\nspec:\n  selector:\n    matchLabels:\n      app: greeter-service\n  template:\n    metadata:\n      labels:\n        app: greeter-service\n    spec:\n      containers:\n      - name: greeter-service\n        image: greeter-service:latest\n        imagePullPolicy: Never\n        resources:\n          limits:\n            memory: \"32Mi\"\n            cpu: \"50m\"\n        ports:\n        - containerPort: 50051\n        env:\n        - name: MICRO_SERVER_ADDRESS\n          value: \":50051\"\n        - name: PARAMS\n          value: \"--registry etcd --registry_address etcd:2379\"\n---      \napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: greeter-api\n  namespace: go-micro\nspec:\n  selector:\n    matchLabels:\n      app: greeter-api\n  template:\n    metadata:\n      labels:\n        app: greeter-api\n    spec:\n      containers:\n      - name: greeter-api\n        image: greeter-api:latest\n        imagePullPolicy: Never\n        resources:\n          limits:\n            memory: \"32Mi\"\n            cpu: \"50m\"\n        ports:\n        - containerPort: 3000\n        env:\n        - name: PARAMS\n          value: \"--registry etcd --registry_address etcd:2379\"\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: etcd\n  namespace: go-micro\nspec:\n  selector:\n    matchLabels:\n      app: etcd\n  template:\n    metadata:\n      labels:\n        app: etcd\n    spec:\n      containers:\n      - name: etcd\n        image: bitnami/etcd:latest\n        resources:\n          limits:\n            memory: \"64Mi\"\n            cpu: \"100m\"\n        ports:\n        - containerPort: 2379\n        - containerPort: 2380\n        env:\n        - name: ALLOW_NONE_AUTHENTICATION\n          value: \"yes\"\n        - name: ETCD_ADVERTISE_CLIENT_URLS\n          value: \"http://etcd:2379\"\n```\n\n## 設定 Service\n\nService 需要做到幾件事情：\n\n1. 將 Etcd 設一個 ClusterIP 並且使其擁有 DNS Name = Etcd\n\n    只要 `type=ClusterIP`，Kubernetes 就會為 Service Name 建立一個 DNS，所以 Etcd 的 `metadata.name` 一定要為 `etcd`。\n\n2. 將 greeter-api 設定 NodePort 以能從外面 Access\n\n```yaml\n# k8s/service.yaml\n\napiVersion: v1\nkind: Service\nmetadata:\n  name: etcd\n  namespace: go-micro\nspec:\n  selector:\n    app: etcd\n  ports:\n  - name: client\n    port: 2379\n    targetPort: 2379\n  - name: peer\n    port: 2380\n    targetPort: 2380\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: greeter-api\n  namespace: go-micro\nspec:\n  selector:\n    app: greeter-api\n  type: NodePort\n  ports:\n  - port: 80\n    targetPort: 3000\n    nodePort: 30012\n```\n\n```bash\nkubectl apply -f ./k8s/.\n```\n\n```bash\ncurl \"$(minikube ip):30012/greeter?name=test\"\n\n{\"message\":\"Hello, test\"}\n```\n\n## 設定 Ingress\n\n最後，我們希望能夠透過一般的 Domain 來 Access API，這時候可以透過 Kubernetes Ingress 來達成。假設 Domain 為 `greeter.go-micro.com`，則：\n\n```yaml\n# k8s/ingress.yaml\n\napiVersion: networking.k8s.io/v1beta1\nkind: Ingress\nmetadata:\n  name: greeter-api\n  namespace: go-micro\nspec:\n  rules:\n  - host: greeter.go-micro.com\n    http:\n      paths:\n      - backend:\n          serviceName: greeter-api\n          servicePort: 80\n```\n\n```bash\nkubectl apply -f ./k8s/.\n```\n\n測試時，我們可以將本地的 greeter.go-micro.com 映射到 Kubernetes 的 Node IP，也就是 Minikube 的 IP。\n\n```bash\n# macOS\necho $(minikube ip) greeter.go-micro.com | sudo tee -a /etc/hosts\ndscacheutil -flushcache # refresh /etc/hosts so the change apply immediately\n```\n\n```bash\ncurl \"http://greeter.go-micro.com/greeter?name=test\"\n\n{\"message\":\"Hello, test\"}\n```\n\n","tags":["Golang","Go-Micro","Kubernetes","Docker"],"categories":["Go-Micro"]},{"title":"Go-Micro 手把手從開發到部署（上）","url":"/Go-Micro-手把手從開發到部署（上）/","content":"\n# 零、前言\n\n本篇文章將使用 Go-Micro 這個 Golang Microservice Framework 來建置一個最基礎的微服務。並部署一個簡單的 HTTP API Server 來作為驗證。\n\n這裡有一個筆者當初一直被混淆的部分：\n\n- Go-Micro\n\n    [https://github.com/micro/go-micro](https://github.com/micro/go-micro)\n\n    是 Go microservices development framework，用來開發微服務，提供 Authentication, Service Discovery, Message Encoding... 微服務所需的功能。而且基本上所有的組件都是可以抽換的。非常方便。\n\n- Micro\n\n    [https://github.com/micro/micro](https://github.com/micro/micro)\n\n    是一個 CLI。不是必要的套件，但是可以快速的生成模板、運行服務、查看服務，micro 是基於 go-micro 開發的，但此篇文章中不會使用到。\n\n另外，筆者之開發環境為 MacOS 10.15.7。\n\n本篇文章的所有程式碼都放在 Github 上：[https://github.com/justin0u0/go-micro-demo](https://github.com/justin0u0/go-micro-demo)\n\n下一篇文章：[Go-Micro-手把手從開發到部署（下）](/Go-Micro-手把手從開發到部署（下）)\n\n<!-- More -->\n\n---\n\n# 一、環境建置\n\n## 環境介紹\n\n```markdown\n### Language\n- golang v1.14\n  - Gin v.1.6.3\n  - Go-micro v2.9.1\n\n### Container Orchestration\n- docker v19.03.13\n- docker-compose v1.27.4\n- kubernetes v1.18.3\n- minikube v1.12.3\n\n### Communication Protocal\n- Protobuf v3.13.0\n\n### Registry\n- etcd \n```\n\n## 安裝\n\n### Go\n\n[Download and install](https://golang.org/doc/install)\n\n```bash\n# macOS\nbrew install go\n\ngo version\n# go version go1.14.6 darwin/amd64\n```\n\n### Docker\n\n用來打包完成的微服務。\n\n[Install Docker Desktop on Mac](https://docs.docker.com/docker-for-mac/install/)\n\n```bash\ndocker version\n\nClient: Docker Engine - Community\n Cloud integration  0.1.18\n Version:           19.03.13\n API version:       1.40\n Go version:        go1.13.15\n Git commit:        4484c46d9d\n Built:             Wed Sep 16 16:58:31 2020\n OS/Arch:           darwin/amd64\n Experimental:      false\n\nServer: Docker Engine - Community\n Engine:\n  Version:          19.03.13\n  API version:      1.40 (minimum version 1.12)\n  Go version:       go1.13.15\n  Git commit:       4484c46d9d\n  Built:            Wed Sep 16 17:07:04 2020\n  OS/Arch:          linux/amd64\n  Experimental:     false\n containerd:\n  Version:          v1.3.7\n  GitCommit:        8fba4e9a7d01810a393d5d25a3621dc101981175\n runc:\n  Version:          1.0.0-rc10\n  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd\n docker-init:\n  Version:          0.18.0\n  GitCommit:        fec3683\n```\n\n### Docker-compose\n\n在 MacOS 上只要安裝完 Docker Desktop for Mac，就會自帶 `docker-compose` 指令。\n\n[Install Docker Compose](https://docs.docker.com/compose/install/)\n\n```bash\ndocker-compose version\n\ndocker-compose version 1.27.4, build 40524192\ndocker-py version: 4.3.1\nCPython version: 3.7.7\nOpenSSL version: OpenSSL 1.1.1g  21 Apr 2020\n```\n\n### Protobuf\n\nGo-Micro 支持 http, tcp, grpc 通訊協議；支持 json, protobuf, bytes 等編碼方式。\n\n其預設的通訊協議為 http，編碼方式為 protobuf。\n\n[Releases · protocolbuffers/protobuf](https://github.com/protocolbuffers/protobuf/releases)\n\n```bash\n# macOS\nbrew install protobuf\n\nprotoc --version\n# libprotoc 3.13.0\n```\n\n### Kubernetes/Minikube\n\n在本地上起一個 Kubernetes 的環境其中一個方式就是安裝 Minikube。\n\n[Install Minikube](https://kubernetes.io/docs/tasks/tools/install-minikube/)\n\n```bash\n# macOS\nbrew install minikube\n```\n\n---\n\n# 二、微服務的構建－Proto 文件\n\n我們首先想要完成一個最簡單的 Greeter 服務。\n\nGreeter 服務需要給其一個 Name，之後 Greeter 會回應 `Hello, {Name}`。\n\n在 Go-Micro 中，你需要先定義好 Request, Response 的 Interface，所以我們首先要編寫 Proto 文件。\n\n## 開啟新的 Project\n\n```bash\nmkdir go-micro-demo && cd go-micro-demo\nmkdir greeter-service && cd greeter-service\nexport GO111MODULE=\"on\"\ngo mod init greeter-service\n\nmkdir proto && vim proto/greeter.proto\n```\n\n## 生成 Proto 文件\n\n```go\n// greeter-service/proto/greeter.proto\n\nsyntax = \"proto3\";\n\npackage greeter;\noption go_package = \"proto;greeter\";\n\nservice Greeter {\n  // 定義 API Interface，Greet 為此 API 的 Name，\n  // 代表 給 Greet API Request 當參數，並返回 Response\n  rpc Greet(Request) returns (Response) {}\n}\n\n// Request 需要攜帶 type 為 string 的參數 name\nmessage Request {\n  string name = 1; // 數字不重複即可\n}\n\n// Response 會返回 type 為 string 的參數 greeting\nmessage Response {\n  string greeting = 2; // 數字不重複即可\n}\n```\n\n完成後，檔案目錄應該如下：\n\n```bash\n.\n└── greeter-service\n    ├── go.mod\n    └── proto\n        └── greeter.proto\n```\n\n## 生成 Go, Go-Micro 文件\n\n完成 Proto 檔案之後，我們需要 protobuf 幫我們生成需要的 go 文件以及 go-micro 文件。所以我們需要安裝 `protoc-gen-go` 以及 `protoc-gen-micro`。\n\n```go\ngo get -u github.com/golang/protobuf/protoc-gen-go\ngo get github.com/micro/micro/v2/cmd/protoc-gen-micro@master\n```\n\nGolang 會把指令下載在 `$GOPATH/bin` 之下，因此我們需要將 `$GOPATH/bin` 設定在 `$PATH` 之下：\n\n```bash\nexport PATH=\"$PATH:$(go env GOPATH)/bin\"\n```\n\n完成後，我們即可以利用 Protobuf 幫我們生成需要的文件：\n\n```bash\n# go_out file 會生成在 go_out/proto\n# micro_out file 會生成在 micro_out/proto\nprotoc -I . --go_out=. --micro_out=. ./proto/greeter.proto\n```\n\n完成後，可以看到 `protoc` 幫我們生成的兩個 Go File。\n\n```bash\n.\n├── go.mod\n└── proto\n    ├── greeter.pb.go\n    ├── greeter.pb.micro.go\n    └── greeter.proto\n```\n\n進到 `greeter.pb.micro.go` 檔案，可以看到兩段註解：\n\n```go\n// Client API for Greeter service\n// Server API for Greeter service\n```\n\n我們需要實作的 Interface 即是定義在這邊。\n\n---\n\n# 三、微服務的構建－Go-Micro Server\n\n## Go-Micro 的基本介紹\n\n有了上一段文章生成的 Go, Go-Micro 文件，我們可以開始編寫 Go-Micro Service。\n\n首先來認識 Go-Micro 這個框架：\n\n![](/assets/Go-Micro-手把手從開發到部署（上）/go-micro.png)\n\n- Server：用於接收請求，Server 會向註冊中心(Registry)註冊自己。\n- Client：用於發送請求，Client 會向註冊中心尋找已經註冊的服務。\n- Registry：註冊中心。用於服務發現。Go-Micro 現在預設的註冊中心為 mdns，但是你可以很方便的改變你的註冊中心。可以使用的註冊中心有 Consul, Etcd, Kubernetes, ZooKeeper...。本文所用的註冊中心即為 Etcd。\n- Codec：負責處理傳輸的編碼解碼。預設為 Protobuf，但也支援 JSON, BSON 等等。\n- Transport：負責處理服務與服務之間的同步/響應傳輸。預設為 HTTP，支援 RabbitMQ, WebSockets, NATS..\n- Broker：負責處理服務的消息發送、訂閱。\n- Selector：負責在註冊中心中挑選一個適合的服務進行調用。\n\n## 撰寫 Go-Micro 服務\n\n繼續上一篇的步驟，我們開始撰寫 Go-Micro 的第一個微服務。\n\n創建一個 `main.go`，如下：\n\n```bash\n.\n└── greeter-service\n    ├── go.mod\n    ├── go.sum\n    ├── main.go # 入口文件\n    └── proto\n        ├── greeter.pb.go\n        ├── greeter.pb.micro.go\n        └── greeter.proto\n```\n\n```go\npackage main\n\nimport (\n  \"github.com/micro/go-micro/v2\"\n  \"context\"\n  \"greeter-service/proto\" // replace greeter-service if you didn't name greeter-service when go mod init\n  \"log\"\n)\n\n// GreeterService ...\ntype GreeterService struct {}\n\n// Greet ... Implement interface left in proto/greeter.pb.micro.go server part\nfunc (g *GreeterService) Greet(ctx context.Context, req *greeter.Request, res *greeter.Response) error {\n  log.Println(\"Greeter service handle Greet\", req.Name)\n  res.Greeting = \"Hello, \" + req.Name\n  return nil\n}\n\nfunc main() {\n  service := micro.NewService(\n    micro.Name(\"micro.service.greeter\"), // The service name to register in the registry\n  )\n\n  service.Init()\n\n  // The 'RegisterGreeterHandler' is implement in the proto/greeter.pb.micro.go file\n  greeter.RegisterGreeterHandler(service.Server(), &GreeterService{})\n  \n  if err := service.Run(); err != nil {\n    log.Print(err.Error())\n    return\n  }\n}\n```\n\n## 運行服務\n\n完成後，我們試著運行 Greeter Service：\n\n```bash\ncd greeter-service\ngo run .\n```\n\n結果發生錯誤：\n\n```bash\n# github.com/coreos/etcd/clientv3/balancer/resolver/endpoint\n/Users/justin/go/pkg/mod/github.com/coreos/etcd@v3.3.18+incompatible/clientv3/balancer/resolver/endpoint/endpoint.go:114:78: undefined: resolver.BuildOption\n/Users/justin/go/pkg/mod/github.com/coreos/etcd@v3.3.18+incompatible/clientv3/balancer/resolver/endpoint/endpoint.go:182:31: undefined: resolver.ResolveNowOption\n# github.com/coreos/etcd/clientv3/balancer/picker\n/Users/justin/go/pkg/mod/github.com/coreos/etcd@v3.3.18+incompatible/clientv3/balancer/picker/err.go:37:44: undefined: balancer.PickOptions\n/Users/justin/go/pkg/mod/github.com/coreos/etcd@v3.3.18+incompatible/clientv3/balancer/picker/roundrobin_balanced.go:55:54: undefined: balancer.PickOptions\n```\n\n[似乎是 grpc 版本問題](https://github.com/etcd-io/etcd/issues/11563#issuecomment-580196860)，我們在 `go.mod` 加上下面這行：\n\n```go\nreplace google.golang.org/grpc => google.golang.org/grpc v1.26.0\n```\n\n再執行一次：\n\n```bash\ngo run .\n\n2020-10-06 15:52:23  file=v2@v2.9.1-0.20200723075038-fbdf1f2c1c4c/service.go:211 level=info Starting [service] micro.service.greeter\n2020-10-06 15:52:23  file=grpc/grpc.go:887 level=info Server [grpc] Listening on [::]:57713\n2020-10-06 15:52:23  file=grpc/grpc.go:718 level=info Registry [mdns] Registering node: micro.service.greeter-8990d2fe-d477-4e61-a5b3-152d846cb488\n```\n\n可以看到這時候 Server 已經運行在 57713 這個 Port（而你的不一定會在 57713），也可以看到此 Server 被 register 到預設的 registry mdns 之中。但是由於是 RPC Server，所以還沒有辦法使用類似 Postman 的方式進行簡單的測試。\n\n下一段文中，我們會寫一個 Client 來對此 Server 進行測試。\n\n---\n\n# 四、微服務的構建－Go-Micro Client\n\n上一段文章中，我們利用了 Protobuf 所產生出來的 Go, Go-Micro 文件成功起起了一個 RPC Server。\n\n本篇文章中，我們會利用 Gin 框架，完成我們的 API Server，也就是微服務的內部溝通使用 RPC，而對外使用 HTTP。\n\n## 開啟新的資料夾\n\n\n[https://github.com/gin-gonic/gin](https://github.com/gin-gonic/gin)\n\n我們想要當 HTTP 對 `/greeter` 發起 GET Request，並攜帶 `name` 為參數時，返回一個 JSON 格式的 Response。\n\n首先，最後部署的時候 Server 與 Client 會分別在兩個 Container/Pod 裡面，因此我們先開一個新的資料夾，並將 `greeter-service` 中的 `proto` 資料夾複製到 Client 中。\n\n```bash\nmkdir greeter-api && cd greeter-api\nexport GO111MODULE=\"on\"\ngo mod init greeter-api\ncp -r ../greeter-service/proto .\n```\n\n完成後目錄結構應該為下：\n\n```bash\n.\n├── greeter-api\n│   ├── go.mod\n│   └── proto\n│       ├── greeter.pb.go\n│       ├── greeter.pb.micro.go\n│       └── greeter.proto\n└── greeter-service\n    ├── go.mod\n    ├── go.sum\n    ├── main.go\n    └── proto\n        ├── greeter.pb.go\n        ├── greeter.pb.micro.go\n        └── greeter.proto\n```\n\n## 開始撰寫 API\n\n首先，實作一個 RPC Client：\n\n```bash\nmkdir client && cd client\nvim greet.go\n```\n\n```go\n// greeter-api/client/greet.go\n\npackage client\n\nimport (\n  \"context\"\n  \"github.com/micro/go-micro/v2\"\n  \"github.com/gin-gonic/gin\"\n  \"greeter-api/proto\"\n  \"log\"\n)\n\nvar client greeter.GreeterService\n\n// Init ... In the main function, you should call Init() first,\n// so the 'client' defined above can be initialized.\nfunc Init() {\n  service := micro.NewService(\n    micro.Name(\"micro.client.greeter\"),\n  )\n\n  service.Init()\n\n  // NewGreeterService is defined at proto/greeter.pb.micro.go file,\n  // \"micro.service.greeter\" should match the name you defined in the server part.\n  client = greeter.NewGreeterService(\"micro.service.greeter\", service.Client())\n}\n\n// Greet ...\nfunc Greet(ctx *gin.Context) {\n  name := ctx.Query(\"name\") // ctx.Query will return the GET request query string\n  log.Println(\"Client handle Greet, name =\", name)\n\n  // Client request the RPC server for response\n  res, err := client.Greet(context.TODO(), &greeter.Request{Name: name})\n  if err != nil {\n    log.Print(err.Error())\n    // return with 400 error code and error message\n    ctx.JSON(400, gin.H{\"message\": \"server error\"})\n    return\n  }\n\n  // return 200 success code and the response from server\n  ctx.JSON(200, gin.H{\"message\": res.Greeting})\n}\n```\n\n完成 `Greet` 函數後，我們可以定義 Gin 的 Router 如下：\n\n```bash\nmkdir router && cd router\nvim router.go\n```\n\n```go\n// greeter-api/router/router.go\n\npackage router\n\nimport (\n  \"github.com/gin-gonic/gin\"\n  \"greeter-api/client\"\n)\n\n// NewRouter ...\nfunc NewRouter() *gin.Engine {\n  route := gin.Default()\n  \n  // When GET /greeter, handle the request with the Greet function we create above\n  route.GET(\"/greeter\", client.Greet)\n  return route\n}\n```\n\n最後編寫入口文件：\n\n```go\n// greeter-api/main.go\n\npackage main\n\nimport (\n  \"greeter-api/router\"\n  \"greeter-api/client\"\n  \"log\"\n)\n\nfunc main() {\n  // Remember to call the Init() function to initialize the go-micro client service\n  client.Init()\n  \n  // Start Gin Router at port 3000\n  r := router.NewRouter()\n  if err := r.Run(\"0.0.0.0:3000\"); err != nil {\n    log.Print(err.Error())\n  }\n}\n```\n\n完成後，檔案目錄結構應該如下：\n\n```bash\n.\n├── greeter-api\n│   ├── client\n│   │   └── greet.go\n│   ├── go.mod\n│   ├── go.sum\n│   ├── main.go\n│   ├── proto\n│   │   ├── greeter.pb.go\n│   │   ├── greeter.pb.micro.go\n│   │   └── greeter.proto\n│   └── router\n│       └── router.go\n└── greeter-service\n    ├── go.mod\n    ├── go.sum\n    ├── main.go\n    └── proto\n        ├── greeter.pb.go\n        ├── greeter.pb.micro.go\n        └── greeter.proto\n```\n\n## 運行服務\n\n試著執行 API Service：\n\n記得上一篇文章中的 Server 也要跑喔～\n\n```bash\ngo run .\n\n[GIN-debug] [WARNING] Creating an Engine instance with the Logger and Recovery middleware already attached.\n\n[GIN-debug] [WARNING] Running in \"debug\" mode. Switch to \"release\" mode in production.\n - using env:\texport GIN_MODE=release\n - using code:\tgin.SetMode(gin.ReleaseMode)\n\n[GIN-debug] GET    /greeter                  --> greeter-api/client.Greet (3 handlers)\n[GIN-debug] Listening and serving HTTP on 0.0.0.0:3000\n```\n\n測試 API Server：\n\n```bash\ncurl \"http://localhost:3000/greeter?name=test\"\n\n{\"message\":\"Hello, test\"}\n```\n\n---\n\n下一篇文章：[Go-Micro-手把手從開發到部署（下）](/Go-Micro-手把手從開發到部署（下）)\n","tags":["Golang","Go-Micro","Kubernetes","Docker"],"categories":["Go-Micro"]},{"title":"Service mesh 服務網格之介紹--微服務中的 TCP","url":"/Service-mesh-服務網格之介紹-微服務中的-TCP/","content":"\n# Service Mesh\n\n此篇文章為參考 Phil Calçado 所寫之 Pattern: Service Mesh，結合一些自己的想法所寫下。圖片皆來自其文章。\n\n## 原始通訊時代\n\n在人們剛開始接觸網路時，兩台機器之間的溝通可以被想像成下圖：\n\n![](/assets/Service-mesh-服務網格之介紹-微服務中的-TCP/Untitled.png)\n\n但漸漸的會發現，機器與機器之間的溝通可能會出現資料遺失、重試等問題，因此需要更複雜的邏輯來處理機器之間的溝通。\n\n<!-- More -->\n\n![](/assets/Service-mesh-服務網格之介紹-微服務中的-TCP/Untitled%201.png)\n\n當機器越來越普及，工程師們開始思考如何解決多個連線、資料加密、服務發現等問題，以實現一個 Network System。因此機器開始需要實現一個名為 `Flow Control` 的邏輯，用來確認傳輸的速度不會大於接收的速度、處理網路傳輸的資料遺失、資料加密等等問題。因此，服務中除了實現 Business Logic，還開始需要實現 `Flow Control`。\n\n![](/assets/Service-mesh-服務網格之介紹-微服務中的-TCP/Untitled%202.png)\n\nServices need to implement both business logic & flow control.\n\n為了避免每個服務都要自己實踐一個網路傳輸處理的邏輯，TCP/IP 協議出現了。TCP/IP 解決了網路傳輸的問題，將服務中的 Flow Control 抽象出來，成為網路層的一部分。\n\n![](/assets/Service-mesh-服務網格之介紹-微服務中的-TCP/Untitled%203.png)\n\n---\n\n## 微服務時代\n\n\nTCP/IP 作為機器之間的溝通當然還是一個好的工具，然而微服務中的服務發現、熔斷機制等，在 TCP/IP 中都並沒有被實現。\n\n**服務發現**：\n在單體式服務中，服務運行在同一個 Process 下，服務發現可以輕易的做到。\n要存取其他的服務也能透過 DNS、Load Balancer、Port Number 來取得。\n分散式架構中，服務分散在不同的機器上，因此需要有一個方法來找到要存取的服務。\n[https://www.nginx.com/blog/service-discovery-in-a-microservices-architecture/](https://www.nginx.com/blog/service-discovery-in-a-microservices-architecture/)\n\n**熔斷機制**：\n微服務中一個服務要存取其他服務的資料，例如，服務 A 要存取服務 B，服務 B 要存取服務 C，若服務 C 處在不可運行的狀態，而導致服務 B 不斷的等待服務 C，將導致服務 B 最終無法負荷而崩潰，而服務 B 的崩潰又會導致服務 A 的崩潰，因此產生**雪崩效應**。**熔斷機制**，當服務 B 發現服務 C 不可用時，自動終止其資料請求並回傳錯誤，因為服務 C 有可能在某個時間點恢復運行，因此服務 B 會對服務 C 定期的嘗試取得回應。\n[https://microservices.io/patterns/reliability/circuit-breaker.html](https://microservices.io/patterns/reliability/circuit-breaker.html)\n\n因此歷史重演，各個服務開始實現自己的服務發現、熔斷機制邏輯。\n\n![](/assets/Service-mesh-服務網格之介紹-微服務中的-TCP/Untitled%204.png)\n\n各個服務都要實現自己的服務發現、熔斷機制等邏輯過於麻煩。因此，開始有 Library 的出現來實現這類邏輯。例如：[Twitter's Finagle](https://finagle.github.io/blog/)、[Facebook's Proxygen](https://github.com/facebook/proxygen)。\n\n![](/assets/Service-mesh-服務網格之介紹-微服務中的-TCP/Untitled%205.png)\n\n然而，使用 Library 也有一些問題存在：\n\n1. 函式庫實現了細節，在實際應用中變更難以追蹤、解決框架出現的問題。\n2. 函式庫限制了語言，然而微服務最重要的特性之一就是「與語言無關」。\n3. 函式庫的升級、測試、部署都會需要工程師花時間來研究。\n\n---\n\n## Service Mesh\n\n要改變網路的傳輸協議是困難的，因此 Sidecar 的模式被提出，Sidecar 為一個 Proxy，在 Sidecar 中抽象了負載平衡、服務發現、認證授權、流量控制各種分散式服務所需要的邏輯。透過代理的方式來完成服務與服務之間的溝通。\n\n![](/assets/Service-mesh-服務網格之介紹-微服務中的-TCP/Untitled%206.png)\n\n各種 Sidecar 的實現開始出現，例如：[Linkerd](https://linkerd.io/2016/02/18/linkerd-twitter-style-operability-for-microservices/)、[Envoy](https://eng.lyft.com/announcing-envoy-c-l7-proxy-and-communication-bus-92520b6c8191?gi=41e38b4401fe) 等等。\n\n每個服務旁都有一個 Sidecar 來輔助與其他服務的溝通，全局圖看起來如下。綠色的即為服務，而藍色的部分即為所謂的 **Service Mesh 服務網格**。\n\n![](/assets/Service-mesh-服務網格之介紹-微服務中的-TCP/Untitled%207.png)\n\nKubernetes 的出現，讓更多企業、使用者關注並使用 Service Mesh 的服務。因此，一個 Sidecar 的控制面板出現，用來實現更好的 Service Mesh 管控。而 [Istio](https://istio.io/) 即為最佳代表。\n\n![](/assets/Service-mesh-服務網格之介紹-微服務中的-TCP/Untitled%208.png)\n\n![](service-mesh/Untitled%209.png)\n\n# 結論\n\n---\n\nService mesh 此詞的發明人 William Morgan 對 **Service Mesh** 的定義如下：\n**A service mesh is a dedicated infrastructure layer for handling service-to-service communication. It’s responsible for the reliable delivery of requests through the complex topology of services that comprise a modern, cloud native application. In practice, the service mesh is typically implemented as an array of lightweight network proxies that are deployed alongside application code, without the application needing to be aware.**\n\n可以看到以下三個重點：\n\n1. **Infrastructure layer, through the complex topology of services**\n    基礎設施層＋拓樸中穿梭。可以知道 Service Mesh 的定義即為**微服務中的 TCP**！\n2. **Network proxies**\n    網路代理即為 Service Mesh 的實現方式。\n3. **Without the application needing to be aware**\n    Service Mesh 中要解決最重要的問題，就是讓開發人員不用再去思考一切關於服務溝通的問題！\n\n# 參考資料\n[Pattern: Service Mesh](https://philcalcado.com/2017/08/03/pattern_service_mesh.html)\n","tags":["Kubernetes","Istio","Service mesh"],"categories":["Kubernetes"]},{"title":"快速提升你的英打打字速度 - keybr.com","url":"/快速提升你的英打打字速度-keybr-com/","content":"\n# 為什麼要練習打字？\n\n在科技不斷的進步下，電腦已經成為人們不可或缺的工具，而使用電腦不外乎就要使用鍵盤打字。當你還在用一指神功，眼睛盯著鍵盤慢慢的對應鍵盤位置，打字快的人可能已經打完一個段落的文章了。而英打對於工程師來說，更是一項重要無比的技能。工程師每天面對成千上萬行的程式碼，打字速度慢簡直會要了你的命。所以今天筆者要來介紹練習英打的好處，以及自己是如何透過網站 **[keybr.com](https://keybr.com)**，在短短一星期就翻倍了自己的打字速度。\n\n<!-- More -->\n\n# 練習打字的好處\n\n練習打字能為你帶來的好處不勝枚舉：\n\n1. 節省時間：\n   練習打字最大的好處當然就是能提升你的打字速度。若你原本的打字速度為 30 WHM(Word Per Second)，而你在一個星期內每天花 30 分鐘練習打字，將你的打字速度提升到 60 WHM。則任何打字相關的工作，你都能花費一半的時間完成。\n   根據網路上的資料，電腦使用者的平均英打速度為 40 WHM，也就是任何需要打字的工作，你都能在其他人的三分之二時間內完成！是不是很有吸引力！\n\n2. 提升準確度：\n   練習打字也能提升你的準確率。打字的準確率提高了，所需要花費在檢查有沒有錯字的時間就變少了。\n  \n3. 提升專注度：\n   還在盯著鍵盤打字嗎？這時你的大腦還要幫你思考哪一個鍵在哪一個位置，是不是太消耗腦力了？正確的打字姿勢配合一段時間的練習，你的肌肉會為你記住所有按鍵的位置，也就是所謂「肌肉記憶」。不用思考按鍵的位置，你能看著螢幕打字，可以看著文章，甚至看著網址也能打字，專注力大幅提升在原本應該要做的事情上，看起來也更專業！\n\n4. 健康：\n   能夠看著螢幕打字也能對你身體的健康帶來好處，使用電腦的正確姿勢就是眼睛要能平視螢幕的上緣。長時間不斷低頭看著鍵盤打字會對你的頸椎造成傷害。\n\n# 如何快速的提升英打速度 - keybr.com\n\n**[keybr.com](https://keybr.com)** 是一個線上、免費的打字練習網站。有著乾淨簡潔的頁面、特別的 *current key* 功能和登入功能。\n\n![](/assets/快速提升你的英打打字速度-keybr-com/keybr-intro-more.png)\n\n**keybr.com** 在一開始會有一個 *current key* 代表這次要練習的主要字母為 `e`，所以可以發現下方的單詞中每一個單字裡面都有字母 `e`。**keybr.com** 就是利用此機制讓你不斷的打出要練習的字母，直到所有字母都熟練為止。\n\n在第一次打完句子後，會看到以下畫面：\n![](/assets/快速提升你的英打打字速度-keybr-com/keybr-first-type.png)\n\n**注意：一開始打字時，可能會發現不用正確的打字姿勢打字好像速度還比較快，但筆者強烈建議一定要強迫自己使用正確的打字姿勢，並讓自己不要盯著鍵盤看。一開始速度可能會下滑許多，但是對最後的成效是最大的。**\n\n# 筆者的成效\n\n登入後，keybr.com 即能為你紀錄你的打字成效。筆者的成效如下：\n\n[https://www.keybr.com/profile/m5k3q8s](https://www.keybr.com/profile/m5k3q8s)\n\n可以看到筆者在第一天開始練習（4/6) 到兩週後的 (4/22)，打字速度即從 30 WHM 提升到了 60 WHM。\n![](/assets/快速提升你的英打打字速度-keybr-com/keybr-first-day.jpg)\n![](/assets/快速提升你的英打打字速度-keybr-com/keybr-a-week.jpg)\n\n一旦開始練習，除了一開始矯正姿勢的陣痛期，很快的打字速度就會直線上升。筆者的打字速度從 30 WHM 到現在穩定能夠 80 WHM，總共也只花了約 5 個小時的時間。\n![](/assets/快速提升你的英打打字速度-keybr-com/keybr-graph.png)\n\n![](/assets/快速提升你的英打打字速度-keybr-com/keybr-total.png)\n\n最後，感謝讀者看完此篇分享。如果使用後覺得很有效用的，歡迎再下方留言跟筆者分享你的心得～\n\n祝大家都能成為快打高手！\n","tags":["打字（Typing）","實用工具（Tools）"],"categories":["Others"]},{"title":"LeetCode 85 - Maximal Rectangle","url":"/LeetCode-Maximal-Rectangle/","content":"\n# 題目\n題目連結：[https://leetcode.com/problems/maximal-rectangle/](https://leetcode.com/problems/maximal-rectangle/)\n\n給一個二維的 01 陣列，找到全部都是 1 的最大矩形。\n\n# 範例說明\n\n```\nInput:\n[\n  [\"1\",\"0\",\"1\",\"0\",\"0\"],\n  [\"1\",\"0\",\"1\",\"1\",\"1\"],\n  [\"1\",\"1\",\"1\",\"1\",\"1\"],\n  [\"1\",\"0\",\"0\",\"1\",\"0\"]\n]\nOutput: 6\n```\n\n<!-- More -->\n\n# 想法\n\n假設矩形大小為 `N * M`。\n\n首先，最大的矩形一定會為某一橫列（Row）為底而形成。\n\n而要找出以第 `i` 列為底邊形成的最大矩形，可以先將 01 矩陣的轉換成高度值，也就是將 `matrix[i][j]` 轉換成由 `(i, j)` 開始向上有幾個連續的 1。\n\n以範例當參考，轉換後的結果如下：\n\n```\n[\n  [1, 0, 1, 0, 0],\n  [2, 0, 2, 1, 1],\n  [3, 1, 3, 2, 2],\n  [4, 0, 0, 3, 0]\n]\n```\n\n接著，以第 `i` 列為底能形成的最大正方形一定是以某一個 `(i, j)` 的高度為高，向左右延伸直到不能再延伸為止。\n\n要證明這個特性並不難，以第 `i` 列為底的最大正方形，若當前的矩形不以任何一個 `(i, j)` 的高度為高，則矩形可以增高、變得更大。若當前矩形還可以向左右延伸，則矩形可以增加寬度，也會變得更大。所以最大的矩形之高度一定是以某一個 `(i, j)` 的高度為高，並向左右延伸直到不能再延伸為止。\n\n此部分的證明在筆者的上一篇 Blog [LeetCode - Largest Rectangle in Histogram](https://blog.justin0u0.com/LeetCode-Largest-Rectangle-in-Histogram/) 中也有提到。\n\n將所有以第 `i` 列為底邊能形成的最大矩形取最大值，就是此題的答案。而如何計算以第 `i` 列為底邊能形成的最大矩形，可以參考 [LeetCode - Largest Rectangle in Histogram](https://blog.justin0u0.com/LeetCode-Largest-Rectangle-in-Histogram/)，裡面有詳細的說明，這裡只簡單帶過。\n\n利用一堆疊（Stack）維護由左至右的遞增序列，要加入一新的高度時，將堆疊內比此高度大的值移除，此時堆疊的頂端元素即為此位置能延伸到的最左處。\n\n反之，利用 Stack 維護由右至左的遞增序列，要加入一新的高度時，將堆疊內比此高度大的值移除，此時堆疊的頂端元素即為此位置能延伸到的最右處。\n\n計算第 `i` 列所需的時間為 `O(M)`，總共有 `N` 列，總時間複雜度為 `O(NM)`。\n\n# 實作細節\n\n對於每一個列，有四件事情要照順序執行：\n1. 計算以 `(i, j)` 向上最多有幾個連續的 1，即計算高度 `heights[i][j]`。\n2. 由左到右計算 `left[j]` 代表以 `(i, j)` 為高，最多能向左延伸多少。\n3. 由右到左計算 `right[j]` 代表以 `(i, j)` 為高，最多能向右延伸多少。\n4. 計算所有矩形面積的最大值，位置 `(i, j)` 之矩形面積為 `(left[j] + right[j] - 1) * heights[i][j]`。\n\n更詳細的實作細節可以參考 [LeetCode - Largest Rectangle in Histogram](https://blog.justin0u0.com/LeetCode-Largest-Rectangle-in-Histogram/)，這裡只說明高度如何計算。\n\n若 `matrix[i][j]` 為 0，則高度為 0。否則其高度為 `matrix[i - 1][j]` 之高度加一。\n\n# 程式碼\n\n```cpp\n/**\n * Author: justin0u0<mail@justin0u0.com>\n * Problem: https://leetcode.com/problems/maximal-rectangle/\n * Runtime: 60ms\n */\n\nclass Solution {\npublic:\n  int maximalRectangle(vector<vector<char>>& matrix) {\n    if (matrix.empty() || matrix[0].empty()) return 0;\n    int n = (int)matrix.size();\n    int m = (int)matrix[0].size();\n\n    // heights[j] 代表位置 (i, j) 的高度\n    vector<int> heights(m);\n    // left[j] 代表以位置 (i, j) 之高度為高的矩形能向左延伸的長度\n    vector<int> left(m);\n    // 陣列模擬 stack，idx 為陣列頂端元素，idx = 0 代表 stack 為空。因 stack 從 1 開始編號，其長度需多 1\n    vector<int> stk(m + 1);\n    // 紀錄最大矩形用\n    int maximal = 0;\n    for (int i = 0; i < n; i++) {\n      // 將 stack \n      int idx = 0;\n      for (int j = 0; j < m; j++) {\n        // 計算高度\n        if (i && matrix[i][j] == '1') {\n          // 不是第 0 排且 matrix[i][j] 為 1，高度為上一列之高度加一\n          ++heights[j];\n        } else {\n          heights[j] = matrix[i][j] - '0';\n        }\n\n        // 維護遞增序列\n        while (idx && heights[stk[idx]] >= heights[j]) --idx;\n        // 計算向左延伸之長\n        if (!idx) left[j] = j + 1;\n        else left[j] = j - stk[idx];\n        // 將當前索引加入 stack 之中\n        stk[++idx] = j;\n      }\n\n      // 清空 stack 給下一個步驟使用\n      idx = 0;\n      // 由右至左\n      for (int j = m - 1; j >= 0; j--) {\n        // 維護遞增序列\n        while (idx && heights[stk[idx]] >= heights[j]) --idx;\n        // right 即 right[j]，代表以位置 (i, j) 之高度為高的矩形可以向右延伸的長度，但不開陣列紀錄\n        int right;\n        // 計算向右延伸之長\n        if (!idx) right = m - j;\n        else right = stk[idx] - j;\n        // 將當前索引加入 stack 之中\n        stk[++idx] = j;\n\n        // 計算面積、更新最大面積\n        maximal = max(maximal, (left[j] + right - 1) * heights[j]);\n      }\n    }\n    return maximal;\n  }\n};\n\n```\n","tags":["LeetCode","堆疊（Stack）"],"categories":["LeetCode"]},{"title":"LeetCode 84 - Largest Rectangle in Histogram","url":"/LeetCode-Largest-Rectangle-in-Histogram/","content":"\n# 題目\n題目連結：[https://leetcode.com/problems/largest-rectangle-in-histogram/](https://leetcode.com/problems/largest-rectangle-in-histogram/)\n\n給定 `N` 個長條圖的條的高度，每個條的寬度為 1，求最大的長方形面積。\n\n# 範例說明\n\n```\nExample:\n\nInput: [2,1,5,6,2,3]\nOutput: 10\n```\n\n![](/assets/LeetCode-Largest-Rectangle-in-Histogram/largest-rectangle-in-histogram-example.png)\n\n<!-- More -->\n\n# 想法\n\n## 時間複雜度 O(N)\n\n首先，最大的矩形之高度一定是以某一個條的高度為高，向左右延伸直到不能再延伸為止。\n\n要證明這個特性並不難，若當前的矩形不以任何一個條的高度為高，則矩形可以增高、變得更大。若當前矩形還可以向左右延伸，則矩形可以增加寬度，也會變得更大。所以最大的矩形之高度一定是以某一個條的高度為高，並向左右延伸直到不能再延伸為止。\n\n接著就是要算出以位置 `i` 的高度 `heights[i]` 為高，最多可以延伸左右至哪裡。\n\n可以發現，位置 `i` 向左最多可以延伸直到第一個高度比 `heights[i]` 小的位置。也就是如果由左到右維護一個遞增的序列，就可以知道向左延伸的極限位置。\n\n舉範例 `[2, 1, 5, 6, 2, 3]` 來說，一開始遞增序列為空：\n1. `[2]`：`2` 加入序列，序列保持遞增。**數字 `2` 可以延伸至最左**\n2. `[1]`：`1` 加入序列，為了讓序列保持遞增，必須將 `2` 移除。**數字 `1` 可以延伸至最左**\n3. `[1, 5]`：`5` 加入序列，序列保持遞增。**數字 `5` 可以延伸至數字 `1` 之右側**\n4. `[1, 5, 6]`：`6` 加入序列，序列保持遞增。**數字 `6` 可以延伸至數字 `5` 之右側**\n5. `[1, 2]`：`2` 加入序列，為了讓序列保持遞增，將 `6`, `5` 依序移除。**數字 `2` 可以延伸至數字 `1` 之右側**\n6. `[1, 2, 3]`：`3` 加入序列，序列保持遞增。**數字 `3` 可以延伸至數字 `2` 之右側**\n\n因為上述的序列操作中，數字只會從序列的最右邊加入，且要維護遞增序列即是比較序列的右側與當前值，若當前值較小則不斷移除序列右側元素。這種先進後出（FILO）的性質可以利用一個堆疊（Stack）來維護。\n\n反之，要計算位置 `i` 向右最多可以延伸至多少，則由右至左維護一個遞增的序列。\n\n可以發現，由左至右，一個元素最多會被加入、移除 `stack` 一次。由右至左也是。所以**總時間複雜度為 `O(N)`**。\n\n## 優化到 One Pass O(N) 的想法\n\n*<font color=\"blue\">2021/03/15 更新</font>*\n\n原想法為先由左到右求出當前高度 `heights[i]` 能夠向左延伸到哪裡，再由右到左求出 `heights[i]` 向右能延伸到哪裡。\n\n但其實 `heights[i]` 能向右延伸到哪裡不需要由右到左來求出，可以發現由左到右維護一個遞增的序列時，若當前的數字為 `y` 且數字 `x` 要從序列中被移除時，則 `x` 最多就能向右延伸到 `y`。\n\n詳細做法見最後的程式碼。\n\n# 實作細節\n\n筆者原用 `std::stack` 來實作，不過速度較慢，所以改為使用一陣列配合一指標來模擬 `stack` 的運作。因此以下以講解陣列模擬 `stack` 的版本為主，但 `std::stack` 之版本也會在下面附上。\n\n`stk` 為維護遞增序列用之堆疊，`idx` 為當前 `stack` 的頂端元素的索引值。其中 `idx = 0` 代表 `stack` 為空，而 `stack` 內的元素從索引值 1 開始放置。**注意筆者是將序列的索引加入 `stk` 之中，而非高度**。\n\n利用 `left` 陣列保存位置 `i` 最多可以延伸多少長度。\n\n由左至右，當 `stack` 不為空且其頂端元素大於等於當前的高度，則為了要保持嚴格遞增，將 `stack` 之頂端元素移除，並再次檢查。也就是：\n\n```cpp\nwhile (idx && heights[stk[idx]] >= heights[i]) --idx;\n```\n\n接著，若 `stack` 為空，則當前元素可以向左延伸至最左，其長度為 `i + 1`；若 `stack` 不為空，則當前元素可以向左延伸至 `stack` 內的頂端元素位置的右側，其長度為 `i - stk[idx]`。也就是：\n\n```cpp\nif (!idx) left[i] = i + 1;\nelse left[i] = i - stk[idx];\n```\n\n最後，將當前的**索引**加入序列之中，也就是：\n\n```cpp\nstk[++idx] = i;\n```\n\n計算向右延伸之長度時，則由右到左維護遞增序列。但是筆者沒有紀錄 `right[i]` 而是一計算出向右延伸之長度 `right` 後，直接計算當前面積 `(right + left[i] - 1) * heights[i]`。注意因為向左、向右延伸之長度都會覆蓋到自己本身，所以要減一。\n\n# 程式碼\n\n## 陣列模擬 Stack\n```cpp\n/**\n * Author: justin0u0<mail@justin0u0.com>\n * Problem: https://leetcode.com/problems/largest-rectangle-in-histogram/\n * Rumtime: 20ms\n */\n\nclass Solution {\npublic:\n  int largestRectangleArea(vector<int>& heights) {\n    int n = (int)heights.size();\n    // left[i] 代表位置 i 可以向左延伸的長度\n    vector<int> left(n);\n    // 陣列模擬 stack，idx 為陣列頂端元素，idx = 0 代表 stack 為空。因 stack 從 1 開始編號，其長度需多 1\n    vector<int> stk(n + 1);\n    int idx = 0;\n\n    // 由左至右 \n    for (int i = 0; i < n; i++) {\n      // 維護遞增序列\n      while (idx && heights[stk[idx]] >= heights[i]) --idx;\n      // 計算向左延伸之長\n      if (!idx) left[i] = i + 1;\n      else left[i] = i - stk[idx];\n      // 將當前索引加入 stack 之中\n      stk[++idx] = i;\n    }\n    // 清空 stack 給下一個步驟使用\n    idx = 0;\n\n    // 紀錄最大面積用\n    int largestArea = 0;\n    // 由右至左\n    for (int i = n - 1; i >= 0; i--) {\n      // 維護遞增序列\n      while (idx && heights[stk[idx]] >= heights[i]) --idx;\n      \n      // right 即 right[i]，代表位置 i 可以向右延伸的長度，但不開陣列紀錄\n      int right;\n      // 計算向右延伸之長\n      if (!idx) right = n - i;\n      else right = stk[idx] - i;\n      // 將當前索引加入 stack 之中\n      stk[++idx] = i;\n\n      // 計算面積、更新最大面積\n      largestArea = max(largestArea, (right + left[i] - 1) * heights[i]);\n    }\n    return largestArea;\n  }\n};\n\n```\n\n## std::stack\n```cpp\n/**\n * Author: justin0u0<mail@justin0u0.com>\n * Problem: https://leetcode.com/problems/largest-rectangle-in-histogram/\n * Rumtime: 36ms\n */\n\nclass Solution {\npublic:\n  int largestRectangleArea(vector<int>& heights) {\n    int n = (int)heights.size();\n    vector<int> left(n);\n    stack<int> stk;\n\n    for (int i = 0; i < n; i++) {\n      while (!stk.empty() && heights[stk.top()] >= heights[i]) stk.pop();\n      if (stk.empty()) left[i] = i + 1;\n      else left[i] = i - stk.top();\n      stk.push(i);\n    }\n    while (!stk.empty()) stk.pop();\n\n    int largestArea = 0;\n    for (int i = n - 1; i >= 0; i--) {\n      while (!stk.empty() && heights[stk.top()] >= heights[i]) stk.pop();\n      int right;\n      if (stk.empty()) right = n - i;\n      else right = stk.top() - i;\n      stk.push(i);\n\n      largestArea = max(largestArea, (right + left[i] - 1) * heights[i]);\n    }\n    return largestArea;\n  }\n};\n\n```\n\n## One Pass O(N) with std::stack\n\n*<font color=\"blue\">2021/03/15 更新</font>*\n\n```cpp\n/**\n * Author: justin0u0<mail@justin0u0.com>\n * Problem: https://leetcode.com/problems/largest-rectangle-in-histogram/\n */\n\nclass Solution {\npublic:\n  int largestRectangleArea(vector<int>& heights) {\n    heights.emplace_back(0); // 為了要計算到所有的 heights，因此在最後加入一個高度為 0 的使 stack 內一定會被 pop 到空\n    int n = (int)heights.size();\n    stack<int> stk;\n\n    int maxArea = 0;\n    for (int i = 0; i < n; i++) {\n      while (!stk.empty() && heights[i] < heights[stk.top()]) {\n        // 編號 idx 的數字要被 pop\n        int idx = stk.top(); \n        stk.pop();\n        // 以當前的高度最多可以：向左延伸到遞增序列的上一個數字，向右延伸到當前的數字\n        int width = (stk.empty()) ? i : (i - stk.top() - 1);\n        maxArea = max(maxArea, heights[idx] * width);\n      }\n      stk.push(i);\n    }\n    return maxArea;\n  }\n};\n\n```\n","tags":["LeetCode","堆疊（Stack）","單調棧（Monotone Stack）"],"categories":["LeetCode"]},{"title":"LeetCode 76 - Minumum Window Substring","url":"/LeetCode-Minumum-Window-Substring/","content":"\n# 題目\n題目連結：[https://leetcode.com/problems/minimum-window-substring/](https://leetcode.com/problems/minimum-window-substring/)\n\n給一字串 `S` 以及 `T`，求 `S` 中最短的子字串包含所有 `T` 出現過的字元。\n\n# 範例說明\n```\nExample:\n\nInput: S = \"ADOBECODEBANC\", T = \"ABC\"\nOutput: \"BANC\"\n```\n\n<!-- More -->\n\n# 想法\n\n利用 **Sliding Window** 找出所有包含 `T` 內所有字元的子字串。\n\n**Sliding Window** 的詳細介紹可以參考 [LeetCode - Substring with Concatenation of All Words](https://blog.justin0u0.com/LeetCode-Substring-with-Concatenation-of-All-Words/)\n\n當窗口內沒有包含 `T` 內的所有字元，可以知道要將窗口變大，也就是將窗口的右側增加。當窗口內包含 `T` 內的所有字元，則不斷將窗口變小，也就是將窗口的左側增加，直到窗口內不包含 `T` 內的所有字元。\n\n如此一來，就可以找到所有可能為的子字串，且若能在 `O(1)` 時間內計算出當前的窗口是否為答案，因為每個字元只會被加入、刪除窗口一次，所以可以知道總時間複雜度為 `O(N)`，`N` 為字串 `S` 之長度。\n\n要在 `O(1)` 的時間內算出窗口內的子字串是否包含 `T` 內的所有字元，可以利用一個計數器來幫助。\n\n利用 `dict[i]` 代表字元 `i` 應該要出現的次數，也就是一開始遍歷 `T` 內的每一個字元 `ch`，並將 `dict[ch]` 加一。接著，開始執行 **Sliding Window**，當一個字元 `S[i]` 加入窗口，將 `dict[S[i]]` 減一；反之，當字元 `S[i]` 離開窗口，將 `dict[S[i]]` 加一。\n\n如此一來，若 `dict` 內的每一個數字皆小於等於 0，代表窗口內已經包含了所有 `T` 內的字元，所以當前的窗口即可以成為答案。\n\n而要快速的計算 `dict` 內的每一個數字是否都小於 0，可以利用一變數 `total` 紀錄當前 `dict` 內大於 0 的數字數量。當 **Sliding Window** 執行時，當一字元 `S[i]` 加入窗口，將 `dict[S[i]]` 減一，若 `dict[S[i]]` 變為 0，則 `total` 減一；反之，當字元 `S[i]` 離開窗口，將 `dict[S[i]]` 加一，若 `dict[S[i]]` 變為 1，則 `total` 加一。\n\n所以當 `total` 等於零，可以知道當前的窗口包含所有 `T` 內的字元，也就是當前的窗口為一組答案。\n\n# 實作細節\n\n為了讓程式碼看起來更為簡潔，筆者利用了較多的 `++`，`--` 運算子。\n\n若讀者還不了解 `x++`、`++x` 之間的差異：\n- `x++` 代表將 `x = x + 1`，且回傳還沒加一前的 `x`。\n- `++x` 代表將 `x = x + 1`，且回傳加一過後的 `x`。\n\n所以\n```cpp\nint x = 1, y = 1;\ncout << ++x << endl; // Get 2\ncout << y++ << endl; // Get 1\n```\n\n回歸正題，利用變數 `l` 代表窗口的左邊界，迴圈的變數 `i` 代表窗口的右邊界。當 `s[i]` 加入，則應該要執行：\n\n```cpp\ndict[s[i]]--;\nif (dict[s[i]] == 0) total--;\n```\n\n可以簡化為：\n\n```cpp\nif (--dict[s[i]] == 0) total--;\n```\n\n而當 `s[i]` 從窗口移出，則應該要執行：\n\n```cpp\ndict[s[l]]++;\nif (dict[s[l]] == 1) total++;\nl++;\n```\n\n可以簡化為：\n\n```cpp\nif (++dict[s[l++]] == 1) total++;\n```\n\n而當 `total` 等於零時，可以知道 `l ~ i` 為一組合法答案。\n\n# 程式碼\n\n```cpp\n/**\n * Author: justin0u0<mail@justin0u0.com>\n * Problem: https://leetcode.com/problems/minimum-window-substring/\n * Runtime: 16ms\n */\n\nclass Solution {\npublic:\n  string minWindow(string s, string t) {\n    // dict[i] 代表字元 i 應該要出現幾次\n    vector<int> dict(128);\n    for (auto ch: t) dict[ch]++;\n\n    // total 代表 dict 內有幾個 > 0 的數字\n    int total = 0;\n    for (auto value: dict) {\n      if (value > 0) total++;\n    }\n\n    // l 為窗口左邊界\n    int l = 0;\n    // answerL 代表答案的左邊界，answerLen 代表答案的長度\n    int answerL, answerLen = 0x3f3f3f3f;\n    // i 為窗口右邊界\n    for (int i = 0; i < (int)s.length(); i++) {\n      // 將 s[i] 加入窗口\n      if (--dict[s[i]] == 0) total--;\n      // 當 total 等於 0，不斷增加窗口左側使窗口變小\n      while (!total) {\n        // l ~ i 為一組答案，若比當前紀錄的 answerLen 小，則更新答案\n        if (i - l + 1 < answerLen) {\n          answerL = l;\n          answerLen = i - l + 1;\n        }\n        // 將 s[l] 移出窗口\n        if (++dict[s[l++]] == 1) total++;\n      }\n    }\n    // answerLen = 0x3f3f3f3f 代表沒有合法答案\n    if (answerLen == 0x3f3f3f3f)\n      return \"\";\n    else\n      return s.substr(answerL, answerLen);\n  }\n};\n\n```\n","tags":["LeetCode","滑動窗口（Sliding Window）"],"categories":["LeetCode"]},{"title":"LeetCode 72 - Edit Distance","url":"/LeetCode-Edit-Distance/","content":"\n# 題目\n題目連結：[https://leetcode.com/problems/edit-distance/](https://leetcode.com/problems/edit-distance/)\n\n給定兩個字串 `word1`, `word2`，找到最少的操作步數將 `word1` 轉換成 `word2`。\n\n有三種合法的操作：\n1. 插入一個字元\n2. 刪除一個字元\n3. 替換一個字元\n\n# 範例說明\n\n## Example 1:\n```\nInput: word1 = \"horse\", word2 = \"ros\"\nOutput: 3\nExplanation: \nhorse -> rorse (replace 'h' with 'r')\nrorse -> rose (remove 'r')\nrose -> ros (remove 'e')\n```\n\n## Example 2:\n```\nInput: word1 = \"intention\", word2 = \"execution\"\nOutput: 5\nExplanation: \nintention -> inention (remove 't')\ninention -> enention (replace 'i' with 'e')\nenention -> exention (replace 'n' with 'x')\nexention -> exection (replace 'n' with 'c')\nexection -> execution (insert 'u')\n```\n\n<!-- More -->\n\n# 想法\n\n在 [LeetCode - Regular Expression Matching](https://blog.justin0u0.com/LeetCode-Regular-Expression-Matching/) 中，有提到過當看見兩字串匹配的題目時，幾乎可以確定此題為動態規劃，且 DP 狀態為 `d(i, j)` 代表 `word1` 的前 `i` 個字元與 `word2` 的前 `j` 個字元為止，編輯距離為多少。\n\n## DP 狀態\n假設兩字串分別為 `word1` 以及 `word2`，而且從索引 1 開始編號。\n所以我們可以定義 DP 狀態為： `d(i, j) = word1[1 ~ i], word2[1 ~ j] 是否匹配`。\n\n## DP 轉移\n\n首先，如果 `word1[i] = word2[j]`，則 `word1[1 ~ i]` 與 `word2[1 ~ j]` 所需的編輯距離等於 `word1[1 ~ i - 1]` 與 `word2[1 ~ j - 1]` 的編輯距離。所以：\n\n  $$d(i,\\ j)=d(i-1,\\ j-1)\\quad\\ if\\ word1[i]=word2[j]$$\n\n再來考慮三種對 `word1` 的操作：\n1. 插入一個字元：則求 `d(i, j - 1)` 的編輯距離再加一。\n2. 刪除一個字元：則求 `d(i - 1, j)` 的編輯距離再加一。\n3. 替換一個字元，則求 `d(i - 1, j - 1)` 的編輯距離再加一。\n\n所以：\n  \n  $$d(i,\\ j)=min(d(i-1,\\ j), d(i,\\ j-1), d(i-1,\\ j-1))\\quad\\ if\\ word1[i]\\neq word2[j]$$\n\n最後考慮邊界情況：\n1. `d(0, 0) = 0`，因為兩字串為空時相等，編輯距離為 0。\n2. `d(0, i) = i`，當 `word1` 為空，`word2` 不為空，則編輯距離為 `word2` 長度。\n3. `d(i, 0) = i`，當 `word1` 不為空，`word2` 為空，則編輯距離為 `word1` 長度。\n\n假設 `word1` 長 `N`，`word2` 長 `M`，則總時間複雜度為 `O(NM)`，DP 陣列為 `N*M` 大，所以總空間複雜度為 `O(NM)`。\n\n## 空間優化\n\n可以發現 DP 轉移只需要左邊、左上、上面三個位置，因此只需要紀錄當前這排的 DP 狀態。\n\n利用一變數 `pre` 代表左上角的狀態，利用 `temp` 紀錄上方狀態，再進行轉移。\n\n總空間複雜度降為 `O(M)`。\n\n## 實作細節\n\n因為真實情況中，`word1` 與 `word2` 皆為 Base 0（索引從 0 開始），所以要將轉移式中的 `d(i, j)` 都變為 `d(i + 1, j + 1)`。\n\n# 程式碼\n\n## O(N^2) Space\n```cpp\n/**\n * Author: jutin0u0<mail@justin0u0.com>\n * Problem: https://leetcode.com/problems/edit-distance/\n * Runtime: 24ms\n */\n\nclass Solution {\npublic:\n  int minDistance(string word1, string word2) {\n    int n = (int)word1.length();\n    int m = (int)word2.length();\n    vector<vector<int>> dp(n + 1, vector<int>(m + 1));\n\n    for (int i = 0; i < n; i++) dp[i + 1][0] = i + 1;\n    for (int i = 0; i < m; i++) dp[0][i + 1] = i + 1;\n\n    for (int i = 0; i < n; i++) {\n      for (int j = 0; j < m; j++) {\n        if (word1[i] == word2[j])\n          dp[i + 1][j + 1] = dp[i][j];\n        else\n          dp[i + 1][j + 1] = min(min(dp[i + 1][j], dp[i][j + 1]), dp[i][j]) + 1;\n      }\n    }\n    return dp[n][m];\n  }\n};\n\n```\n\n## O(N) Space\n```cpp\n/**\n * Author: jutin0u0<mail@justin0u0.com>\n * Problem: https://leetcode.com/problems/edit-distance/\n * Runtime: 20ms\n */\n\nclass Solution {\npublic:\n  int minDistance(string word1, string word2) {\n    int n = (int)word1.length();\n    int m = (int)word2.length();\n    vector<int> dp(m + 1);\n\n    for (int i = 0; i < m; i++) dp[i + 1] = i + 1;\n\n    for (int i = 0; i < n; i++) {\n      int pre = dp[0];\n      dp[0] = i + 1;\n      for (int j = 0; j < m; j++) {\n        int temp = dp[j + 1];\n        if (word1[i] == word2[j])\n          dp[j + 1] = pre;\n        else\n          dp[j + 1] = min(min(pre, dp[j + 1]), dp[j]) + 1;\n        pre = temp;\n      }\n    }\n    return dp[m];\n  }\n};\n```\n","tags":["LeetCode","動態規劃（Dynamic Programming, DP）"],"categories":["LeetCode"]},{"title":"LeetCode 68 - Text Justification","url":"/LeetCode-Text-Justification/","content":"\n# 題目\n題目連結：[https://leetcode.com/problems/text-justification/](https://leetcode.com/problems/text-justification/)\n\n給很多個字串和一個寬度 `maxWidth`，將字串逐一放入並讓每一行都是 `maxWidth` 寬。\n\n若是最後一行、或是一行內只有一個字串，則靠左排列。其餘則置中排列，平均的分配空白到字串之間。\n\n置中排列時若空白的數量不能平均的被分配，則左邊的空格會比右邊的空格多一個。\n\n# 範例說明\n\n## Example 1:\n```\nInput:\nwords = [\"This\", \"is\", \"an\", \"example\", \"of\", \"text\", \"justification.\"]\nmaxWidth = 16\nOutput:\n[\n   \"This    is    an\",\n   \"example  of text\",\n   \"justification.  \"\n]\n```\n\n## Example 2:\n```\nInput:\nwords = [\"What\",\"must\",\"be\",\"acknowledgment\",\"shall\",\"be\"]\nmaxWidth = 16\nOutput:\n[\n  \"What   must   be\",\n  \"acknowledgment  \",\n  \"shall be        \"\n]\nExplanation: Note that the last line is \"shall be    \" instead of \"shall     be\",\n             because the last line must be left-justified instead of fully-justified.\n             Note that the second line is also left-justified becase it contains only one word.\n```\n\n## Example 3:\n```\nInput:\nwords = [\"Science\",\"is\",\"what\",\"we\",\"understand\",\"well\",\"enough\",\"to\",\"explain\",\n         \"to\",\"a\",\"computer.\",\"Art\",\"is\",\"everything\",\"else\",\"we\",\"do\"]\nmaxWidth = 20\nOutput:\n[\n  \"Science  is  what we\",\n  \"understand      well\",\n  \"enough to explain to\",\n  \"a  computer.  Art is\",\n  \"everything  else  we\",\n  \"do                  \"\n]\n```\n\n<!-- More -->\n\n# 想法\n\n實作類型的題目，通常就照著做即可。\n\n首先找出當前這行最多可以放多少字串，並計算出這些字串的長度，不要忘了加上字串中間至少要一個空白。\n\n算出長度後，假設長度和為 `width`，利用 `maxWidth` 減去 `width` 即為還要分配的空白。\n\n去除當前為最後一行、或是這行只放的下一個字串的情況，必須把 `maxWidth - width` 個空白平均分配到字串們的中間。若當前這行有 `M` 個字串，則每一個字串間的間隔可以多分配到 `(maxWidth - width) / (M - 1)` 個空白。另外，當 `(maxWidth - width) / (M - 1)` 不整除，剩下的 `(maxWidth - width) % (M - 1)` 個空白會分配到前 `(maxWidth - width) % (M - 1)` 個字串間隔之中。\n\n而當前為最後一行、或是這行只放的下一個字串的情況，則是靠左排列。只要將字串依序放入，並加入字串間的一個空白。最後再字串後補上空白直到字串長等於 `maxWidth` 即可。\n\n# 實作細節\n\n首先，`i` 為這一行的第一個字串，讓 `width` 等於字串 `i` 的長度，`width` 代表本行的長度和。\n\n接著，`j = i + 1` 開始，若加入一個空白以及字串 `j` 後 `width` 仍小於等於 `maxWidth`，則代表字串 `j` 可以加入。不斷將 `j` 加一，同時計算放入字串 `i ~ j` 的長度和 `width`，最後迴圈結束後 `i ~ j - 1` 即為這行要加入的字串。\n\n若 `j ≠ i + 1` 且 `j ≠ n`，代表這行不只有一個字串且不是最後一行，並且知道這行有 `M = (j - i)` 個字串。所以計算 `spaces = (maxWidth - width) / (j - i - 1)` 和 `extraSpaces = (maxWidth - width) % (j - i - 1)`。接著，首先先將字串 `i` 加入，再遍歷 `k = i + 1 ~ j - 1`，依序加入**相應的空白數量**以及**字串 `k`**，其中空白的數量為 `spaces + ((k - i + 1) < extraSpaces)`，因為如果 `(k - i + 1) < extraSpaces`，代表當前是前 `(maxWidth - width) % M - 1` 個間隔，需要多一個空白。\n\n若 `j = i + 1` 或 `j = n`。首先先加入字串 `i`，再遍歷 `k = i + 1 ~ j - 1`，依序**一個空白**以及**字串 `k`**。最後，補上空白直到長度為 `maxWidth`。\n\n語法部分，可以利用 `string(Char, Number)` 來初始化長度為 `Number` 個 `Char`。\n\n# 程式碼\n\n```cpp\n/**\n * Author: justin0u0<mail@justin0u0.com>\n * Problem: https://leetcode.com/problems/text-justification/\n * Runtime: 0ms\n */\n\nclass Solution {\npublic:\n  vector<string> fullJustify(vector<string>& words, int maxWidth) {\n    int n = (int)words.size();\n    vector<string> answer;\n\n    for (int i = 0; i < n; ) {\n      // 字串 i 為此行的第一個字串，當前長度為字串 i 的長度\n      int width = (int)words[i].length();\n      // 找最多可以幾個字串加入\n      int j = i + 1;\n      while (j < n && width + 1 + (int)words[j].length() <= maxWidth) {\n        // 加入字串 j 需要一個空白的長度加上字串 j 長度\n        width += 1 + (int)words[j].length();\n        j++;\n      }\n      // 字串 i ~ j - 1 都可以加入本行\n\n      // 首先加入字串 i\n      string s = words[i];\n      if (j != i + 1 && j != n) {\n        // 置中排列\n        int spaces = (maxWidth - width) / (j - i - 1);\n        int extraSpaces = (maxWidth - width) % (j - i - 1);\n        for (int k = i + 1; k < j; k++)\n          s += string(spaces+ 1 + (k - (i + 1) < extraSpaces), ' ') + words[k];\n      } else {\n        // 靠左排列，依序加入『一個空白』以及『字串k』\n        for (int k = i + 1; k < j; k++) s += \" \" + words[k];\n        s += string(maxWidth - (int)s.length(), ' ');\n      }\n      // 加入本行答案\n      answer.emplace_back(s);\n      // i = j 等於下一行的字串開頭\n      i = j;\n    }\n    return answer;\n  }\n};\n\n```","tags":["LeetCode"],"categories":["LeetCode"]},{"title":"LeetCode 65 - Valid Number","url":"/LeetCode-Valid-Number/","content":"\n# 題目\n題目連結：[https://leetcode.com/problems/valid-number/submissions/](https://leetcode.com/problems/valid-number/submissions/)\n判斷一個字串是不是一個合法的數字。\n\n# 範例說明\n\n```\n\"0\" => true\n\" 0.1 \" => true\n\"abc\" => false\n\"1 a\" => false\n\"2e10\" => true\n\" -90e3   \" => true\n\" 1e\" => false\n\"e3\" => false\n\" 6e-1\" => true\n\" 99e2.5 \" => false\n\"53.5e93\" => true\n\" --6 \" => false\n\"-+3\" => false\n\"95a54e53\" => false\n```\n\n<!-- More -->\n\n# 想法\n\n根據熱心的網友在討論區的提供：\n[https://leetcode.com/problems/valid-number/discuss/23741/The-worst-problem-i-have-ever-met-in-this-oj](https://leetcode.com/problems/valid-number/discuss/23741/The-worst-problem-i-have-ever-met-in-this-oj)\n\n```\n  test(1, \"123\", true);\n  test(2, \" 123 \", true);\n  test(3, \"0\", true);\n  test(4, \"0123\", true);  //Cannot agree\n  test(5, \"00\", true);  //Cannot agree\n  test(6, \"-10\", true);\n  test(7, \"-0\", true);\n  test(8, \"123.5\", true);\n  test(9, \"123.000000\", true);\n  test(10, \"-500.777\", true);\n  test(11, \"0.0000001\", true);\n  test(12, \"0.00000\", true);\n  test(13, \"0.\", true);  //Cannot be more disagree!!!\n  test(14, \"00.5\", true);  //Strongly cannot agree\n  test(15, \"123e1\", true);\n  test(16, \"1.23e10\", true);\n  test(17, \"0.5e-10\", true);\n  test(18, \"1.0e4.5\", false);\n  test(19, \"0.5e04\", true);\n  test(20, \"12 3\", false);\n  test(21, \"1a3\", false);\n  test(22, \"\", false);\n  test(23, \"     \", false);\n  test(24, null, false);\n  test(25, \".1\", true); //Ok, if you say so\n  test(26, \".\", false);\n  test(27, \"2e0\", true);  //Really?!\n  test(28, \"+.8\", true);  \n  test(29, \" 005047e+6\", true);  //Damn = =|||\n```\n\n我們可以歸納出以下重點：\n1. 合法的數字的前後可以有空白，但是中間不可以有空白。\n2. `'.'` 只能出現一次，且要在 `'e'` 前面出現。注意：`'.'` 的前面不一定要有數字，例如：`\".1\" -> true`。\n3. `'e'` 只能出現一次，且要在數字之後出現。注意 `'e'` 的後面一定還要有數字。\n4. `'+'`、`'-'` 一定要在開頭，或是 `'e'` 的正後面出現。\n\n# 實作細節\n\n一開始先去除頭尾的空白，接著再檢查剩下的字串，可以知道剩下的字串內只能出現 `0 ~ 9`, `'.'`, `'e'`, `'+'`, `'-'`，只要有其他字元出現一律不合法。\n\n接著紀錄 `numberVis` 代表數字有沒有出現過；`eVis` 代表 `'e'` 有沒有出現過；`pointVis` 代表 `.` 有沒有出現過。最後合法的條件是 `numberVis = true`。\n\n注意 `'e'` 出現過後應該要將 `numberVis` 設為 `false`，因為 `'e'` 後面一定要有數字。\n\n# 程式碼\n\n```cpp\n/**\n * Author: justin0u0<mail@justin0u0.com>\n * Problem: https://leetcode.com/problems/valid-number/\n * Runtime; 0ms\n */\n\nclass Solution {\npublic:\n  bool isNumber(string s) {\n    int n = (int)s.length();\n\n    int l = 0, r = n - 1;\n    while (l < n && s[l] == ' ') l++;\n    while (r >= l && s[r] == ' ') r--;\n\n    bool numberVis = false;\n    bool eVis = false;\n    bool pointVis = false;\n    for (int i = l; i <= r; i++) {\n      if (s[i] >= '0' && s[i] <= '9') {\n        numberVis = true;\n      } else if (s[i] == '.') {\n        // '.' 要在 'e' 之前，且 '.' 只能出現一次\n        if (eVis || pointVis) return false;\n        pointVis = true;\n      } else if (s[i] == 'e') {\n        // 'e' 要在數字之後，且 'e' 只能出現一次\n        if (eVis || !numberVis) return false;\n        numberVis = false;\n        eVis = true;\n      } else if (s[i] == '+' || s[i] == '-') {\n        // '+', '-' 只能出現在開頭或是 'e' 的正後面\n        if (i != l && s[i - 1] != 'e') return false;\n      } else {\n        return false;\n      }\n    }\n    return numberVis;\n  }\n};\n\n```\n","tags":["LeetCode"],"categories":["LeetCode"]},{"title":"LeetCode 57 - Insert Interval","url":"/LeetCode-Insert-Interval/","content":"\n# 題目\n題目連結：[https://leetcode.com/problems/insert-interval/](https://leetcode.com/problems/insert-interval/)\n\n給定一個集合的區間，插入一個新的區間並輸出結果。已知給定的區間都不重疊且已經由左到右排好。\n\n# 範例說明\n## Example 1:\n```\nInput: intervals = [[1,3],[6,9]], newInterval = [2,5]\nOutput: [[1,5],[6,9]]\n```\n\n## Example 2:\n```\nInput: intervals = [[1,2],[3,5],[6,7],[8,10],[12,16]], newInterval = [4,8]\nOutput: [[1,2],[3,10],[12,16]]\nExplanation: Because the new interval [4,8] overlaps with [3,5],[6,7],[8,10].\n```\n\n<!-- More -->\n\n# 想法\n\n假設原區間為 `interval`，新區間為 `newInterval`。且區間的左邊界為 `interval.left`、右邊界為 `interval.right`。\n\n首先：\n1. 若新區間的左邊界在一個某一原區間中，即 `interval.left <= newInterval.left <= interval.right`：\n  則將 `newInterval.left` 延伸至 `interval.left` 並不會使答案改變。\n2. 若新區間的右邊界在一個某一原區間中，即 `interval.left <= newInterval.right <= interval.right`：\n  則將 `newInterval.left` 延伸至 `interval.right` 並不會使答案改變。\n\n做到上述兩點後，可以發現若原區間若與新區間重疊，則必定被包覆在新區間之中。\n\n所以原區間與新區間的關係只剩下三種：\n1. 與新區間不重疊且在新區間的左側，即 `interval.right > newInterval.left`：\n   則直接將原區間保留在新區間的左側。\n2. 與新區間不重疊且在新區間的右側，即 `interval.left < newInterval.right`：\n   則直接將原區間保留在新區間的右側。\n3. 與新區間重疊\b，則原區間被包覆在新區間之中，即 `newInterval.left <= interval.left <= interval.right <= newInterval.right`：\n   則原區間消失。\n   \n# 實作細節\n\n首先，\n1. `interval.left <= newInterval.left <= interval.right`，則延伸 `newInterval.left`，即 `newInterval.left = interval.left`。\n2. `interval.left <= newInterval.right <= interval.right`，則延伸 `newInterval.right`，即 `newInterval.right = interval.right`。\n\n再來，依序將區間加入一個空的集合 `newIntervals` 之中，所有不被新區間的原區間都能加入。要注意加入的區間在新區間的左側還是右側。\n\n筆者的作法為先將新區間加入 `newIntervals` 之中，若原區間在新區間左側，則將 `newInterals` 的最後一個元素（即 `newInterval`）取代成原區間，並再放入一次 `newInterval`。\n\n# 程式碼\n```cpp\n/**\n * Author: justin0u0<mail@justin0u0.com>\n * Problem: https://leetcode.com/problems/insert-interval/\n * Runtime: 52ms\n */\n\nclass Solution {\npublic:\n  vector<vector<int>> insert(vector<vector<int>>& intervals, vector<int>& newInterval) {\n    // 延伸新區間\n    for (auto interval: intervals) {\n      if (interval[0] <= newInterval[0] && newInterval[0] <= interval[1]) newInterval[0] = interval[0];\n      if (interval[0] <= newInterval[1] && newInterval[1] <= interval[1]) newInterval[1] = interval[1];\n    }\n    // 先將新的區間加入\n    vector<vector<int>> newIntervals{newInterval};\n    for (auto interval: intervals) {\n      // 若原區間不被新區間包含，則可以加入\n      if (!(newInterval[0] <= interval[0] && interval[1] <= newInterval[1])) {\n        if (interval[1] < newInterval[0]) {\n          // 在新區間的左側，則交換原區間，新區間的位置\n          newIntervals.back() = interval;\n          newIntervals.emplace_back(newInterval);\n        } else {\n          // 在新區間的右側，直接加入\n          newIntervals.emplace_back(interval);\n        }\n      }\n    }\n    return newIntervals;\n  }\n};\n\n```\n","tags":["LeetCode"],"categories":["LeetCode"]},{"title":"LeetCode 52 - N-Queens II","url":"/LeetCode-N-Queens-II/","content":"\n# 題目\n題目連結：[https://leetcode.com/problems/n-queens-ii/](https://leetcode.com/problems/n-queens-ii/)\n\n求 **N-皇后** 的解的數量。\n\n# 範例說明\n\n```\nInput: 4\nOutput: 2\nExplanation: There are two distinct solutions to the 4-queens puzzle as shown below.\n[\n [\".Q..\",  // Solution 1\n  \"...Q\",\n  \"Q...\",\n  \"..Q.\"],\n\n [\"..Q.\",  // Solution 2\n  \"Q...\",\n  \"...Q\",\n  \".Q..\"]\n]\n```\n\n<!-- More -->\n\n# 想法\n\n與上一題：[LeetCode N-Queens](https://blog.justin0u0.com/LeetCode-N-Queens) 相同，但是不用紀錄解的數量。\n\n# 實作細節\n\n實作細節可以參考 [LeetCode N-Queens](https://blog.justin0u0.com/LeetCode-N-Queens)，本題在 `row` 等於 `n` 時不需要紀錄解的樣子，只需要將一個計數器 `solutions` 加一即可。\n\n# 程式碼\n\n```cpp\n/**\n * Author: justin0u0<mail@justin0u0.com>\n * Problem: https://leetcode.com/problems/n-queens-ii/\n * Runtime: 8ms\n */\n\nclass Solution {\nprivate:\n  int solutions = 0;\n  void solver(vector<int>& col, int n) {\n    // row 為當前要放入的列\n    int row = (int)col.size();\n    // 已經放滿，將 solutions 加一\n    if (row == n) {\n      solutions++;\n      // 遞迴終止並返回\n      return;\n    }\n\n    // 嘗試放入每一行，嘗試將皇后放在 (row, i)\n    for (int i = 0; i < n; i++) {\n      bool ok = true;\n      // 檢查前面放入的皇后有沒有衝突，前面的皇后在 (j, col[j])\n      for (int j = 0; j < row; j++) {\n        // 有衝突，將 ok 設成 false\n        if (col[j] == i || j + col[j] == row + i || j - col[j] == row - i) {\n          ok = false;\n          break;\n        }\n      }\n      // 沒有衝突\n      if (ok) {\n        // 將皇后放在 (row, i)\n        col.emplace_back(i);\n        solver(col, n);\n        // 遞迴結束後將放在第 row 列的皇后拿出來\n        col.pop_back();\n      }\n    }\n  }\npublic:\n  int totalNQueens(int n) {\n    vector<int> col;\n    solver(col, n);\n    return solutions;\n  }\n};\n\n```\n","tags":["LeetCode","回朔法（Backtracking）"],"categories":["LeetCode"]},{"title":"LeetCode 51 - N-Queens","url":"/LeetCode-N-Queens/","content":"\n# 題目\n題目連結：[https://leetcode.com/problems/n-queens/](https://leetcode.com/problems/n-queens/)\n\n求 **N-皇后** 的所有可行解。\n\n# 範例說明\n\n```\nInput: 4\nOutput: [\n [\".Q..\",  // Solution 1\n  \"...Q\",\n  \"Q...\",\n  \"..Q.\"],\n\n [\"..Q.\",  // Solution 2\n  \"Q...\",\n  \"...Q\",\n  \".Q..\"]\n]\nExplanation: There exist two distinct solutions to the 4-queens puzzle as shown above.\n```\n\n<!-- More -->\n\n# 想法\n八皇后的解可以利用回朔法來求出。\n\n根據皇后的攻擊規則，可以知道一行最多只會放入一個皇后。所以回朔法過程為利用遞迴，嘗試在每一個列（Row）中挑一個行（Column）放入皇后，並記錄下來以利下一個 Row 要挑選位置時能檢查此位置是否能放入皇后。\n\n# 實作細節\n\n利用遞迴函數 `solver(col, n)` 來求解。`col` 為一陣列，`col[i]` 紀錄第 `i` 列（Row）的皇后放在哪一個行（Column）。\n\n首先，`col` 陣列的大小，紀錄為 `row`，即為當前要放入的是哪個 Row。只要當 `row` 不等於 `n` 時，可以知道盤面還沒有被放滿。\n\n則利用迴圈遍歷 `i = 0 ~ n - 1`，`i` 代表當前的想要放入的行（Column）。要能在第 `row` 列的第 `i` 行放下皇后，必須檢查這個皇后會不會攻擊到其他前面已經放下的皇后。\n\n遍歷 `j = 0 ~ row - 1`，`(j, col[j])` 代表前面已經放下的皇后的 `(列、行)`。且已知當前嘗試要放入的皇后在 `(row, i)`。所以當：\n\n1. 兩皇后在同一列上：`j == row`\n2. **兩皇后在同一對角線上：`j + col[j] == row + i` 或是 `j - col[j] == row - i`**\n\n代表不能將皇后放在第 `row` 列的第 `i` 行上。\n\n最後，當 `row` 等於 `n` 時，代表皇后已經放滿，所以紀錄當前盤面的解。\n\n# 程式碼\n```cpp\n/**\n * Author: justin0u0<mail@justin0u0.com>\n * Problem: https://leetcode.com/problems/n-queens/\n * Runtime: 16ms\n */\n\nclass Solution {\nprivate:\n  // 紀錄所有可行解用\n  vector<vector<string>> solutions;\n\n  // 遞迴函數 solver\n  void solver(vector<int>& col, int n) {\n    // row 為當前要放入的列\n    int row = (int)col.size();\n\n    // 已經放滿，則紀錄答案到 solutions\n    if (row == n) {\n      vector<string> solution;\n      // i 為列\n      for (int i = 0; i < n; i++) {\n        string s = \"\";\n        // j 為行\n        for (int j = 0; j < n; j++)\n          s += (col[i] == j) ? 'Q' : '.';\n        solution.emplace_back(s);\n      }\n      solutions.emplace_back(solution);\n      // 遞迴終止並返回\n      return;\n    }\n\n    // 嘗試放入每一行，嘗試將皇后放在 (row, i)\n    for (int i = 0; i < n; i++) {\n      bool ok = true;\n      // 檢查前面放入的皇后有沒有衝突，前面的皇后在 (j, col[j])\n      for (int j = 0; j < row; j++) {\n        // 有衝突，將 ok 設成 false\n        if (col[j] == i || j + col[j] == row + i || j - col[j] == row - i) {\n          ok = false;\n          break;\n        }\n      }\n      // 沒有衝突\n      if (ok) {\n        // 將皇后放在 (row, i)\n        col.emplace_back(i);\n        solver(col, n);\n        // 遞迴結束後將放在第 row 列的皇后拿出來\n        col.pop_back();\n      }\n    }\n  }\npublic:\n  vector<vector<string>> solveNQueens(int n) {\n    vector<int> col;\n    solver(col, n);\n    return solutions;\n  }\n};\n\n```","tags":["LeetCode","回朔法（Backtracking）"],"categories":["LeetCode"]},{"title":"LeetCode 45 - Jump Game II","url":"/LeetCode-Jump-Game-II/","content":"\n# 題目\n題目連結：[https://leetcode.com/problems/jump-game-ii/submissions/](https://leetcode.com/problems/jump-game-ii/submissions/)\n\n給一非負的整數序列，一開始在序列的第一格上。序列的值代表在此位置時最多可以跳多少距離，求最少幾步可以到達序列的最後一格。\n\n# 範例說明\n\n```\nInput: [2,3,1,1,4]\nOutput: 2\nExplanation: The minimum number of jumps to reach the last index is 2.\n    Jump 1 step from index 0 to 1, then 3 steps to the last index.\n```\n\n<!-- More -->\n\n# 想法\n假設序列的第 i 個元素為 Ai，且序列從 0 開始編號。\n\n在第 0 步的時候，假設 `R0 = 0`，則可以到達的範圍在 `0 ~ R0`。\n\n第 1 步時，一步能到達的範圍在 `0 ~ R1`，其中 `R1 = A0`。但是從 `0 ~ R0` 的這個區間出發，必定只能到達 `0 ~ R1`，所以要算出第 2 步能到達的範圍時，可以排除從 `0 ~ R0` 出發的可能性。因此第 2 步可以到達的範圍應該是由 `[R0 + 1, R1]` 出發：\n\n$$\\bigcup\\ [i,\\ i+A_i],\\quad\\forall\\ i\\in [R0+1, R1]$$\n\n假設聯集後的範圍在 `[L2, R2]`，代表 `[0 ~ R2]` 都可以在 2 步內到達。但是從 `0 ~ R1` 這個區間出發，必定只能到達 `0 ~ R2`，所以要算出第 3 步能到達的範圍時，可以排除從第 `0 ~ R1` 格出發的可能性，因此第 3 步可以到達的範圍應該是由 `[R1 + 1, R2]` 出發：\n\n$$\\bigcup\\ [j,\\ j+A_j],\\quad\\forall\\ j\\in [R1+1, R2]$$\n\n以此類推，可以發現要算第 `i` 步能到達的區間，只需要由 `i - 1` 步能多走到的區間出發計算就好。\n\n假設 `N` 為序列長度，因為每一個區間都不重複，所以總時間複雜度為 `O(N)`。\n\n# 實作細節\n\n紀錄 `[iL, iR]` 區間，代表要從這個區間出發找下一步可以到哪個範圍。`steps` 為當前的步數。\n\n初始時，`steps = 0`，且 `[iL, iR] = [0, 0]`。\n\n每一次都從 `[iL, iR]` 區間出發，尋找下一個 `iR`，紀錄為 `next_iR`：\n$$next\\_iR=max(i + Ai),\\quad\\forall\\ i\\in [iL, iR]$$\n而下一個 `iL` 則為 `iR + 1`。\n\n# 程式碼\n```cpp\n/**\n * Author: justin0u0<mail@justin0u0.com>\n * Problem: https://leetcode.com/problems/jump-game-ii/\n * Runtime: 20ms\n */\n\nclass Solution {\npublic:\n  int jump(vector<int>& nums) {\n    int n = (int)nums.size();\n    int steps = 0;\n    int iL = 0, iR = 0;\n    // iR >= n - 1，代表已經可以走到最後一格\n    while (iR < n - 1) {\n      int next_iR = 0;\n      // 從 [iL, iR] 出發找下一步的範圍\n      for (int i = iL; i <= iR; i++)\n        next_iR = max(next_iR, i + nums[i]);\n      // 下一個 iL\n      iL = iR + 1;\n      // 下一個 iR\n      iR = next_iR;\n      // 每一次都把 steps + 1\n      steps++;\n    }\n    return steps;\n  }\n};\n\n```\n","tags":["LeetCode","Greedy（貪心）"],"categories":["LeetCode"]},{"title":"LeetCode 44 - Wildcard Matching","url":"/LeetCode-Wildcard-Matching/","content":"\n# 題目\n題目連結：[https://leetcode.com/problems/wildcard-matching/](https://leetcode.com/problems/wildcard-matching/)\n\n給一個字串 `s` 和樣板（pattern） `p`，實作支援 `'?'` 和 `'*'` 的 wildcard pattern matching。\n\n```\n'?' Matches any single character.\n'*' Matches any sequence of characters (including the empty sequence).\n```\n\n計算 `s` 是否匹配 `p`。\n\n# 範例說明\n\n## Example 1:\n```\nInput:\ns = \"aa\"\np = \"a\"\nOutput: false\nExplanation: \"a\" does not match the entire string \"aa\".\n```\n\n## Example 2:\n```\nInput:\ns = \"aa\"\np = \"*\"\nOutput: true\nExplanation: '*' matches any sequence.\n```\n\n## Example 3:\n```\nInput:\ns = \"cb\"\np = \"?a\"\nOutput: false\nExplanation: '?' matches 'c', but the second letter is 'a', which does not match 'b'.\n```\n\n## Example 4:\n```\nInput:\ns = \"adceb\"\np = \"*a*b\"\nOutput: true\nExplanation: The first '*' matches the empty sequence, while the second '*' matches the substring \"dce\".\n```\n\n## Example 5:\n```\nInput:\ns = \"acdcb\"\np = \"a*c?b\"\nOutput: false\n```\n\n<!-- More -->\n\n# 想法\n\n此題與 [LeetCode 10 - Regular Expression Matching](https://blog.justin0u0.com/LeetCode-Regular-Expression-Matching) 題目類似，實作起來也比較簡單。\n\n有關動態規劃的詳細說明可以參考上述題目網址。這裡只做簡單的說明。\n\n## DP 狀態\n假設兩字串分別為 `s` 以及 `p`，而且從索引 1 開始編號。\n所以我們可以定義 DP 狀態為： `d(i, j) = s[1 ~ i], p[1 ~ j] 是否匹配`。\n\n## DP 轉移\n\n1. 若 `p[j] = '*'`：\n   1. 若 `'*'` 重複了 0 次，則 `d(i, j) = 1` 若且唯若 `d(i - 1, j) = 1`，也就是 `s[1 ~ i - 1]` 匹配到 `p[1 ~ j]`。\n   2. 若 `'*'` 重複了一次以上，因為 `'*'` 能代表任何字元，所以 `d(i, j) = 1` 若且唯若 `d(i, j - 1) = 1`，也就是 `s[1 ~ i]` 匹配到 `p[1 ~ j - 1]`。\n2. 若 `p[j]` 為一般字母，則 `d(i, j) = 1` 若且唯若 `d(i - 1, j - 1) = 1` 且 `s[i] = p[j]`。也就是如果 `s[1 ~ i - 1]` 匹配到 `p[1 ~ j - 1]` 且 `s[i] = p[j]`。\n3. 若 `p[j] = '?'`，則與第二點類似。因為 `'?'` 能匹配到任何字元，所以 `s[i] = p[j]` 的條件永遠成立。\n  \n## DP 總整理\n綜合上述 3 點，得到：\n  $$d(i,\\ j)=d(i-1,\\ j)\\ |\\ d(i,\\ j-1)\\quad if\\ p[j]=*$$\n  $$d(i,\\ j)=d(i-1,\\ j-1)\\quad if\\ s[i]=p[j]\\ or\\ p[j]=?$$\n\n最後考慮邊界情況：\n1. 初始化 DP 陣列為 `false`\n2. `d(0, 0) = 1`：`s` 與 `p` 為空應該算是匹配。\n3. `d(i, 0) = 0, i > 0`：`p` 為空，但 `s` 不為空，不匹配。\n4. `d(0, i)`：與 DP 轉移式相同，但只能從 `d(0, i - 1)` 轉移（因為無 `d(-1, i)`）。\n\n最終答案為 `dp[|s|][|p|]`。\n\n# 實作細節\n真實清況中， `s` 與 `p` 皆為 Base 0（索引從 0 開始），因此所有的轉移都由 `d(i, j)` 轉為 `d(i + 1, j + 1)`。\n\n# 程式碼\n```cpp\n/**\n * Author: justin0u0<mail@justin0u0.com>\n * Problem: https://leetcode.com/problems/wildcard-matching/\n * Runtime: 356ms\n */\n\nclass Solution {\npublic:\n  bool isMatch(string s, string p) {\n    int sl = (int)s.length();\n    int pl = (int)p.length();\n    vector<vector<bool>> dp(sl + 1, vector<bool>(pl + 1));\n\n    // 初始化陣列\n    dp[0][0] = true;\n    for (int i = 0; i < pl; i++) {\n      if (p[i] == '*') dp[0][i + 1] = dp[0][i];\n    }\n\n    for (int i = 0; i < sl; i++) {\n      for (int j = 0; j < pl; j++) {\n        if (p[j] == '*') {\n          \b// 轉移 1\n          dp[i + 1][j + 1] = (dp[i][j + 1] || dp[i + 1][j]);\n        } else if (p[j] == '?' || s[i] == p[j]) {\n          // 轉移 2\n          dp[i + 1][j + 1] = dp[i][j];\n        }\n      }\n    }\n    return dp[sl][pl];\n  }\n};\n\n```","tags":["LeetCode","動態規劃（Dynamic Programming, DP）"],"categories":["LeetCode"]},{"title":"LeetCode 42 - Trapping Rain Water","url":"/LeetCode-Trapping-Rain-Water/","content":"\n# 題目\n題目連結：[https://leetcode.com/problems/trapping-rain-water/](https://leetcode.com/problems/trapping-rain-water/)\n\n給定一個長度為 `N` 個序列，代表海拔高度，每個條的寬度都是 1，求下雨時會有多少格水。\n\n# 範例說明\n\n```\nExample:\n\nInput: [0,1,0,2,1,0,1,3,2,1,2,1]\nOutput: 6\n```\n\n![](/assets/LeetCode-Trapping-Rain-Water/trapping-rain-water-sample.png)\n\n上圖顯示輸入為 `[0,1,0,2,1,0,1,3,2,1,2,1]` 後 6 格水（藍色）所在的位置。\n\n<!-- More -->\n\n# 想法\n\n把每一個位置的最高水面高度分開計算，在某個位置 `i` 的水面高度為以此條往左的最大高度和往右的最大高度之最小值，也就是：\n$$min(max(height[x]), max(height[y])),\\quad\\ \\forall x\\lt i,\\ y\\gt i$$\n\n每個位置的最高水面高度再減去此位置原本的高度就是能累積的水量。\n\n# 實作細節\n\n先紀錄 `left[i]` 代表位置 `i` 的左邊出現過的最大高度。以及 `right[i]` 代表位置 `i` 的右邊出現過的最大高度。先將 `height` 陣列複製到 `left`, `right`。\n\n所以 `left` 應該要由左到右計算 `left[i] = max(left[i], left[i - 1])`。\n\n而 `right` 應該要由右到左計算 `right[i] = max(right[i], right[i + 1])`。\n\n計算後，位置 `i` 的水面最大高度為 `min(left[i], right[i])`。水量為 `min(left[i], right[i]) - height[i]`。\n\n# 程式碼\n\n```cpp\n/**\n * Author: justin0u0<mail@justin0u0.com>\n * Problem: https://leetcode.com/problems/trapping-rain-water/\n * Runtime: 12ms\n */\n\nclass Solution {\npublic:\n  int trap(vector<int>& height) {\n    int n = (int)height.size();\n    vector<int> left(height);\n    vector<int> right(height);\n\n    for (int i = 1; i < n; i++) {\n      int j = n - i - 1;\n      left[i] = max(left[i], left[i - 1]);\n      right[j] = max(right[j], right[j + 1]);\n    }\n\n    int sum = 0;\n    for (int i = 0; i < n; i++) sum += min(left[i], right[i]) - height[i];\n    return sum;\n  }\n};\n\n```","tags":["LeetCode"],"categories":["LeetCode"]},{"title":"LeetCode 41 - First Missing Positive","url":"/LeetCode-First-Missing-Positive/","content":"\n# 題目\n題目連結：[https://leetcode.com/problems/first-missing-positive/](https://leetcode.com/problems/first-missing-positive/)\n\n給一數字序列，找出序列中最小沒有出現的正整數。\n\n要求時間複雜度 `O(N)`，空間複雜度 `O(1)`。\n\n# 範例說明\n\n## Example 1\n```\nInput: [1,2,0]\nOutput: 3\n```\n\n## Example 2:\n```\nInput: [3,4,-1,1]\nOutput: 2\n```\n\n## Example 3:\n```\nInput: [7,8,9,11,12]\nOutput: 1\n```\n\n<!-- More -->\n\n# 想法\n\n假設序列名為 `a`，長為 `N`，索引從開始，則答案一定在 `1 ~ N + 1` 之間。\n\n若序列有出現 `x`，且 `x` 在 `1 ~ N` 之間，且將 `a[x - 1]` 設置為 `x` 來代表數字 `x` 有出現過。則由左至右第一個 `a[i - 1] != i` 的 `i` 就是我們要找的答案。\n\n在將 `a[x - 1]` 設置為 `x` 時，`a[x - 1]` 可能還存放著其他數字，但這時候存放 `x` 的位置就空下來了，所以可以想成是將兩個數字交換。\n\n數字交換後，`a[x - 1]` 被放置到當前的位置，所以 `a[x - 1]` 所存之數字要立即被處理，否則將繼續向下遍歷就不會再經過這個數字了。\n\n# 程式碼\n```cpp\n/**\n * Author: justin0u0<mail@justin0u0.com>\n * Problem: https://leetcode.com/problems/first-missing-positive/\n * Runtime: 4ms\n */\n\nclass Solution {\npublic:\n  int firstMissingPositive(vector<int>& nums) {\n    int n = (int)nums.size();\n    for (int i = 0; i < n; i++) {\n      while (nums[i] > 0 && nums[i] <= n && nums[nums[i] - 1] != nums[i])\n        swap(nums[nums[i] - 1], nums[i]);\n    }\n    for (int i = 0; i < n; i++)\n      if (nums[i] != i + 1)\n        return i + 1;\n    return n + 1;\n  }\n};\n\n```\n","tags":["LeetCode"],"categories":["LeetCode"]},{"title":"LeetCode 37 - Sudoku Solver","url":"/LeetCode-Sudoku-Solver/","content":"\n# 題目\n題目連結：[https://leetcode.com/problems/sudoku-solver/](https://leetcode.com/problems/sudoku-solver/)\n\n給一個數獨，保證存在唯一一組解，求出數獨。\n\n# 範例說明\n\n**A sudoku puzzle:**\n![](/assets/LeetCode-Sudoku-Solver/sudoku-solver-start.png)\n**The sudoku puzzle solution:**\n![](/assets/LeetCode-Sudoku-Solver/sudoku-solver-end.png)\n\n<!-- More -->\n\n# 想法\n\n解數獨最簡單的方法為回朔法。所謂回朔法其實就是利用遞迴暴力嘗試，對於每一個數獨的空格，都暴力嘗試填入 `1 ~ 9`。若發現填不下去了，則返回到上一步嘗試填入下一種數字。\n\n當然，若要解的數獨比九乘九大小更大，可以將數獨轉換為**精準覆蓋問題**，再利用**舞蹈鏈**求解。（待補）\n\n# 實作細節\n\n實作上，遞迴函數 `solver` 攜帶 `x`, `y` 代表當前位置。如果當前位置為數字則跳過，否則嘗試填入 `1 ~ 9`。\n\n填入數字 `i` 時檢查此位置是否能夠填入，所以只要檢查：\n1. 第 `x` 列（row）是否有 `i`。\n2. 第 `y` 行（column）是否有 `i`。\n3. `(x, y)` 所在的方格（block）內是否有填入 `i`。\n   若我們將方格編號，由左到右、由上到下為 `0 ~ 9` 號，則 `(x, y)` 所在的方格編號為 `x / 3 * 3 + y / 3`。\n\n檢查數字可以使用迴圈檢查，或是額外紀錄布林值陣列 `row[i][j]`, `col[i][j]`, `block[i][j]` 分別代表第 `i` 個列、行、方格有沒有數字 `j`。\n當然，要額外紀錄陣列就必須在初始化時先遍歷整個數獨，但是在檢查時可以 `O(1)` 知道數字能否填入。\n不額外紀錄陣列雖然程式碼較簡潔，但速度稍慢一些。\n\n在 `(x, y)` 填入數字 `i` 後，向下一格遞迴。**不要忘記在遞迴返回後恢復原本的盤面**（在呼叫函數後的下一行）。\n若有額外紀錄 `row`, `col`, `block` 陣列，填入數字時要將 `row[x][i]`, `col[y][i]`, `block[x / 3 * 3 + y / 3][i]` 改為 `true`，遞迴返回後，這些值也要恢復成 `false`。\n\n最後，遞迴的終止條件為 `x = 9`，代表所有格子已經填完。\n\n另外要注意 `board` 內存的為 `char`，轉為對應數字時應該要剪去字元的 ASCII 編碼。\n\n# 程式碼\n\n## 不額外紀錄 row, col, block\n```cpp\n/**\n * Author: justin0u0<mail@justin0u0>\n * Problem: https://leetcode.com/problems/sudoku-solver/\n * Runtime: 28ms\n */\n\nclass Solution {\nprivate:\n  bool solver(int x, int y, vector<vector<char>>& board) {\n    // 遞迴邊界，找到解\n    if (x == 9) return true;\n\n    int nextX = y == 8 ? x + 1 : x;\n    int nextY = y == 8 ? 0 : y + 1;\n    if (board[x][y] == '.') {\n      // 嘗試填入 1 ~ 9\n      for (int i = 1; i <= 9; i++) {\n        bool valid = true;\n        char cell = i + '0';\n        // 檢查是否可以在 (x, y) 填入數字 i\n        for (int j = 0; j < 9; j++) {\n          int blockX = (x / 3) * 3 + (j / 3);\n          int blockY = (y / 3) * 3 + (j % 3);\n          if (board[x][j] == cell || board[j][y] == cell || board[blockX][blockY] == cell) {\n            valid = false;\n            break;\n          }\n        }\n        if (!valid) continue;\n        // 可以填入\n        board[x][y] = cell;\n        if (solver(nextX, nextY, board)) return true;\n        // 恢復盤面\n        board[x][y] = '.';\n      }\n    } else {\n      // 原本就有數字，跳過 (x, y)\n      return solver(nextX, nextY, board);\n    }\n    return false;\n  }\npublic:\n  void solveSudoku(vector<vector<char>>& board) {\n    solver(0, 0, board);\n  }\n};\n\n```\n\n## 額外紀錄 row, col, block 三個布林值陣列\n```cpp\n/**\n * Author: justin0u0<mail@justin0u0>\n * Problem: https://leetcode.com/problems/sudoku-solver/\n * Runtime: 8ms\n */\n\nclass Solution {\nprivate:\n  // 額外紀錄布林陣列 col, row, block\n  bool row[9][9], col[9][9], block[9][9];\n  // 將額外紀錄的布林陣列值反轉\n  inline void toggleState(int x, int y, int i) {\n    row[x][i] ^= true;\n    col[y][i] ^= true;\n    block[x / 3 * 3 + y / 3][i] ^= true;\n  }\n  bool solver(int x, int y, vector<vector<char>>& board) {\n    // 遞迴邊界，找到解\n    if (x == 9) return true;\n\n    int nextX = y == 8 ? x + 1 : x;\n    int nextY = y == 8 ? 0 : y + 1;\n    if (board[x][y] == '.') {\n      // 嘗試填入 1 ~ 9\n      for (int i = 0; i < 9; i++) {\n        if (!row[x][i] && !col[y][i] && !block[x / 3 * 3 + y / 3][i]) {\n          // 可以在 (x, y) 填入數字 i\n          board[x][y] = i + '1';\n          // 將 row, col, block 設成 1\n          toggleState(x, y, i);\n          if (solver(nextX, nextY, board)) return true;\n          // 將 row, col, block 設成 0\n          toggleState(x, y, i);\n          // 恢復盤面\n          board[x][y] = '.';\n        }\n      }\n    } else {\n      // 原本就有數字，跳過 (x, y)\n      return solver(nextX, nextY, board);\n    }\n    return false;\n  }\npublic:\n  void solveSudoku(vector<vector<char>>& board) {\n    // 初始化 row, col, block\n    memset(row, false, sizeof row);\n    memset(col, false, sizeof col);\n    memset(block, false, sizeof block);\n    for (int i = 0; i < 9; i++) {\n      for (int j = 0; j < 9; j++) {\n        if (board[i][j] != '.') {\n          int cell = board[i][j] - '1';\n          row[i][cell] = true;\n          col[j][cell] = true;\n          block[i / 3 * 3 + j / 3][cell] = true;\n        }\n      }\n    }\n    solver(0, 0, board);\n  }\n};\n\n```\n","tags":["LeetCode","回朔法（Backtracking）"],"categories":["LeetCode"]},{"title":"LeetCode 32 - Longest Valid Parentheses","url":"/LeetCode-Longest-Valid-Parentheses/","content":"\n# 題目\n題目連結：[https://leetcode.com/problems/longest-valid-parentheses/](https://leetcode.com/problems/longest-valid-parentheses/)\n\n給定一個只包含 `'('` 和 `')'` 的字串 `s`，找到最長的合法括號子字串。\n\n# 範例說明\n\n## Example 1:\n\n```\nInput: \"(()\"\nOutput: 2\nExplanation: The longest valid parentheses substring is \"()\"\n```\n\n## Example 2:\n\n```\nInput: \")()())\"\nOutput: 4\nExplanation: The longest valid parentheses substring is \"()()\"\n```\n\n<!-- More -->\n\n# 想法\n\n首先，要判斷一個字串是否為合法的括號字串。一個合法的括號，若且唯若，字串左括號的數量一定要等於右括號的數量，且由左至右數任一個時刻，左括號的數量都應該大於等於右括號出現的數量。\n\n要判斷字串是否有上述的性質，可以使用一個 `stack`，`stack` 為先進後出（First-in-last-out, FILO）之資料結構。給定之字串由左至右，每次遇到左括號，就將左括號放入 `stack` 之中；反之，遇到右括號時，將 `stack` 之頂端元素拿出。`stack` 之頂端左括號即為當前右括號之匹配。若 `stack` 為空，代表右括號出現的數量比左括號還多，此字串為不合法的字串。若遍歷完字串後 `stack` 內還有剩餘元素，代表左括號數量大於右括號，所以此字串也非合法字串。\n\n有了上述概念，此題目要求最長合法括號子字串。額外紀錄當前合法區間的左邊界 `left`，一開始為 `left = -1` 代表目前整個字串都是合法的。字串左至右，如果遇到左括號，則加入 `stack` 之中。當遇到右括號時：\n1. `stack` 為空，代表此右括號沒有任何任何左括號可以匹配，更新 `left` 等於此右括號的索引。\n2. `stack` 不為空：將右括號所匹配的左括號從 `stack` 移除。\n   1. 如果 `stack` 內還有元素，則右括號到 `stack` 的頂端左括號之間都是合法括號子字串。\n   2. 如果 `stack` 為空，則右括號到上述紀錄的合法區間左邊界都是合法括號子字串。\n\n每一個字元都只遍歷一次，若字串長度為 `N`，總時間複雜度為 `O(N)`。\n# 實作細節\n\n實作上為了方便，筆者將 `left` 推入 `stack` 之中，如此一來，當遇到右括號時：\n1. `stack` 頂端元素**等於** `left`，代表此右括號沒有任何任何左括號可以匹配，更新 `left` 等於右括號的索引，**並將此合法邊界推入 `stack` 之中**。\n2. `stack` 頂端元素**不等於** `left`：將右括號所匹配的左括號從 `stack` 移除，右括號到 `stack` 的頂端元素之間都是合法括號子字串。\n\n# 程式碼\n\n```cpp\n/**\n * Author: justin0u0<mail@justin0u0.com>\n * Problem: https://leetcode.com/problems/longest-valid-parentheses/\n * Runtime: 8ms\n */\n\nclass Solution {\npublic:\n  int longestValidParentheses(string s) {\n    stack<int> box;\n    // 將 left 推入 stack 之中\n    box.push(-1);\n    int left = -1;\n    // 紀錄答案用\n    int ans = 0;\n    for (int i = 0; i < (int)s.length(); i++) {\n      if (s[i] == '(') {\n        // 左括號，推入 stack 之中\n        box.push(i);\n      } else {\n        if (box.top() != left) {\n          box.pop();\n          // 右括號到 stack 之頂端元素都為合法括號子字串\n          ans = max(ans, i - box.top());\n        } else {\n          // 右括號沒有任何左括號能匹配，更新 left 並推入 stack 之中\n          box.push(i);\n          left = i;\n        }\n      }\n    }\n    return ans;\n  }\n};\n\n```\n","tags":["LeetCode","堆疊（Stack）"],"categories":["LeetCode"]},{"title":"LeetCode 30 - Substring with Concatenation of All Words","url":"/LeetCode-Substring-with-Concatenation-of-All-Words/","content":"\n# 題目\n題目連結：[https://leetcode.com/problems/substring-with-concatenation-of-all-words/](https://leetcode.com/problems/substring-with-concatenation-of-all-words/)\n\n給定一個字串 `s` 和一個 `words` 陣列，`words` 內包含長度一樣的單詞。\n找到所有的子字串的開頭索引值，子字串必須是 `words` 中的每一個單詞各出現一次的連接字串。\n\n# 範例說明\n## Example 1\n```\nInput:\n  s = \"barfoothefoobarman\",\n  words = [\"foo\",\"bar\"]\nOutput: [0,9]\nExplanation: Substrings starting at index 0 and 9 are \"barfoo\" and \"foobar\" respectively.\nThe output order does not matter, returning [9,0] is fine too.\n```\n\n## Example 2\n```\nInput:\n  s = \"wordgoodgoodgoodbestword\",\n  words = [\"word\",\"good\",\"best\",\"word\"]\nOutput: []\n```\n\n<!-- More -->\n\n# 想法\n假設 `wl` 為每一個單詞的長度。\n\n要找的子字串必須相連，所以將字串 `s` 分為 `wl` 個集合，分別為：\n\n- `0`, `0 + wl`, `0 + 2 * wl`, `0 + 3 * wl` ...\n- `1`, `1 + wl`, `1 + 2 * wl`, `1 + 3 * wl` ...\n- ...\n- `(wl - 1)`, `(wl - 1) + wl`, `(wl - 1) + 2 * wl`, `(wl - 1) + 3 * wl` ...\n\n例如 `Example 1` 中的 `s = \"barfoothefoobarman\"`, `words = [\"foo\", \"bar\"]`， 則可以分為 `{ \"bar\", \"foo\", \"the\", \"foo\", \"bar\", \"man\" }`, `{ \"arf\", \"oot\", \"hef\", \"oob\", \"arm\" }`, `{ \"rfo\", \"oth\", \"efo\", \"oba\", \"rma\" }` 三個集合。\n\n答案必定為同一個集合內的連續一段子字串。\n\n在一個集合之中，利用 **Sliding Window** 找尋答案。所謂 **Sliding Window** 是指利用兩個指標標示目前的範圍，或是稱作「窗口」。原本窗口內為空集合，從第一個字串開始，將字串加入窗口（窗口的右側增加，窗口變大），如果當前的字串加入後，窗口內的字串們無法形成答案，就逐次將窗口左側向右（窗口變小），直到窗口內的字串們可以形成答案，或是窗口為空。\n\n要判斷窗口內的答案可否形成答案，也就是要判斷窗口內的子字串們是不是 `words` 的子集合。再者，若窗口內的子字串們恰好等於 `words` 的單詞集合，那窗口最左側的字串之索引值就是一個合法答案。\n\n一樣以 `Example 1` 為例子，一開始窗口為 `[]`。\n1. `\"bar\"` -> 將 `\"bar\"` 加入窗口，窗口為 `[\"bar\"]`，是 `words` 的子集合。\n2. `\"foo\"` -> 將 `\"foo\"` 加入窗口，窗口為 `[\"bar\", \"foo\"]`，恰好等於 `words`，所以窗口左側 `\"bar\"` 的索引為一組答案。\n3. `\"the\"` -> 將 `\"the\"` 加入窗口，窗口為 `[\"bar\", \"foo\", \"the\"]`，不為 `words` 的子集合，依次將左側窗口向右直到窗口為 `words` 之子集合或是窗口為空，`[\"bar\", \"foo\", \"the\"] -> [\"foo\", \"the\"]-> [\"the\"] -> []`。\n4. `\"foo\"` -> 將 `\"foo\"` 加入窗口，窗口為 `[\"foo\"]`，是 `words` 的子集合。\n5. `\"bar\"` -> 將 `\"bar\"` 加入窗口，窗口為 `[\"foo\", \"bar\"]`，恰好等於 `words`，所以窗口左側 `\"foo\"` 的索引為一組答案。\n3. `\"man\"` -> 將 `\"man\"` 加入窗口，窗口為 `[\"foo\", \"bar\", \"man\"]`，不為 `words` 的子集合，依次將左側窗口向右直到窗口為 `words` 之子集合或是窗口為空，`[\"foo\", \"bar\", \"man\"] -> [\"bar\", \"man\"]-> [\"man\"] -> []`。\n\n# 實作細節\n\n為了維護窗口內的子集合，可以使用 **`C++ STL unordered_multiset`**，`unordered_multiset` 為使用 `Hashmap` 實作的集合，可以 `O(1)` 加入、刪除、查找一個值。與 `unordered_set` 不同的是，`unordered_set` 視相同的值為集合內的同一個元素，但 `unordered_multiset` 視同一個值為集合內的不同元素。恰好符合 `words` 內可能有相同單詞的性質。\n\n假設 `dict` 為一 `unordered_multiset`，初始為空。\n\n實作上，先將 `words` 內的單詞都先加入 `dict` 之中，當新的子字串要加入窗口，就必須在 `dict` 中找到此子字串才代表此子字串加入後窗口會是 `words` 的子集合。子字串加入後，從 `dict` 中刪除此子字串，若 `dict` 為空，說明當前窗口恰好等於 `words`，左側窗口索引值紀錄。當左側窗口向右移動時，則把離開窗口的子字串加回 `dict` 之中。\n\n完成後不忘把窗口內的元素都加回 `dict` 之中，讓 `dict` 恢復成原本的樣子，以方便下一組的集合使用。\n\n假設 `N = 字串 s 長度`，每一個子字串只會被加入 Sliding Window 一次，只會從 Sliding Window 中被移除一次，加入、刪除的時間複雜度均是 `O(1)`。所以總時間複雜度為 `O(2N) = O(N)`。\n\n不過 C++ 的 `String.substr` 時間複雜度為 `O(String Length)`，所以總時間複雜度應該為 `O(wl * N)`。\n\n# 程式碼\n\n```cpp\n/**\n * Author: justin0u0<mail@justin0u0.com>\n * Problem: https://leetcode.com/problems/substring-with-concatenation-of-all-words/\n * Runtime: 52ms\n */\n\nclass Solution {\npublic:\n  vector<int> findSubstring(string s, vector<string>& words) {\n    // 紀錄答案的索引值用\n    vector<int> indices;\n    // 排除一定無解的狀況\n    int sl = (int)s.length();\n    if (!sl || words.empty()) return indices;\n    int wl = (int)words[0].length();\n    if (sl < wl * (int)words.size() || !wl) return indices;\n\n    // 先將 words 中的單詞加入 dict\n    unordered_multiset<string> dict;\n    for (auto word: words) dict.insert(word);\n\n    // 共 wl 個集合，分別檢驗\n    for (int i = 0; i < wl; i++) {\n      // 窗口左側索引值\n      int left = i;\n      // 逐次將窗口右側向右\n      for (int j = i; j + wl <= sl; j += wl) {\n        string substring = s.substr(j, wl);\n        // 若當前子字串加入後窗口不為 words 之子集合，則逐次將窗口左側向右，直到可以加入或窗口為空\n        while (left < j && dict.find(substring) == dict.end()) {\n          dict.insert(s.substr(left, wl));\n          left += wl;\n        }\n        auto it = dict.find(substring);\n        if (it != dict.end()) {\n          // 將當前子字串加入窗口\n          dict.erase(it);\n          // 若 dict 為空，窗口左側索引為一組合法答案\n          if (dict.empty()) indices.emplace_back(left);\n        } else {\n          // 當前子字串無法加入窗口\n          left = j + wl;\n        }\n      }\n      // 將窗口內元素加回 dict 之中，復原 dict 讓下一個集合使用\n      while (left + wl <= sl) {\n        dict.insert(s.substr(left, wl));\n        left += wl;\n      }\n    }\n    return indices;\n  }\n};\n\n```\n","tags":["LeetCode","滑動窗口（Sliding Window）","雜湊（Hash table）"],"categories":["LeetCode"]},{"title":"LeetCode 25 - Reverse Nodes in k Group","url":"/LeetCode-Reverse-Nodes-in-k-Group/","content":"\n# 題目\n題目連結：[https://leetcode.com/problems/reverse-nodes-in-k-group/](https://leetcode.com/problems/reverse-nodes-in-k-group/)\n\n給定一個 Linked List（以下簡稱串列），以每 `k` 個節點為一段做反轉。\n\n保證 `k > 0` 且 `k <= 串列長度`，如果剩下的一段長度不足 `k` 則不需要反轉。\n\n# 範例說明\nGiven this linked list: `1->2->3->4->5`\n\nFor `k = 2`, you should return: `2->1->4->3->5`\n\nFor `k = 3`, you should return: `3->2->1->4->5`\n\n<!-- More -->\n\n# 想法\n\n把題目拆成兩個遞迴式來想。\n\n首先，如果只要將串列 `head` 的前 `k` 個節點做反轉，\n\n例如：`k = 3`： `1->2->3->...` -> `3->2->1->...`\n\n可以發現除了第一個節點外，每一個節點都要連向上一個節點。所以遞迴函數中，紀錄 `當前節點 head`, `上一個節點 lastNode`，`剩餘數量 k`，如下：\n\n`reverseSingleGroup(head, lastNode, k)`\n\n每次都將 `head->next` 連向 `lastNode`，並且遞迴向下 `reverseSingleGroup(head->next, head, k - 1)`，要注意在修改 `head->next` 之前要先把 `head->next` 記錄下來。\n\n當做到 `k = 1` 時，代表當前 `head` 等於反轉串列後的新的 `head`，所以我們一路將 `head` 返回。\n\n再來，每 `k` 個節點為一段做反轉，我們定義遞迴函數 `reverseKGroup(head, k)`，\n\n可以發現 `reverseKGroup(head, k) = reverseSingleGroup(head, reverseKGroup({ the k + 1 Node }, k), k)`，\n\n也就是 `reverseKGroup(head, k)` 等於將前 `k` 個節點反轉（`reverseSingleGroup(head, ..., k)`），且從第 `k + 1` 個節點繼續做每 `k` 個節點為一點反轉，（`reverseKGroup({ the k + 1 Node}, k)`）。\n\n還有一點要注意，在 `reverseSingleGroup(head, lastNode, k)` 中有提到，每次都應該要將 `head->next = lastNode`，但第一次呼叫的 `lastNode` 上面並沒有特別說明。因為第一次呼叫的 `lastNode` 應該要等於 `reverseKGroup({ the k + 1 Node }, k)` 所返回的新的 `head`。例如：\n\n`1->2->3->4->5->6`, `k = 3`，呼叫 `reverseSingleGroup(1, reverseKGroup(4, 3), 3)`，且 `reverseKGroup(4, 3) = reverseSingleGroup(4, nullptr, 3) = 6->5->4`，所以：`reverseSingleGroup(1, 6->5->4, 3)`，所以節點 `1` 應該要連向節點 `6`。即：`3->2->1->6->5->4`。\n\n最後，若 `reverseKGroup` 時長度已經不足 `k`，則直接返回串列。\n\n# 程式碼\n\n```cpp\n/**\n * Author: justin0u0<mail@justin0u0.com>\n * Problem: https://leetcode.com/problems/reverse-nodes-in-k-group/\n * Runtime: 16ms\n */\n\n/**\n * Definition for singly-linked list.\n * struct ListNode {\n *     int val;\n *     ListNode *next;\n *     ListNode() : val(0), next(nullptr) {}\n *     ListNode(int x) : val(x), next(nullptr) {}\n *     ListNode(int x, ListNode *next) : val(x), next(next) {}\n * };\n */\nclass Solution {\nprivate:\n  ListNode* reverseSingleGroup(ListNode* head, ListNode* lastNode, int k) {\n    // 先將下一個節點紀錄\n    ListNode* nextNode = head->next;\n    // 將當前節點連向上一個節點\n    head->next = lastNode;\n    // 遞迴終點：返回新的 head\n    if (k == 1) return head;\n    // 向下遞迴\n    return reverseSingleGroup(nextNode, head, k - 1);\n  }\npublic:\n  ListNode* reverseKGroup(ListNode* head, int k) {\n    // 找尋第 k 個節點\n    ListNode* node = head;\n    for (int i = 1; i < k && node != nullptr; i++)\n      node = node->next;\n    // 若第 k 個節點為 nullptr，則代表長度不足，直接返回串列\n    if (node == nullptr)\n      return head;\n    // 向下遞迴\n    return reverseSingleGroup(head, reverseKGroup(node->next, k), k);\n  }\n};\n\n```\n","tags":["LeetCode","鏈結串列（Linked List）"],"categories":["LeetCode"]},{"title":"LeetCode 23 - Merge k Sorted Lists","url":"/LeetCode-Merge-k-Sorted-Lists/","content":"\n# 題目\n題目連結：[https://leetcode.com/problems/merge-k-sorted-lists/](https://leetcode.com/problems/merge-k-sorted-lists/)\n\n合併 `k` 個已排序好的鏈結串列成一個排序好的鏈結串列。\n\n# 範例說明\n```\nInput:\n[\n  1->4->5,\n  1->3->4,\n  2->6\n]\nOutput: 1->1->2->3->4->4->5->6\n```\n\n<!-- More -->\n\n# 想法\n以下簡稱 Linked list 為串列。\n\n## 方法一：時間複雜度 O(KN)、空間複雜度 O(KN)\n合併兩個長度分別為 `N`, `M`，排序好的串列，我們可以用雙指針遍歷兩個串列，每次都將比較小的值加入一個**新的序列**中，時間複雜度為 `O(N + M)`，空間複雜度為 `O(N + M)`。見下圖：\n\n<img width=\"50%\" src=\"/assets/LeetCode-Merge-k-Sorted-Lists/merge-k-sorted-lists-double-pointer.gif\">\n\n假設所有串列之總長為 `N`。\n\n如果每次逐次將第一、二個串列合併，再將合併結果與第三個串列合併、再將合併結果與第四個串列合併，最終我們合併了 `k - 1` 次，每次合併的時間複雜度不超過 `O(N)`。\n\n所以總時間複雜度為 `O(KN)`，空間複雜度為 `O(KN)`。\n\n## 方法二：時間複雜度 O(NlogK)、空間複雜度 O(1)\n\n先考慮合併序列的方法，若改為先將串列兩兩配對合併，下一輪再將合併過後的串列兩兩配對合併...，直到剩下一個串列為止。如下圖：\n\n<img width=\"70%\" src=\"/assets/LeetCode-Merge-k-Sorted-Lists/merge-k-sorted-lists-merge.png\">\n\n每一輪合併，串列的數量減半，總共合併了 `logK + 1` 輪。再加上每一輪都會遍歷所有的串列每一個數字，總長度為 `N`。總時間複雜度降為 `O(NLogK)`。\n\n再來改善記憶體空間的使用，若合併兩序列能不花費額外的空間儲存，即可做到空間複雜度 `O(1)`。\n解決辦法其實也很簡單，就是做 in-place（原地）合併。\n\n合併兩串列時 `lhs`, `rhs` 時，若 `lhs->val < rhs->val`，則 `lhs` 即為合併後串列的頭，且 `lhs->next` 會等於合併 `lhs->next`, `rhs` 兩串列的結果。反之亦然，若 `lhs->val > rhs->val`，則 `rhs` 即為合併後串列的頭，且 `rhs->next` 為合併 `lhs`, `rhs->next` 兩串列的結果。\n\n舉例來說，串列 `lhs=1->3->7->8`, `rhs=2->4->5->6`。因為 `lhs->val = 1 < 2 = rhs->val`，所以 `lhs` 為合併 `lhs`, `rhs` 後串列的頭，而 `lhs->next` 等於合併 `lhs->next=3->7->8`, `rhs=2->4->5->6` 兩串列的結果。\n\n# 實作細節\n## 合併 K 個串列\n\n筆者是這樣思考的：`x <- y` 為將串列 `y` 合併進串列 `x`。\n- 第一輪：`0 <- 1`, `2 <- 3`, `4 <- 5`, `6 <- 7`... `x = 0, 2, 4, 6 ...`, `y = x + 1`\n- 第二輪：`0 <- 2`, `4 <- 6`, `8 <- 10`, `12 <- 14`... `x = 0, 4, 8, 12 ...`, `y = x + 2`\n- 第三輪：`0 <- 4`, `8 <- 12`, `16 <- 20`, `24 <- 28`... `x = 0, 8, 16, 24 ...`, `y = x + 4`\n\n總結來說，第 `k` 輪：\n$$x=0,\\ 1\\times(2^k),\\ 2\\times(2^k),\\ 3\\times(2^k)...$$\n$$y=x+2^{k-1}$$\n\n所以：\n```cpp\n// i = 2^(k-1), so i = 1, 2, 4, 8, ....\nfor (int i = 1; i < listsLength; i <<= 1) {\n  /**\n   * j = 0, 1 * (2^k), 2 * (2^k), 3 * (2^k), so\n   * x = j, y = i + j\n   * so we merge lists[i + j] into lists[j]\n   */\n  for (int j = 0; j + i < listsLength; j += i * 2) {\n    lists[j] = inplaceMerge(lists[j], lists[j + i]);\n  }\n}\n```\n\n## 合併兩個串列\n\n寫成遞迴的形式，見下方程式碼 `inplaceMerge`。\n\n# 程式碼\n\n```cpp\n/**\n * Author: justin0u0<mail@justin0u0.com>\n * Problem: https://leetcode.com/problems/merge-k-sorted-lists/\n * Runtime: 28ms\n */\n\n/**\n * Definition for singly-linked list.\n * struct ListNode {\n *     int val;\n *     ListNode *next;\n *     ListNode() : val(0), next(nullptr) {}\n *     ListNode(int x) : val(x), next(nullptr) {}\n *     ListNode(int x, ListNode *next) : val(x), next(next) {}\n * };\n */\nclass Solution {\nprivate:\n  ListNode* inplaceMerge(ListNode* lhs, ListNode* rhs) {\n    if (!lhs) return rhs;\n    if (!rhs) return lhs;\n\n    if (lhs->val < rhs->val) {\n      // 如果 lhs->val < rhs->val, lhs->next 為合併 lhs->next, rhs 之結果\n      lhs->next = inplaceMerge(lhs->next, rhs);\n      // 如果 lhs->val < rhs->val，lhs 為合併兩串列之頭\n      return lhs;\n    } else {\n      rhs->next = inplaceMerge(lhs, rhs->next);\n      return rhs;\n    }\n  }\npublic:\n  ListNode* mergeKLists(vector<ListNode*>& lists) {\n    if (lists.empty()) return nullptr;\n    int listsLength = (int)lists.size();\n    // i = 2^(k-1), so i = 1, 2, 4, 8, ....\n    for (int i = 1; i < listsLength; i <<= 1) {\n      /**\n      * j = 0, 1 * (2^k), 2 * (2^k), 3 * (2^k), so\n      * x = j, y = i + j\n      * so we merge lists[i + j] into lists[j]\n      */\n      for (int j = 0; j + i < listsLength; j += i * 2) {\n        lists[j] = inplaceMerge(lists[j], lists[j + i]);\n      }\n    }\n    return lists[0];\n  }\n};\n\n```\n","tags":["LeetCode","鏈結串列（Linked List）"],"categories":["LeetCode"]},{"title":"LeetCode 10 - Regular Expression Matching","url":"/LeetCode-Regular-Expression-Matching/","content":"\n# 題目\n題目連結：[https://leetcode.com/problems/regular-expression-matching/](https://leetcode.com/problems/regular-expression-matching/)\n\n給一個字串 `s` 和樣板（pattern） `p`，實作支援 `.` 和 `*` 的 regular expression。\n\n```\n'.' Matches any single character. 匹配一個任一字元。\n'*' Matches zero or more of the preceding element. 匹配零到任意多個前一個字元\n```\n\n計算 `s` 是否匹配 `p`。\n\n# 範例說明\n\n## Example 1:\n```\nInput:\ns = \"aa\"\np = \"a\"\nOutput: false\nExplanation: \"a\" does not match the entire string \"aa\".\n```\n\n## Example 2:\n```\nInput:\ns = \"aa\"\np = \"a*\"\nOutput: true\nExplanation:\n'*' means zero or more of the preceding element, 'a'.\nTherefore, by repeating 'a' once, it becomes \"aa\".\n```\n\n<!-- More -->\n\n## Example 3:\n```\nInput:\ns = \"ab\"\np = \".*\"\nOutput: true\nExplanation:\n\".*\" means \"zero or more (*) of any character (.)\".\n```\n\n## Example 4:\n```\nInput:\ns = \"aab\"\np = \"c*a*b\"\nOutput: true\nExplanation:\nc can be repeated 0 times, a can be repeated 1 time. \nTherefore, it matches \"aab\".\n```\n\n## Example 5:\n```\nInput:\ns = \"mississippi\"\np = \"mis*is*p*.\"\nOutput: false\n```\n\n# 想法\n\n## 動態規劃 Dynamic programming\n首先，遇到兩字串匹配的問題，我們通常都可以用一個二維的 dynamic programming 表格來解決。\n筆者喜歡將 DP 表格從一開始編號，因為 0 是邊界，常常拿來儲存邊界資訊。而這題也不例外。\n遇到 DP 問題，筆者通常都會思考兩個方向：\n1. 狀態：定義 `d(i)`, `d(i, j)` ... 代表什麼意義。\n2. 轉移：定義 `d(i)` 的答案從哪裡來，`d(i, j)` 的答案從哪裡來...\n\n轉移時務必要注意答案要從已經計算完的區間得來。\n\n## DP 狀態\n假設兩字串分別為 `s` 以及 `p`，而且從索引 1 開始編號。\n所以我們可以定義 DP 狀態為： `d(i, j) = s[1 ~ i], p[1 ~ j] 是否匹配`。\n\n## DP 轉移\n\n1. 首先，我們可以發現，如果一個字元的後面為一個 `*` 字元，那麼我們應該要把這個字元跟連著的 `*` 看成一組。也就是說，如果遇到一個字元後面緊接著一個 `*`，那麼我們可以直接把忽略這個字元的作用直接繼承上一排的狀態，所以轉移式為：\n\n  $$d(i,\\ j)=d(i,\\ j-1)\\quad if\\ \\textcolor{red}{p[j+1]=*}$$\n\n2. 再來，如果 `p[j]` 為一般的字母且匹配到 `s[i]`，那麼我們 `d(i, j)=1` 若且唯若 `d(i - 1, j - 1) = 1`。也就是如果 `s[1 ~ i - 1]` 能匹配到 `p[1 ~ j - 1]` 且 `s[i] == p[j]`，那麼 `s[1 ~ i]` 匹配到 `p[1 ~ j]`。所以轉移式為：\n\n  $$d(i,\\ j)=d(i-1,\\ j-1)\\quad if\\ \\textcolor{red}{p[j+1]\\ne*}\\ \\& \\ \\textcolor{red}{s[i]=p[j]}$$\n\n3. 再來我們考慮 `p[j]='.'` 的情況，可以發現其實 `p[j]='.'` 的轉移與第二點類似，只是 `.` 可以代表任意字元，因此我們 `s[i]=p[j]` 的條件永遠成立。所以轉移式為：\n\n  $$d(i,\\ j)=d(i-1,\\ j-1)\\quad if\\ \\textcolor{red}{p[j+1]\\ne*}\\ \\&\\ \\textcolor{red}{p[j]=.}$$\n\n4. 最後我們考慮 `p[j]='*'` 的情況，有兩種情況能使 `d(i, j) = 1`。\n   \n   1. 如果 `*` 重複了 0 次，代表此狀態跟上一排一樣，所以轉移式應該與第一點相同。\n   2. 如果 `*` 重複一次以上，必須滿足 `*` 的前一個字元 `p[j - 1]` 應該等於當前的 `s[i]`（當然 `p[j - 1] = '.'` 也是可以的），且 `s[1 ~ i - 1]` 要能匹配 `p[1 ~ j]`，也就是 `d(i - 1, j) = 1`。滿足上述兩點性質，就代表我們可以再加上一個 `p[j - 1]` 字元使得 `d(i, j) = 1`。\n  \n    所以轉移式為：\n    $$d(i,\\ j)=(\\textcolor{red}{d(i,\\ j-1)=1}\\ |\\ \\textcolor{blue}{(}\\textcolor{red}{d(i-1,j)=1}\\ \\&\\ \\textcolor{purple}{(}\\textcolor{red}{p[j-1]=s[i]}\\ |\\ \\textcolor{red}{p[j-1]=.}\\textcolor{purple}{)}\\textcolor{blue}{)}) \\quad if\\ \\textcolor{red}{p[j]=*}$$\n\n## DP 總整理\n\n有了上述 4 點，可以整理轉移式為：\n  $$d(i,\\ j)=d(i,\\ j-1)\\quad if\\ \\textcolor{red}{p[j+1]=*}$$\n\n  $$d(i,\\ j)=d(i-1,\\ j-1)\\quad else\\ if\\ \\textcolor{red}{s[i]=p[j]\\ |\\ p[j]=.}$$\n\n  $$d(i,\\ j)=(\\textcolor{red}{d(i,\\ j-1)}\\ |\\ \\textcolor{blue}{(}\\textcolor{red}{d(i-1,j)}\\ \\&\\ \\textcolor{purple}{(}\\textcolor{red}{p[j-1]=s[i]}\\ |\\ \\textcolor{red}{p[j-1]=.}\\textcolor{purple}{)}\\textcolor{blue}{)}) \\quad else\\ if\\ \\textcolor{red}{p[j]=*}$$\n\n最後我們考慮邊界情況，發現：\n\n1. `d(0, 0)=1`：`s` 與 `p` 同時為空應該要算是匹配。\n2. `d(i, 0)=0, i > 0`：`p` 為空但 `s` 不為空，不匹配。\n3. `d(0, i)`：與 DP 轉移式相同，只是無法從 `d(-1, i)` 轉移，所有轉移皆從 `d(0, i - 1)` 而來。\n\n最終答案即是 `dp[|s|][|p|]`\n\n# 範例與 DP 對照\n## Example 1\n\n| s\\p | X | a |\n|-----|---|---|\n| X   | 1 | 0 |\n| a   | 0 | 1 |\n| a   | 0 | 0 |\n\n## Example 2\n\n| s\\p | X | a | * |\n|-----|---|---|---|\n| X   | 1 | 1 | 1 |\n| a   | 0 | 0 | 1 |\n| a   | 0 | 0 | 1 |\n\n## Example 4\n\n| s\\p | x | c | * | a | * | b |\n|-----|---|---|---|---|---|---|\n| x   | 1 | 1 | 1 | 1 | 1 | 0 |\n| a   | 0 | 0 | 0 | 0 | 1 | 0 |\n| a   | 0 | 0 | 0 | 0 | 1 | 0 |\n| b   | 0 | 0 | 0 | 0 | 0 | 1 |\n\n# 實作細節\n因為真實情況中，`s` 與 `p` 皆為 Base 0（索引從 0 開始），所以實作中可以考慮兩種做法：\n1. 將字串都轉換為 Base 1。\n2. 將轉移式中的 `d(i, j)` 都變為 `d(i + 1, j + 1)`。\n\n筆者實作中採用的是第二種方法。\n\n# 程式碼\n\n```cpp\n/**\n * Author: justin0u0<mail@justin0u0.com>\n * Problem: https://leetcode.com/problems/regular-expression-matching/\n * Runtime: 24ms\n */\n\nclass Solution {\npublic:\n  bool isMatch(string s, string p) {\n    int sLength = (int)s.length();\n    int pLength = (int)p.length();\n\n    // 宣告 (sLength + 1) * (pLength + 1) 大小的 2D DP 陣列表格，並初始化為 0\n    vector<vector<bool>> dp(sLength + 1, vector<bool>(pLength + 1, false));\n    // 邊界 1\n    dp[0][0] = true;\n\n    // 邊界 3\n    for (int i = 0; i < pLength; i++) {\n      if ((i != pLength - 1 && p[i + 1] == '*') || p[i] == '*')\n        dp[0][i + 1] = dp[0][i];\n    }\n\n    for (int i = 0; i < sLength; i++) {\n      for (int j = 0; j < pLength; j++) {\n        if (j != pLength - 1 && p[j + 1] == '*') {\n          // 轉移 1\n          dp[i + 1][j + 1] = dp[i + 1][j];\n        } else if ((p[j] == s[i] || p[j] == '.')) {\n          // 轉移 2\n          dp[i + 1][j + 1] = dp[i][j];\n        } else if (p[j] == '*') {\n          // 轉移 3\n          dp[i + 1][j + 1] = (dp[i + 1][j] || (dp[i][j + 1] && (p[j - 1] == s[i] || p[j - 1] == '.')));\n        }\n      }\n    }\n\n    return dp[sLength][pLength];\n  }\n};\n\n```\n\n# 感想\n這題雖然沒有很複雜，但是要把 DP 的想法表達的清楚真的不簡單呢！\n\n希望大家會喜歡，喜歡的話可以留下 Comments 或是點個讚，謝謝支持～\n","tags":["LeetCode","動態規劃（Dynamic Programming, DP）"],"categories":["LeetCode"]},{"title":"LeetCode 4 - Median of Two Sorted Arrays","url":"/LeetCode-Median-of-Two-Sorted-Arrays/","content":"\n# 題目\n題目連結：[https://leetcode.com/problems/median-of-two-sorted-arrays/](https://leetcode.com/problems/median-of-two-sorted-arrays/)\n\n給定兩個排序好的序列 `nums1` 和 `nums2`，長度分別為 `m` 和 `n`。\n\n找到兩個序列的中位數。\n\n# 範例說明\n\n**Example 1**\n```\nnums1 = [1, 3]\nnums2 = [2]\n\nThe median is 2.0\n```\n\n**Example 2**\n```\nnums1 = [1, 2]\nnums2 = [3, 4]\n\nThe median is (2 + 3)/2 = 2.5\n```\n\n<!-- more -->\n\n# 想法\n我們先將題目想成從兩個序列中求出第 k 大的數字。\n\n題目要求時間複雜度為 `O(log(m + n))`，所以我們首先想到如果能每一次都捨去總長度一半的序列，那我們的最終時間複雜度就會是 `O(log(m + n))`。\n\n那我們要如何知道哪段序列是可以捨去的呢？\n假設 `nums1` 以及 `nums2` 都是從索引值 0 開始編號。\n\n**我們比較任意 `nums1[i]` 以及 `nums2[j]`，如果 `nums1[i] < nums2[j]`，那 `nums1[i]` 最大的可能性為第 `i + j + 1` 大（如果 `nums1[0] ~ nums1[i - 1], nums2[0] ~ nums2[j - 1]` 都小於 `nums1[i]`）。反之亦然，如果 `nums1[i] > nums2[j]`，那 `nums2[j]` 最大的可能性也是第 `i + j + 1` 大**。\n\n也就是：\n1. `nums1[i] < nums2[j]`，`nums1[i]` 最大為第 `i + j + 1` 大。\n2. `nums1[i] >= nums2[j]`, `nums2[j]` 最大為第 `i + j + 1` 大。\n\n知道了這個性質後，如果我們取 `i = k / 2 - 1` 且 `j = k / 2 - 1`，那上述兩點會變為：\n1. `nums1[i] < nums2[j]`，`nums1[i]` 最大為第 `k - 1` 大。\n2. `nums1[i] >= nums2[j]`, `nums2[j]` 最大為第 `k - 1` 大。\n\n也就是說，如果 `nums1[i] < nums2[j]`，我們可以捨去 `nums1[0] ~ nums1[i]`，因為 `nums1[i]` 至多才第 `k - 1` 大而已。捨去後部分序列後，我們要找的變成剩下的序列中第 `k - 捨去的數字數量` 大的數字。\n\n最後，如果一序列已被完全捨棄，那答案必定是另一個序列的第 `k` 大數字。或是當 `k` 剩下 1 時，我們知道答案為兩個序列的第一個數字的最小值。\n\n因為我們每次都捨去至少 `k / 2` 個數字，所以 `k` 每次都會變小一半，直到 `k = 1` 為止，所以時間複雜度為 `O(log(k))`。而 `k = m + n / 2`，所以總時間複雜度為 `O(log(m + n / 2)) = O(log(m + n))`。\n\n# 實作細節\n`arr1` 為 `nums1` 之序列指標；`arr2` 為 `nums2` 之序列指標。\n\n`m` 為 `arr1` 當前之長度，`n` 為 `arr2` 當前之長度。\n\n[可以利用 `vector.data()` 來拿到序列的指標。](http://www.cplusplus.com/reference/vector/vector/data/)\n\n若要刪除 `arr1[0] ~ arr1[i - 1]`，則將指標向後移動 `i` 格，將序列長度 `m` 減少 `i`，將 `k` 減去 `i`。\n\n# 程式碼\n```cpp\n/**\n * Author: justin0u0<mail@justin0u0.com>\n * Problem: https://leetcode.com/problems/median-of-two-sorted-arrays/\n * Runtime: 44ms\n */\n\nclass Solution {\n  // 在 arr1[0 ~ m - 1], arr2[0 ~ n - 1] 中，找到第 k 大數字。\n  int findKthNumber(int *arr1, int *arr2, int m, int n, int k) {\n    // 當 arr1 為空，答案在 arr2 中\n    if (m == 0) {\n      return arr2[k - 1];\n    }\n    // 當 arr2 為空，答案在 arr1 中\n    if (n == 0) {\n      return arr1[k - 1];\n    }\n    // 當 k = 1，答案為兩序列中第一個數字的最小值\n    if (k == 1) {\n      return arr1[0] < arr2[0] ? arr1[0] : arr2[0];\n    }\n\n    // 當 m < k / 2 或是 n < k / 2 時，取 i = m 或是 j = n，一樣滿足上述式子\n    int i = min(k / 2, m);\n    int j = min(k / 2, n);\n    // 捨棄較小一端的部分序列\n    if (arr1[i - 1] < arr2[j - 1]) {\n      // 捨棄 arr1[0] ~ arr1[i - 1]\n      return findKthNumber(arr1 + i, arr2, m - i, n, k - i);\n    } else {\n      // 捨棄 arr2[0] ~ arr2[j - 1]\n      return findKthNumber(arr1, arr2 + j, m, n - j, k - j);\n    }\n  }\npublic:\n  double findMedianSortedArrays(vector<int>& nums1, vector<int>& nums2) {\n    int m = (int)nums1.size();\n    int n = (int)nums2.size();\n    int k = (n + m) / 2 + 1;\n    // 如果總長度為奇數，中位數 = 第 (n + m) / 2 + 1 大的數字\n    if ((n + m) & 1) {\n      return findKthNumber(nums1.data(), nums2.data(), m, n, k);\n    }\n    // 如果總長度為偶數，中位數 \b= 第 (n + m) / 2 + 1, (n + m) / 2 大的數字之平均\n    return (findKthNumber(nums1.data(), nums2.data(), m, n, k) + findKthNumber(nums1.data(), nums2.data(), m, n, k - 1)) / 2.0;\n};\n\n```\n","tags":["LeetCode"],"categories":["LeetCode"]},{"title":"LeetCode 514 - Freedom Trail","url":"/LeetCode-Freedom-Trail/","content":"\n# 題目\n題目連結：[https://leetcode.com/problems/freedom-trail/](https://leetcode.com/problems/freedom-trail/)\n\n給定一個環狀的字串 `ring`，再給一個字串 `key`，要求利用 `ring` 在最少步數內拼出字串 `key`。\n\n一開始指標在字串 `ring` 的第一個字元上，將指標順時鐘或是逆時鐘動一格算是一步。當指標所指的字元等於你要拼的 `key` 中的字元，你還必須花一步來按下確認按鈕。\n\n# 範例說明\n<img src=\"/assets/LeetCode-Freedom-Trail/freedom-trail-ring.jpg\" width=\"30%\" />\n\n<!-- more -->\n\n**輸入：**\n\n`ring = \"godding\"`\n\n`key = \"gd\"`\n\n**輸出：** 4\n\n**說明：** 一開始指標在 `ring` 的第一個字元 `g`，所以我們只要花一步按下確認鈕就好。再來我們花費兩步逆時針旋轉 `ring` 兩次，讓指標到達 `d`。再花一步按下確認鈕，總共花費 4 步。\n\n# 想法\n`ring` 中的字元是會重複的，因此我們無法確定離當前指標比較近的目標字元會使我們的答案最佳化。\n因此我們換個想法，如果在搜尋第 `i` 個字元 `key[i]` 時，旋轉到位置 `j` 的最佳答案，紀錄為 `dp(i, j)`。\n\n定義 `N = ring 的長度`, `M = key 的長度`。\n定義將 `ring` 從位置 `k` 轉到位置 `j` 的最小花費為 `dist(k, j)`。那麼我們可以輕易發現：\n$$dp(i, j) = min(dp(i - 1,k)+dist(k,j)+1), \\quad \\forall i \\in [1, M]\\ ,\\forall j \\in [0, N) $$\n也就是 `dp(i, j)` 等於從第 `i - 1` 步的任意位置轉到位置 `j` 的花費加上原來記錄的最小花費`dp(i - 1, k)`，再加上一步按確認鍵。\n\n初始化時只要將 `dp(0, 0)` 設成 0，其餘位置設成無限大，`dp(i, j)` 只在 `ring[j] = key[i]` 時計算。便能求出答案為：\n$$min(dp(M, j)), \\quad \\forall\\ j \\in [0, N)$$\n\n總時間複雜度為 `O(N^2 * M)`。\n\n# 程式碼\n```cpp\n/**\n * Author: justin0u0<mail@justin0u0.com>\n * Problem: https://leetcode.com/problems/freedom-trail/\n * Runtime: 116ms\n */\n\nclass Solution {\nprivate:\n  const int INF = 0x3f3f3f3f;\npublic:\n  int findRotateSteps(string ring, string key) {\n    const int rl = (int)ring.length();\n    const int kl = (int)key.length();\n    // 初始化 kl * rl 的陣列，並將值都設為無限大\n    vector<vector<int>> dp(kl + 1, vector<int>(rl, INF));\n    dp[0][0] = 0;\n\n    for (int i = 1; i <= kl; i++) {\n      for (int j = 0; j < rl; j++) {\n        if (key[i - 1] == ring[j]) {\n          for (int k = 0; k < rl; k++) {\n            // 從位置 k 到位置 j，dist(k, j) = min(abs(k - j), rl - abs(k - j)) + 1\n            int dist = abs(k - j);\n            dp[i][j] = min(dp[i][j], dp[i - 1][k] + min(dist, rl - dist) + 1);\n          }\n        }\n      }\n    }\n\n    // 答案為 dp[kl] 中的最小值\n    int steps = INF;\n    for (int i = 0; i < rl; i++) {\n      steps = min(steps, dp[kl][i]);\n    }\n    return steps;\n  }\n};\n\n```\n","tags":["LeetCode","動態規劃（Dynamic Programming, DP）"],"categories":["LeetCode"]}]